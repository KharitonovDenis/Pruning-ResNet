{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:24:29.724649Z","iopub.status.busy":"2024-03-30T12:24:29.724084Z","iopub.status.idle":"2024-03-30T12:24:37.350653Z","shell.execute_reply":"2024-03-30T12:24:37.349843Z","shell.execute_reply.started":"2024-03-30T12:24:29.724616Z"},"trusted":true},"outputs":[],"source":["import os\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import datasets, transforms\n","\n","import time\n","import copy\n","\n","import numpy as np\n","\n","import sklearn.metrics\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:24:39.371583Z","iopub.status.busy":"2024-03-30T12:24:39.370796Z","iopub.status.idle":"2024-03-30T12:24:39.376750Z","shell.execute_reply":"2024-03-30T12:24:39.375613Z","shell.execute_reply.started":"2024-03-30T12:24:39.371546Z"},"trusted":true},"outputs":[],"source":["def set_random_seeds(random_seed=0):\n","\n","    torch.manual_seed(random_seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(random_seed)\n","    random.seed(random_seed)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:24:40.343193Z","iopub.status.busy":"2024-03-30T12:24:40.342818Z","iopub.status.idle":"2024-03-30T12:24:41.338836Z","shell.execute_reply":"2024-03-30T12:24:41.337877Z","shell.execute_reply.started":"2024-03-30T12:24:40.343164Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Sat Mar 30 12:24:41 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0              27W / 250W |      0MiB / 16384MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:24:45.685210Z","iopub.status.busy":"2024-03-30T12:24:45.684857Z","iopub.status.idle":"2024-03-30T12:24:45.689622Z","shell.execute_reply":"2024-03-30T12:24:45.688575Z","shell.execute_reply.started":"2024-03-30T12:24:45.685180Z"},"trusted":true},"outputs":[],"source":["#torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:24:46.134619Z","iopub.status.busy":"2024-03-30T12:24:46.133697Z","iopub.status.idle":"2024-03-30T12:24:46.138546Z","shell.execute_reply":"2024-03-30T12:24:46.137515Z","shell.execute_reply.started":"2024-03-30T12:24:46.134573Z"},"trusted":true},"outputs":[],"source":["#!nvidia-smi"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:24:46.827253Z","iopub.status.busy":"2024-03-30T12:24:46.826908Z","iopub.status.idle":"2024-03-30T12:24:47.888665Z","shell.execute_reply":"2024-03-30T12:24:47.887920Z","shell.execute_reply.started":"2024-03-30T12:24:46.827226Z"},"trusted":true},"outputs":[],"source":["#import os\n","#import time\n","import math\n","#import random\n","#import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","import glob\n","\n","import matplotlib.pyplot as plt\n","from PIL import Image, ImageEnhance, ImageOps\n","\n","from tqdm import tqdm, tqdm_notebook\n","\n","import torch\n","from torch import nn, cuda\n","from torch.autograd import Variable \n","import torch.nn.functional as F\n","import torchvision as vision\n","import torchvision.models as models\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import Adam, SGD, Optimizer\n","from torch.optim.lr_scheduler import _LRScheduler, CosineAnnealingLR, ReduceLROnPlateau\n","\n","from sklearn.metrics import f1_score\n","\n","class CIFAR10Policy(object):\n","    \"\"\" Randomly choose one of the best 25 Sub-policies on CIFAR10.\n","        Example:\n","        >>> policy = CIFAR10Policy()\n","        >>> transformed = policy(image)\n","        Example as a PyTorch Transform:\n","        >>> transform=transforms.Compose([\n","        >>>     transforms.Resize(256),\n","        >>>     CIFAR10Policy(),\n","        >>>     transforms.ToTensor()])\n","    \"\"\"\n","    def __init__(self, fillcolor=(128, 128, 128)):\n","        self.policies = [\n","            SubPolicy(0.1, \"invert\", 7, 0.2, \"contrast\", 6, fillcolor),\n","            SubPolicy(0.7, \"rotate\", 2, 0.3, \"translateX\", 9, fillcolor),\n","            SubPolicy(0.8, \"sharpness\", 1, 0.9, \"sharpness\", 3, fillcolor),\n","            SubPolicy(0.5, \"shearY\", 8, 0.7, \"translateY\", 9, fillcolor),\n","            SubPolicy(0.5, \"autocontrast\", 8, 0.9, \"equalize\", 2, fillcolor),\n","\n","            SubPolicy(0.2, \"shearY\", 7, 0.3, \"posterize\", 7, fillcolor),\n","            SubPolicy(0.4, \"color\", 3, 0.6, \"brightness\", 7, fillcolor),\n","            SubPolicy(0.3, \"sharpness\", 9, 0.7, \"brightness\", 9, fillcolor),\n","            SubPolicy(0.6, \"equalize\", 5, 0.5, \"equalize\", 1, fillcolor),\n","            SubPolicy(0.6, \"contrast\", 7, 0.6, \"sharpness\", 5, fillcolor),\n","\n","            SubPolicy(0.7, \"color\", 7, 0.5, \"translateX\", 8, fillcolor),\n","            SubPolicy(0.3, \"equalize\", 7, 0.4, \"autocontrast\", 8, fillcolor),\n","            SubPolicy(0.4, \"translateY\", 3, 0.2, \"sharpness\", 6, fillcolor),\n","            SubPolicy(0.9, \"brightness\", 6, 0.2, \"color\", 8, fillcolor),\n","            SubPolicy(0.5, \"solarize\", 2, 0.0, \"invert\", 3, fillcolor),\n","\n","            SubPolicy(0.2, \"equalize\", 0, 0.6, \"autocontrast\", 0, fillcolor),\n","            SubPolicy(0.2, \"equalize\", 8, 0.8, \"equalize\", 4, fillcolor),\n","            SubPolicy(0.9, \"color\", 9, 0.6, \"equalize\", 6, fillcolor),\n","            SubPolicy(0.8, \"autocontrast\", 4, 0.2, \"solarize\", 8, fillcolor),\n","            SubPolicy(0.1, \"brightness\", 3, 0.7, \"color\", 0, fillcolor),\n","\n","            SubPolicy(0.4, \"solarize\", 5, 0.9, \"autocontrast\", 3, fillcolor),\n","            SubPolicy(0.9, \"translateY\", 9, 0.7, \"translateY\", 9, fillcolor),\n","            SubPolicy(0.9, \"autocontrast\", 2, 0.8, \"solarize\", 3, fillcolor),\n","            SubPolicy(0.8, \"equalize\", 8, 0.1, \"invert\", 3, fillcolor),\n","            SubPolicy(0.7, \"translateY\", 9, 0.9, \"autocontrast\", 1, fillcolor)\n","        ]\n","\n","\n","    def __call__(self, img):\n","        policy_idx = random.randint(0, len(self.policies) - 1)\n","        return self.policies[policy_idx](img)\n","\n","    def __repr__(self):\n","        return \"AutoAugment CIFAR10 Policy\"\n","\n","\n","class SubPolicy(object):\n","    def __init__(self, p1, operation1, magnitude_idx1, p2, operation2, magnitude_idx2, fillcolor=(128, 128, 128)):\n","        ranges = {\n","            \"shearX\": np.linspace(0, 0.3, 10),\n","            \"shearY\": np.linspace(0, 0.3, 10),\n","            \"translateX\": np.linspace(0, 150 / 331, 10),\n","            \"translateY\": np.linspace(0, 150 / 331, 10),\n","            \"rotate\": np.linspace(0, 30, 10),\n","            \"color\": np.linspace(0.0, 0.9, 10),\n","            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(int),\n","            \"solarize\": np.linspace(256, 0, 10),\n","            \"contrast\": np.linspace(0.0, 0.9, 10),\n","            \"sharpness\": np.linspace(0.0, 0.9, 10),\n","            \"brightness\": np.linspace(0.0, 0.9, 10),\n","            \"autocontrast\": [0] * 10,\n","            \"equalize\": [0] * 10,\n","            \"invert\": [0] * 10\n","        }\n","\n","        # from https://stackoverflow.com/questions/5252170/specify-image-filling-color-when-rotating-in-python-with-pil-and-setting-expand\n","        def rotate_with_fill(img, magnitude):\n","            rot = img.convert(\"RGBA\").rotate(magnitude)\n","            return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(img.mode)\n","\n","        func = {\n","            \"shearX\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, magnitude * random.choice([-1, 1]), 0, 0, 1, 0),\n","                Image.BICUBIC, fillcolor=fillcolor),\n","            \"shearY\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, 0, 0, magnitude * random.choice([-1, 1]), 1, 0),\n","                Image.BICUBIC, fillcolor=fillcolor),\n","            \"translateX\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, 0, magnitude * img.size[0] * random.choice([-1, 1]), 0, 1, 0),\n","                fillcolor=fillcolor),\n","            \"translateY\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * img.size[1] * random.choice([-1, 1])),\n","                fillcolor=fillcolor),\n","            \"rotate\": lambda img, magnitude: rotate_with_fill(img, magnitude),\n","            # \"rotate\": lambda img, magnitude: img.rotate(magnitude * random.choice([-1, 1])),\n","            \"color\": lambda img, magnitude: ImageEnhance.Color(img).enhance(1 + magnitude * random.choice([-1, 1])),\n","            \"posterize\": lambda img, magnitude: ImageOps.posterize(img, magnitude),\n","            \"solarize\": lambda img, magnitude: ImageOps.solarize(img, magnitude),\n","            \"contrast\": lambda img, magnitude: ImageEnhance.Contrast(img).enhance(\n","                1 + magnitude * random.choice([-1, 1])),\n","            \"sharpness\": lambda img, magnitude: ImageEnhance.Sharpness(img).enhance(\n","                1 + magnitude * random.choice([-1, 1])),\n","            \"brightness\": lambda img, magnitude: ImageEnhance.Brightness(img).enhance(\n","                1 + magnitude * random.choice([-1, 1])),\n","            \"autocontrast\": lambda img, magnitude: ImageOps.autocontrast(img),\n","            \"equalize\": lambda img, magnitude: ImageOps.equalize(img),\n","            \"invert\": lambda img, magnitude: ImageOps.invert(img)\n","        }\n","\n","        # self.name = \"{}_{:.2f}_and_{}_{:.2f}\".format(\n","        #     operation1, ranges[operation1][magnitude_idx1],\n","        #     operation2, ranges[operation2][magnitude_idx2])\n","        self.p1 = p1\n","        self.operation1 = func[operation1]\n","        self.magnitude1 = ranges[operation1][magnitude_idx1]\n","        self.p2 = p2\n","        self.operation2 = func[operation2]\n","        self.magnitude2 = ranges[operation2][magnitude_idx2]\n","\n","\n","    def __call__(self, img):\n","        if random.random() < self.p1: img = self.operation1(img, self.magnitude1)\n","        if random.random() < self.p2: img = self.operation2(img, self.magnitude2)\n","        return img\n","  \n","\n","class TestDataset(Dataset):\n","    def __init__(self, df, mode='test', transforms=None):\n","        self.df = df\n","        self.mode = mode\n","        self.transform = transforms[self.mode]\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, idx):\n","        \n","        image = Image.open(TEST_IMAGE_PATH / self.df[idx]).convert(\"RGB\")\n","        \n","        if self.transform:\n","            image = self.transform(image)\n","            \n","        return image"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:24:52.354308Z","iopub.status.busy":"2024-03-30T12:24:52.353420Z","iopub.status.idle":"2024-03-30T12:24:52.362335Z","shell.execute_reply":"2024-03-30T12:24:52.361282Z","shell.execute_reply.started":"2024-03-30T12:24:52.354275Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'\\ntrain_dataset = torchvision.datasets.CIFAR10(root=\"data\",\\n                                             train=True,\\n                                             download=True,\\n                                             transform=torchvision.transforms.Compose([\\n        # Resize step is required as we will use a ResNet model, which accepts at leats 224x224 images\\n        torchvision.transforms.Resize((224,224)),  \\n        torchvision.transforms.ToTensor(),\\n    ]))\\n\\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=512, shuffle=False, num_workers=2, pin_memory=False)\\n\\nmeans = []\\nstdevs = []\\nfor X, _ in train_dataloader:\\n    # Dimensions 0,2,3 are respectively the batch, height and width dimensions\\n    means.append(X.mean(dim=(0,2,3)))\\n    stdevs.append(X.std(dim=(0,2,3)))\\n\\nmean = torch.stack(means, dim=0).mean(dim=0)\\nstdev = torch.stack(stdevs, dim=0).mean(dim=0)\\nprint(mean, stdev)\\n'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","train_dataset = torchvision.datasets.CIFAR10(root=\"data\",\n","                                             train=True,\n","                                             download=True,\n","                                             transform=torchvision.transforms.Compose([\n","        # Resize step is required as we will use a ResNet model, which accepts at leats 224x224 images\n","        torchvision.transforms.Resize((224,224)),  \n","        torchvision.transforms.ToTensor(),\n","    ]))\n","\n","train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=512, shuffle=False, num_workers=2, pin_memory=False)\n","\n","means = []\n","stdevs = []\n","for X, _ in train_dataloader:\n","    # Dimensions 0,2,3 are respectively the batch, height and width dimensions\n","    means.append(X.mean(dim=(0,2,3)))\n","    stdevs.append(X.std(dim=(0,2,3)))\n","\n","mean = torch.stack(means, dim=0).mean(dim=0)\n","stdev = torch.stack(stdevs, dim=0).mean(dim=0)\n","print(mean, stdev)\n","\"\"\""]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:24:53.685436Z","iopub.status.busy":"2024-03-30T12:24:53.684743Z","iopub.status.idle":"2024-03-30T12:24:53.689565Z","shell.execute_reply":"2024-03-30T12:24:53.688522Z","shell.execute_reply.started":"2024-03-30T12:24:53.685397Z"},"trusted":true},"outputs":[],"source":["#!nvidia-smi"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:24:54.471434Z","iopub.status.busy":"2024-03-30T12:24:54.470751Z","iopub.status.idle":"2024-03-30T12:24:54.481770Z","shell.execute_reply":"2024-03-30T12:24:54.480912Z","shell.execute_reply.started":"2024-03-30T12:24:54.471400Z"},"trusted":true},"outputs":[],"source":["def prepare_dataloader(num_workers=0,\n","                       train_batch_size=128,\n","                       eval_batch_size=256,\n","                       mean=(0.4914, 0.4822, 0.4466),\n","                       stdev=(0.2412, 0.2377, 0.2563)):\n","\n","    train_transform = transforms.Compose([\n","        torchvision.transforms.Resize((224,224)),\n","        CIFAR10Policy(),\n","        torchvision.transforms.ToTensor(),\n","        torchvision.transforms.Normalize(mean=mean, std=stdev)\n","    ])\n","\n","    test_transform = transforms.Compose([\n","        torchvision.transforms.Resize((224,224)),\n","        torchvision.transforms.ToTensor(),\n","        torchvision.transforms.Normalize(mean=torch.tensor(mean), std=stdev)\n","    ])\n","\n","    train_set = torchvision.datasets.CIFAR10(root=\"data\",\n","                                             train=True,\n","                                             download=True,\n","                                             transform=train_transform)\n","\n","    test_set = torchvision.datasets.CIFAR10(root=\"data\",\n","                                            train=False,\n","                                            download=True,\n","                                            transform=test_transform)\n","\n","    train_sampler = torch.utils.data.RandomSampler(train_set)\n","    test_sampler = torch.utils.data.SequentialSampler(test_set)\n","\n","    train_loader = torch.utils.data.DataLoader(dataset=train_set,\n","                                               batch_size=train_batch_size,\n","                                               #shuffle=True,\n","                                               sampler=train_sampler,\n","                                               num_workers=num_workers,\n","                                               pin_memory=True\n","                                              )\n","\n","    test_loader = torch.utils.data.DataLoader(dataset=test_set,\n","                                              batch_size=eval_batch_size,\n","                                              #shuffle=False,\n","                                              sampler=test_sampler,\n","                                              num_workers=num_workers,\n","                                              pin_memory=True\n","                                             )\n","\n","    classes = train_set.classes\n","\n","    return train_loader, test_loader, classes"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:24:55.439584Z","iopub.status.busy":"2024-03-30T12:24:55.439062Z","iopub.status.idle":"2024-03-30T12:24:55.456232Z","shell.execute_reply":"2024-03-30T12:24:55.455193Z","shell.execute_reply.started":"2024-03-30T12:24:55.439558Z"},"trusted":true},"outputs":[],"source":["def train_model(model,\n","                train_loader,\n","                test_loader,\n","                device,\n","                model_dir,\n","                model_filename,\n","                l1_regularization_strength=0,\n","                l2_regularization_strength=0,\n","                weight_decay=5e-4,\n","                learning_rate=1e-4,\n","                num_epochs=200\n","                ):\n","\n","    \n","\n","    criterion = nn.CrossEntropyLoss()\n","\n","    model.to(device)\n","\n","    \n","    #optimizer = optim.SGD(model.parameters(),\n","    #                      lr=learning_rate,\n","    #                      momentum=0.9,\n","    #                      weight_decay=l2_regularization_strength)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=500)\n","    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n","                                                     milestones=[num_epochs*3/7, num_epochs*45/7, num_epochs*6/7],\n","                                                     gamma=0.1,\n","                                                     last_epoch=-1)\n","    # optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n","\n","    # Evaluation\n","    model.eval()\n","    eval_loss, eval_accuracy = evaluate_model(model=model,\n","                                              test_loader=test_loader,\n","                                              device=device,\n","                                              criterion=criterion)\n","    print(\"Epoch: {:03d} Eval Loss: {:.3f} Eval Acc: {:.3f}\".format(\n","        0, eval_loss, eval_accuracy))\n","\n","    for epoch in range(num_epochs):\n","\n","        # Training\n","        model.train()\n","\n","        running_loss = 0\n","        running_corrects = 0\n","\n","        for inputs, labels in train_loader:\n","\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            \n","            optimizer.zero_grad()\n","\n","            \n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","            loss = criterion(outputs, labels)\n","\n","            l1_reg = torch.tensor(0.).to(device)\n","            for module in model.modules():\n","                mask = None\n","                weight = None\n","                for name, buffer in module.named_buffers():\n","                    if name == \"weight_mask\":\n","                        mask = buffer\n","                for name, param in module.named_parameters():\n","                    if name == \"weight_orig\":\n","                        weight = param\n","                \n","                if mask is not None and weight is not None:\n","                    l1_reg += torch.norm(mask * weight, 1)\n","\n","            loss += l1_regularization_strength * l1_reg \n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            # statistics\n","            running_loss += loss.item() * inputs.size(0)\n","            running_corrects += torch.sum(preds == labels.data)\n","\n","        train_loss = running_loss / len(train_loader.dataset)\n","        train_accuracy = running_corrects / len(train_loader.dataset)\n","\n","        # Evaluation\n","        model.eval()\n","        eval_loss, eval_accuracy = evaluate_model(model=model,\n","                                                  test_loader=test_loader,\n","                                                  device=device,\n","                                                  criterion=criterion)\n","        if epoch % 40 == 0:\n","            save_model(model=model, model_dir=model_dir, model_filename=\"{}_epoch{}\".format(model_filename, epoch))\n","\n","        \n","        scheduler.step()\n","\n","        print(\n","            \"Epoch: {:03d} Train Loss: {:.3f} Train Acc: {:.3f} Eval Loss: {:.3f} Eval Acc: {:.3f}\"\n","            .format(epoch + 1, train_loss, train_accuracy, eval_loss,\n","                    eval_accuracy))\n","        #torch.cuda.empty_cache()\n","\n","    return model"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:24:56.142654Z","iopub.status.busy":"2024-03-30T12:24:56.142033Z","iopub.status.idle":"2024-03-30T12:24:56.150961Z","shell.execute_reply":"2024-03-30T12:24:56.150088Z","shell.execute_reply.started":"2024-03-30T12:24:56.142624Z"},"trusted":true},"outputs":[],"source":["def measure_module_sparsity(module, weight=True, bias=False, use_mask=False):\n","\n","    num_zeros = 0\n","    num_elements = 0\n","\n","    if use_mask == True:\n","        for buffer_name, buffer in module.named_buffers():\n","            if \"weight_mask\" in buffer_name and weight == True:\n","                num_zeros += torch.sum(buffer == 0).item()\n","                num_elements += buffer.nelement()\n","            if \"bias_mask\" in buffer_name and bias == True:\n","                num_zeros += torch.sum(buffer == 0).item()\n","                num_elements += buffer.nelement()\n","    else:\n","        for param_name, param in module.named_parameters():\n","            if \"weight\" in param_name and weight == True:\n","                num_zeros += torch.sum(param == 0).item()\n","                num_elements += param.nelement()\n","            if \"bias\" in param_name and bias == True:\n","                num_zeros += torch.sum(param == 0).item()\n","                num_elements += param.nelement()\n","\n","    sparsity = num_zeros / num_elements\n","\n","    return num_zeros, num_elements, sparsity"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:24:56.685833Z","iopub.status.busy":"2024-03-30T12:24:56.685472Z","iopub.status.idle":"2024-03-30T12:24:56.693106Z","shell.execute_reply":"2024-03-30T12:24:56.692175Z","shell.execute_reply.started":"2024-03-30T12:24:56.685805Z"},"trusted":true},"outputs":[],"source":["def measure_global_sparsity(model,\n","                            weight=True,\n","                            bias=False,\n","                            conv2d_use_mask=False,\n","                            linear_use_mask=False):\n","\n","    num_zeros = 0\n","    num_elements = 0\n","\n","    for module_name, module in model.named_modules():\n","\n","        if isinstance(module, torch.nn.Conv2d):\n","\n","            module_num_zeros, module_num_elements, _ = measure_module_sparsity(\n","                module, weight=weight, bias=bias, use_mask=conv2d_use_mask)\n","            num_zeros += module_num_zeros\n","            num_elements += module_num_elements\n","\n","        elif isinstance(module, torch.nn.Linear):\n","\n","            module_num_zeros, module_num_elements, _ = measure_module_sparsity(\n","                module, weight=weight, bias=bias, use_mask=linear_use_mask)\n","            num_zeros += module_num_zeros\n","            num_elements += module_num_elements\n","\n","    sparsity = num_zeros / num_elements\n","\n","    return num_zeros, num_elements, sparsity"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:24:57.326201Z","iopub.status.busy":"2024-03-30T12:24:57.325838Z","iopub.status.idle":"2024-03-30T12:24:57.333918Z","shell.execute_reply":"2024-03-30T12:24:57.333021Z","shell.execute_reply.started":"2024-03-30T12:24:57.326172Z"},"trusted":true},"outputs":[],"source":["def evaluate_model(model, test_loader, device, criterion=None):\n","\n","    model.eval()\n","    model.to(device)\n","\n","    running_loss = 0\n","    running_corrects = 0\n","\n","    for inputs, labels in test_loader:\n","\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(inputs)\n","        _, preds = torch.max(outputs, 1)\n","\n","        if criterion is not None:\n","            loss = criterion(outputs, labels).item()\n","        else:\n","            loss = 0\n","\n","        # statistics\n","        running_loss += loss * inputs.size(0)\n","        running_corrects += torch.sum(preds == labels.data)\n","        \n","        #torch.cuda.empty_cache()\n","\n","    eval_loss = running_loss / len(test_loader.dataset)\n","    eval_accuracy = running_corrects / len(test_loader.dataset)\n","    \n","\n","    return eval_loss, eval_accuracy"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:24:58.037976Z","iopub.status.busy":"2024-03-30T12:24:58.037010Z","iopub.status.idle":"2024-03-30T12:24:58.044694Z","shell.execute_reply":"2024-03-30T12:24:58.043673Z","shell.execute_reply.started":"2024-03-30T12:24:58.037945Z"},"trusted":true},"outputs":[],"source":["def create_classification_report(model, device, test_loader):\n","\n","    model.eval()\n","    model.to(device)\n","\n","    y_pred = []\n","    y_true = []\n","\n","    with torch.no_grad():\n","        for data in test_loader:\n","            y_true += data[1].numpy().tolist()\n","            images, _ = data[0].to(device), data[1].to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            y_pred += predicted.cpu().numpy().tolist()\n","\n","    classification_report = sklearn.metrics.classification_report(\n","        y_true=y_true, y_pred=y_pred)\n","\n","    return classification_report"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:24:58.629832Z","iopub.status.busy":"2024-03-30T12:24:58.629474Z","iopub.status.idle":"2024-03-30T12:24:58.635059Z","shell.execute_reply":"2024-03-30T12:24:58.633995Z","shell.execute_reply.started":"2024-03-30T12:24:58.629804Z"},"trusted":true},"outputs":[],"source":["def save_model(model, model_dir, model_filename):\n","\n","    if not os.path.exists(model_dir):\n","        os.makedirs(model_dir)\n","    model_filepath = os.path.join(model_dir, model_filename)\n","    torch.save(model.state_dict(), model_filepath)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:24:59.125591Z","iopub.status.busy":"2024-03-30T12:24:59.124890Z","iopub.status.idle":"2024-03-30T12:24:59.130256Z","shell.execute_reply":"2024-03-30T12:24:59.129195Z","shell.execute_reply.started":"2024-03-30T12:24:59.125555Z"},"trusted":true},"outputs":[],"source":["def load_model(model, model_filepath, device):\n","\n","    model.load_state_dict(torch.load(model_filepath, map_location=device))\n","\n","    return model"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:24:59.830666Z","iopub.status.busy":"2024-03-30T12:24:59.829969Z","iopub.status.idle":"2024-03-30T12:24:59.835902Z","shell.execute_reply":"2024-03-30T12:24:59.834818Z","shell.execute_reply.started":"2024-03-30T12:24:59.830632Z"},"trusted":true},"outputs":[],"source":["def create_model(num_classes=10, model_func=torchvision.models.resnet34):\n","\n","    \n","    model = model_func(num_classes=num_classes, pretrained=False)\n","\n","    \n","\n","    return model"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:25:00.449711Z","iopub.status.busy":"2024-03-30T12:25:00.449217Z","iopub.status.idle":"2024-03-30T12:25:00.468765Z","shell.execute_reply":"2024-03-30T12:25:00.467859Z","shell.execute_reply.started":"2024-03-30T12:25:00.449681Z"},"trusted":true},"outputs":[],"source":["def iterative_pruning_finetuning(model,\n","                                 train_loader,\n","                                 test_loader,\n","                                 device,\n","                                 learning_rate,\n","                                 l1_regularization_strength=0,\n","                                 l2_regularization_strength=0,\n","                                 weight_decay=5e-4,\n","                                 learning_rate_decay=0.6,\n","                                 conv2d_prune_amount=0.4,\n","                                 linear_prune_amount=0.2,\n","                                 num_iterations=10,\n","                                 num_epochs_per_iteration=10,\n","                                 model_filename_prefix=\"pruned_model\",\n","                                 model_dir=\"saved_models\",\n","                                 grouped_pruning=False):\n","\n","    conv2d_one_iter_prune_amount = 1 - (1 - conv2d_prune_amount)**(1/num_iterations)\n","    linear_one_iter_prune_amount = 1 - (1 - linear_prune_amount)**(1/num_iterations)\n","    for i in range(num_iterations):\n","\n","        print(\"Pruning and Finetuning {}/{}\".format(i + 1, num_iterations))\n","\n","        print(\"Pruning...\")\n","\n","        if grouped_pruning == True:\n","            \n","            parameters_to_prune = []\n","            for module_name, module in model.named_modules():\n","                if isinstance(module, torch.nn.Conv2d):\n","                    parameters_to_prune.append((module, \"weight\"))\n","            prune.global_unstructured(\n","                parameters_to_prune,\n","                pruning_method=prune.L1Unstructured,\n","                amount=conv2d_one_iter_prune_amount,\n","            )\n","        else:\n","            for module_name, module in model.named_modules():\n","                if isinstance(module, torch.nn.Conv2d):\n","                    prune.l1_unstructured(module,\n","                                          name=\"weight\",\n","                                          amount=conv2d_one_iter_prune_amount)\n","                elif isinstance(module, torch.nn.Linear):\n","                    prune.l1_unstructured(module,\n","                                          name=\"weight\",\n","                                          amount=linear_one_iter_prune_amount)\n","\n","        _, eval_accuracy = evaluate_model(model=model,\n","                                          test_loader=test_loader,\n","                                          device=device,\n","                                          criterion=None)\n","\n","        classification_report = create_classification_report(\n","            model=model, test_loader=test_loader, device=device)\n","\n","        num_zeros, num_elements, sparsity = measure_global_sparsity(\n","            model,\n","            weight=True,\n","            bias=False,\n","            conv2d_use_mask=True,\n","            linear_use_mask=False)\n","\n","        print(\"Test Accuracy: {:.3f}\".format(eval_accuracy))\n","        print(\"Classification Report:\")\n","        print(classification_report)\n","        print(\"Global Sparsity:\")\n","        print(\"{:.2f}\".format(sparsity))\n","\n","        # print(model.conv1._forward_pre_hooks)\n","        \n","        if (i >= (num_iterations * 2/3)) and (num_iterations >= 3):\n","            cur_num_epochs_per_iter = num_epochs_per_iteration * 3/2\n","        else:\n","            cur_num_epochs_per_iter = num_epochs_per_iteration\n","\n","        print(\"Fine-tuning...\")\n","\n","        train_model(model=model,\n","                    train_loader=train_loader,\n","                    test_loader=test_loader,\n","                    device=device,\n","                    model_dir=model_dir,\n","                    model_filename=\"{}_iter{}\".format(model_filename_prefix, i + 1),\n","                    l1_regularization_strength=l1_regularization_strength,\n","                    l2_regularization_strength=l2_regularization_strength,\n","                    weight_decay=weight_decay,\n","                    learning_rate=learning_rate * (learning_rate_decay**i),\n","                    num_epochs=cur_num_epochs_per_iter)\n","        \n","\n","        _, eval_accuracy = evaluate_model(model=model,\n","                                          test_loader=test_loader,\n","                                          device=device,\n","                                          criterion=None)\n","\n","        classification_report = create_classification_report(\n","            model=model, test_loader=test_loader, device=device)\n","\n","        num_zeros, num_elements, sparsity = measure_global_sparsity(\n","            model,\n","            weight=True,\n","            bias=False,\n","            conv2d_use_mask=True,\n","            linear_use_mask=False)\n","\n","        print(\"Test Accuracy: {:.3f}\".format(eval_accuracy))\n","        print(\"Classification Report:\")\n","        print(classification_report)\n","        print(\"Global Sparsity:\")\n","        print(\"{:.2f}\".format(sparsity))\n","\n","        model_filename = \"{}_{}.pt\".format(model_filename_prefix, i + 1)\n","        model_filepath = os.path.join(model_dir, model_filename)\n","        save_model(model=model,\n","                   model_dir=model_dir,\n","                   model_filename=model_filename)\n","        \n","        model = load_model(model=model,\n","                           model_filepath=model_filepath,\n","                           device=device)\n","        torch.cuda.empty_cache()\n","        \n","\n","    return model\n","\n","\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:25:01.494199Z","iopub.status.busy":"2024-03-30T12:25:01.493494Z","iopub.status.idle":"2024-03-30T12:25:01.500653Z","shell.execute_reply":"2024-03-30T12:25:01.499643Z","shell.execute_reply.started":"2024-03-30T12:25:01.494166Z"},"trusted":true},"outputs":[],"source":["def remove_parameters(model):\n","\n","    for module_name, module in model.named_modules():\n","        if isinstance(module, torch.nn.Conv2d):\n","            try:\n","                prune.remove(module, \"weight\")\n","            except:\n","                pass\n","            try:\n","                prune.remove(module, \"bias\")\n","            except:\n","                pass\n","        elif isinstance(module, torch.nn.Linear):\n","            try:\n","                prune.remove(module, \"weight\")\n","            except:\n","                pass\n","            try:\n","                prune.remove(module, \"bias\")\n","            except:\n","                pass\n","\n","    return model"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:25:02.093660Z","iopub.status.busy":"2024-03-30T12:25:02.092985Z","iopub.status.idle":"2024-03-30T12:25:02.100233Z","shell.execute_reply":"2024-03-30T12:25:02.099183Z","shell.execute_reply.started":"2024-03-30T12:25:02.093626Z"},"trusted":true},"outputs":[],"source":["import torch.nn.utils.prune as prune"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:25:31.514211Z","iopub.status.busy":"2024-03-30T12:25:31.513390Z","iopub.status.idle":"2024-03-30T12:25:31.518608Z","shell.execute_reply":"2024-03-30T12:25:31.517442Z","shell.execute_reply.started":"2024-03-30T12:25:31.514178Z"},"trusted":true},"outputs":[],"source":["model_dir = \"saved_models\"\n","model_filename_prefix = \"pruned_model\"\n","pruned_model_filename = \"resnet34_acc0.96_prunedto0.95_cifar10.pt\"\n","pruned_model_filepath = os.path.join(model_dir, pruned_model_filename)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:25:41.273864Z","iopub.status.busy":"2024-03-30T12:25:41.273038Z","iopub.status.idle":"2024-03-30T12:25:41.277702Z","shell.execute_reply":"2024-03-30T12:25:41.276668Z","shell.execute_reply.started":"2024-03-30T12:25:41.273833Z"},"trusted":true},"outputs":[],"source":["model_filepath = \"/kaggle/input/resnet34-for-cifar10/pytorch/resnet34_accuracy0.96/1/resnet34_96_epoch20 (1)\""]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:25:41.974711Z","iopub.status.busy":"2024-03-30T12:25:41.973875Z","iopub.status.idle":"2024-03-30T12:25:41.979226Z","shell.execute_reply":"2024-03-30T12:25:41.978142Z","shell.execute_reply.started":"2024-03-30T12:25:41.974674Z"},"trusted":true},"outputs":[],"source":["num_classes = 10\n","random_seed = 1\n","l1_regularization_strength = 0\n","l2_regularization_strength = 0\n","weight_decay = 5e-4\n","learning_rate = 3e-4\n","learning_rate_decay = 1"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:25:44.022683Z","iopub.status.busy":"2024-03-30T12:25:44.022332Z","iopub.status.idle":"2024-03-30T12:25:44.027235Z","shell.execute_reply":"2024-03-30T12:25:44.026147Z","shell.execute_reply.started":"2024-03-30T12:25:44.022655Z"},"trusted":true},"outputs":[],"source":["mean = (0.4914, 0.4822, 0.4466) # CIFAR10 train mean\n","std = (0.2412, 0.2377, 0.2563) # CIRAR10 train std"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:25:47.799687Z","iopub.status.busy":"2024-03-30T12:25:47.798999Z","iopub.status.idle":"2024-03-30T12:25:47.806965Z","shell.execute_reply":"2024-03-30T12:25:47.806181Z","shell.execute_reply.started":"2024-03-30T12:25:47.799653Z"},"trusted":true},"outputs":[],"source":["cuda_device = torch.device(\"cuda:0\")\n","cpu_device = torch.device(\"cpu:0\")"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:25:49.392523Z","iopub.status.busy":"2024-03-30T12:25:49.391891Z","iopub.status.idle":"2024-03-30T12:25:49.424517Z","shell.execute_reply":"2024-03-30T12:25:49.423528Z","shell.execute_reply.started":"2024-03-30T12:25:49.392487Z"},"trusted":true},"outputs":[{"data":{"text/plain":["True"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:25:50.599093Z","iopub.status.busy":"2024-03-30T12:25:50.598392Z","iopub.status.idle":"2024-03-30T12:25:50.606269Z","shell.execute_reply":"2024-03-30T12:25:50.605329Z","shell.execute_reply.started":"2024-03-30T12:25:50.599060Z"},"trusted":true},"outputs":[],"source":["set_random_seeds(random_seed=random_seed)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:25:51.959846Z","iopub.status.busy":"2024-03-30T12:25:51.959303Z","iopub.status.idle":"2024-03-30T12:25:54.166687Z","shell.execute_reply":"2024-03-30T12:25:54.165872Z","shell.execute_reply.started":"2024-03-30T12:25:51.959807Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]}],"source":["model = create_model(num_classes=num_classes)\n","\n","\n","model = load_model(model=model,\n","                    model_filepath=model_filepath,\n","                    device=cuda_device) # cuda_device!!!"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:25:55.647386Z","iopub.status.busy":"2024-03-30T12:25:55.646944Z","iopub.status.idle":"2024-03-30T12:25:55.651778Z","shell.execute_reply":"2024-03-30T12:25:55.650720Z","shell.execute_reply.started":"2024-03-30T12:25:55.647356Z"},"trusted":true},"outputs":[],"source":["#torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:25:56.072481Z","iopub.status.busy":"2024-03-30T12:25:56.071667Z","iopub.status.idle":"2024-03-30T12:25:56.076194Z","shell.execute_reply":"2024-03-30T12:25:56.075172Z","shell.execute_reply.started":"2024-03-30T12:25:56.072446Z"},"trusted":true},"outputs":[],"source":["#!nvidia-smi"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:25:58.072221Z","iopub.status.busy":"2024-03-30T12:25:58.071878Z","iopub.status.idle":"2024-03-30T12:26:07.885100Z","shell.execute_reply":"2024-03-30T12:26:07.884180Z","shell.execute_reply.started":"2024-03-30T12:25:58.072195Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 170498071/170498071 [00:05<00:00, 28831750.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data/cifar-10-python.tar.gz to data\n","Files already downloaded and verified\n"]}],"source":["train_loader, test_loader, classes = prepare_dataloader(\n","        num_workers=0, train_batch_size=128, eval_batch_size=128, mean=mean, stdev=std)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:26:09.721343Z","iopub.status.busy":"2024-03-30T12:26:09.720415Z","iopub.status.idle":"2024-03-30T12:26:10.769069Z","shell.execute_reply":"2024-03-30T12:26:10.767903Z","shell.execute_reply.started":"2024-03-30T12:26:09.721303Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Sat Mar 30 12:26:10 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0              32W / 250W |    364MiB / 16384MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:26:22.586523Z","iopub.status.busy":"2024-03-30T12:26:22.586143Z","iopub.status.idle":"2024-03-30T12:26:22.591383Z","shell.execute_reply":"2024-03-30T12:26:22.590329Z","shell.execute_reply.started":"2024-03-30T12:26:22.586488Z"},"trusted":true},"outputs":[],"source":["#torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:26:22.968310Z","iopub.status.busy":"2024-03-30T12:26:22.967896Z","iopub.status.idle":"2024-03-30T12:26:22.972752Z","shell.execute_reply":"2024-03-30T12:26:22.971558Z","shell.execute_reply.started":"2024-03-30T12:26:22.968280Z"},"trusted":true},"outputs":[],"source":["#!nvidia-smi"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:26:23.839277Z","iopub.status.busy":"2024-03-30T12:26:23.838620Z","iopub.status.idle":"2024-03-30T12:26:23.845316Z","shell.execute_reply":"2024-03-30T12:26:23.844342Z","shell.execute_reply.started":"2024-03-30T12:26:23.839244Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'\\n_, eval_accuracy = evaluate_model(model=model,\\n                                    test_loader=test_loader,\\n                                    device=cuda_device,\\n                                    criterion=None)\\n'"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","_, eval_accuracy = evaluate_model(model=model,\n","                                    test_loader=test_loader,\n","                                    device=cuda_device,\n","                                    criterion=None)\n","\"\"\""]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:26:25.446906Z","iopub.status.busy":"2024-03-30T12:26:25.446557Z","iopub.status.idle":"2024-03-30T12:26:25.452947Z","shell.execute_reply":"2024-03-30T12:26:25.451919Z","shell.execute_reply.started":"2024-03-30T12:26:25.446878Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'\\nclassification_report = create_classification_report(\\n        model=model, test_loader=test_loader, device=cuda_device)\\n'"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","classification_report = create_classification_report(\n","        model=model, test_loader=test_loader, device=cuda_device)\n","\"\"\""]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:26:26.647078Z","iopub.status.busy":"2024-03-30T12:26:26.646429Z","iopub.status.idle":"2024-03-30T12:26:26.652874Z","shell.execute_reply":"2024-03-30T12:26:26.651865Z","shell.execute_reply.started":"2024-03-30T12:26:26.647049Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'\\nnum_zeros, num_elements, sparsity = measure_global_sparsity(model)\\n\\nprint(\"Test Accuracy: {:.3f}\".format(eval_accuracy))\\nprint(\"Classification Report:\")\\nprint(classification_report)\\nprint(\"Global Sparsity:\")\\nprint(\"{:.2f}\".format(sparsity))\\n'"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","num_zeros, num_elements, sparsity = measure_global_sparsity(model)\n","\n","print(\"Test Accuracy: {:.3f}\".format(eval_accuracy))\n","print(\"Classification Report:\")\n","print(classification_report)\n","print(\"Global Sparsity:\")\n","print(\"{:.2f}\".format(sparsity))\n","\"\"\""]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:26:27.630828Z","iopub.status.busy":"2024-03-30T12:26:27.630479Z","iopub.status.idle":"2024-03-30T12:26:27.694231Z","shell.execute_reply":"2024-03-30T12:26:27.693250Z","shell.execute_reply.started":"2024-03-30T12:26:27.630802Z"},"trusted":true},"outputs":[],"source":["pruned_model = copy.deepcopy(model)"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:26:28.576762Z","iopub.status.busy":"2024-03-30T12:26:28.576389Z","iopub.status.idle":"2024-03-30T12:26:28.639360Z","shell.execute_reply":"2024-03-30T12:26:28.638453Z","shell.execute_reply.started":"2024-03-30T12:26:28.576732Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.0\n"]}],"source":["num_zeros, num_elements, sparsity = measure_global_sparsity(pruned_model)\n","print(sparsity)"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:26:31.618443Z","iopub.status.busy":"2024-03-30T12:26:31.617465Z","iopub.status.idle":"2024-03-30T12:26:32.626931Z","shell.execute_reply":"2024-03-30T12:26:32.625970Z","shell.execute_reply.started":"2024-03-30T12:26:31.618401Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Sat Mar 30 12:26:32 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0              32W / 250W |    364MiB / 16384MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:26:38.285288Z","iopub.status.busy":"2024-03-30T12:26:38.284891Z","iopub.status.idle":"2024-03-30T12:26:38.289944Z","shell.execute_reply":"2024-03-30T12:26:38.288986Z","shell.execute_reply.started":"2024-03-30T12:26:38.285253Z"},"trusted":true},"outputs":[],"source":["#torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:26:38.727395Z","iopub.status.busy":"2024-03-30T12:26:38.727016Z","iopub.status.idle":"2024-03-30T12:26:38.735142Z","shell.execute_reply":"2024-03-30T12:26:38.734186Z","shell.execute_reply.started":"2024-03-30T12:26:38.727366Z"},"trusted":true},"outputs":[],"source":["#!nvidia-smi"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:26:39.786281Z","iopub.status.busy":"2024-03-30T12:26:39.785903Z","iopub.status.idle":"2024-03-30T12:26:39.797560Z","shell.execute_reply":"2024-03-30T12:26:39.796676Z","shell.execute_reply.started":"2024-03-30T12:26:39.786252Z"},"trusted":true},"outputs":[{"data":{"text/plain":["False"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["next(pruned_model.parameters()).is_cuda"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:26:40.975551Z","iopub.status.busy":"2024-03-30T12:26:40.974619Z","iopub.status.idle":"2024-03-30T12:26:41.010481Z","shell.execute_reply":"2024-03-30T12:26:41.009583Z","shell.execute_reply.started":"2024-03-30T12:26:40.975515Z"},"trusted":true},"outputs":[],"source":["pruned_model.to(cuda_device);"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:26:44.232244Z","iopub.status.busy":"2024-03-30T12:26:44.231877Z","iopub.status.idle":"2024-03-30T12:26:44.238557Z","shell.execute_reply":"2024-03-30T12:26:44.237620Z","shell.execute_reply.started":"2024-03-30T12:26:44.232214Z"},"trusted":true},"outputs":[{"data":{"text/plain":["True"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["next(pruned_model.parameters()).is_cuda"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:26:45.968944Z","iopub.status.busy":"2024-03-30T12:26:45.968613Z","iopub.status.idle":"2024-03-30T12:26:46.989819Z","shell.execute_reply":"2024-03-30T12:26:46.988532Z","shell.execute_reply.started":"2024-03-30T12:26:45.968919Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Sat Mar 30 12:26:46 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0              32W / 250W |    364MiB / 16384MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:24:20.174310Z","iopub.status.idle":"2024-03-29T12:24:20.174707Z","shell.execute_reply":"2024-03-29T12:24:20.174542Z","shell.execute_reply.started":"2024-03-29T12:24:20.174526Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:26:54.188733Z","iopub.status.busy":"2024-03-30T12:26:54.188340Z","iopub.status.idle":"2024-03-30T15:58:29.695574Z","shell.execute_reply":"2024-03-30T15:58:29.693723Z","shell.execute_reply.started":"2024-03-30T12:26:54.188697Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Pruning...\n","Pruning and Finetuning 1/1\n","Pruning...\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.100\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00      1000\n","           1       0.00      0.00      0.00      1000\n","           2       0.00      0.00      0.00      1000\n","           3       0.10      1.00      0.18      1000\n","           4       0.00      0.00      0.00      1000\n","           5       0.00      0.00      0.00      1000\n","           6       0.00      0.00      0.00      1000\n","           7       0.00      0.00      0.00      1000\n","           8       0.00      0.00      0.00      1000\n","           9       0.00      0.00      0.00      1000\n","\n","    accuracy                           0.10     10000\n","   macro avg       0.01      0.10      0.02     10000\n","weighted avg       0.01      0.10      0.02     10000\n","\n","Global Sparsity:\n","0.95\n","Fine-tuning...\n","Epoch: 000 Eval Loss: 20.971 Eval Acc: 0.100\n","Epoch: 001 Train Loss: 0.541 Train Acc: 0.820 Eval Loss: 0.248 Eval Acc: 0.916\n","Epoch: 002 Train Loss: 0.291 Train Acc: 0.900 Eval Loss: 0.188 Eval Acc: 0.937\n","Epoch: 003 Train Loss: 0.224 Train Acc: 0.923 Eval Loss: 0.178 Eval Acc: 0.939\n","Epoch: 004 Train Loss: 0.190 Train Acc: 0.934 Eval Loss: 0.171 Eval Acc: 0.941\n","Epoch: 005 Train Loss: 0.171 Train Acc: 0.941 Eval Loss: 0.171 Eval Acc: 0.942\n","Epoch: 006 Train Loss: 0.156 Train Acc: 0.946 Eval Loss: 0.182 Eval Acc: 0.941\n","Epoch: 007 Train Loss: 0.151 Train Acc: 0.949 Eval Loss: 0.171 Eval Acc: 0.947\n","Epoch: 008 Train Loss: 0.144 Train Acc: 0.951 Eval Loss: 0.179 Eval Acc: 0.946\n","Epoch: 009 Train Loss: 0.131 Train Acc: 0.955 Eval Loss: 0.161 Eval Acc: 0.948\n","Epoch: 010 Train Loss: 0.133 Train Acc: 0.954 Eval Loss: 0.164 Eval Acc: 0.947\n","Epoch: 011 Train Loss: 0.127 Train Acc: 0.957 Eval Loss: 0.174 Eval Acc: 0.946\n","Epoch: 012 Train Loss: 0.128 Train Acc: 0.956 Eval Loss: 0.175 Eval Acc: 0.946\n","Epoch: 013 Train Loss: 0.120 Train Acc: 0.960 Eval Loss: 0.181 Eval Acc: 0.942\n","Epoch: 014 Train Loss: 0.122 Train Acc: 0.959 Eval Loss: 0.181 Eval Acc: 0.944\n","Epoch: 015 Train Loss: 0.121 Train Acc: 0.959 Eval Loss: 0.177 Eval Acc: 0.946\n","Epoch: 016 Train Loss: 0.116 Train Acc: 0.960 Eval Loss: 0.173 Eval Acc: 0.942\n","Epoch: 017 Train Loss: 0.117 Train Acc: 0.961 Eval Loss: 0.173 Eval Acc: 0.950\n","Epoch: 018 Train Loss: 0.116 Train Acc: 0.961 Eval Loss: 0.177 Eval Acc: 0.945\n","Epoch: 019 Train Loss: 0.121 Train Acc: 0.959 Eval Loss: 0.172 Eval Acc: 0.945\n","Epoch: 020 Train Loss: 0.112 Train Acc: 0.962 Eval Loss: 0.176 Eval Acc: 0.943\n","Epoch: 021 Train Loss: 0.114 Train Acc: 0.962 Eval Loss: 0.222 Eval Acc: 0.931\n","Epoch: 022 Train Loss: 0.114 Train Acc: 0.963 Eval Loss: 0.175 Eval Acc: 0.944\n","Epoch: 023 Train Loss: 0.116 Train Acc: 0.962 Eval Loss: 0.168 Eval Acc: 0.945\n","Epoch: 024 Train Loss: 0.115 Train Acc: 0.962 Eval Loss: 0.179 Eval Acc: 0.946\n","Epoch: 025 Train Loss: 0.111 Train Acc: 0.962 Eval Loss: 0.203 Eval Acc: 0.937\n","Epoch: 026 Train Loss: 0.117 Train Acc: 0.962 Eval Loss: 0.185 Eval Acc: 0.943\n","Epoch: 027 Train Loss: 0.115 Train Acc: 0.962 Eval Loss: 0.179 Eval Acc: 0.946\n","Epoch: 028 Train Loss: 0.110 Train Acc: 0.964 Eval Loss: 0.172 Eval Acc: 0.945\n","Epoch: 029 Train Loss: 0.118 Train Acc: 0.961 Eval Loss: 0.171 Eval Acc: 0.947\n","Epoch: 030 Train Loss: 0.111 Train Acc: 0.963 Eval Loss: 0.187 Eval Acc: 0.944\n","Epoch: 031 Train Loss: 0.083 Train Acc: 0.973 Eval Loss: 0.140 Eval Acc: 0.958\n","Epoch: 032 Train Loss: 0.071 Train Acc: 0.977 Eval Loss: 0.135 Eval Acc: 0.958\n","Epoch: 033 Train Loss: 0.068 Train Acc: 0.978 Eval Loss: 0.134 Eval Acc: 0.959\n","Epoch: 034 Train Loss: 0.063 Train Acc: 0.980 Eval Loss: 0.131 Eval Acc: 0.961\n","Epoch: 035 Train Loss: 0.063 Train Acc: 0.979 Eval Loss: 0.129 Eval Acc: 0.960\n","Epoch: 036 Train Loss: 0.061 Train Acc: 0.980 Eval Loss: 0.130 Eval Acc: 0.961\n","Epoch: 037 Train Loss: 0.060 Train Acc: 0.980 Eval Loss: 0.126 Eval Acc: 0.961\n","Epoch: 038 Train Loss: 0.057 Train Acc: 0.982 Eval Loss: 0.127 Eval Acc: 0.961\n","Epoch: 039 Train Loss: 0.058 Train Acc: 0.981 Eval Loss: 0.128 Eval Acc: 0.961\n","Epoch: 040 Train Loss: 0.055 Train Acc: 0.982 Eval Loss: 0.130 Eval Acc: 0.961\n","Epoch: 041 Train Loss: 0.058 Train Acc: 0.981 Eval Loss: 0.129 Eval Acc: 0.960\n","Epoch: 042 Train Loss: 0.055 Train Acc: 0.983 Eval Loss: 0.130 Eval Acc: 0.960\n","Epoch: 043 Train Loss: 0.057 Train Acc: 0.981 Eval Loss: 0.128 Eval Acc: 0.961\n","Epoch: 044 Train Loss: 0.054 Train Acc: 0.982 Eval Loss: 0.128 Eval Acc: 0.962\n","Epoch: 045 Train Loss: 0.053 Train Acc: 0.982 Eval Loss: 0.124 Eval Acc: 0.963\n","Epoch: 046 Train Loss: 0.055 Train Acc: 0.982 Eval Loss: 0.126 Eval Acc: 0.961\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[49], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPruning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43miterative_pruning_finetuning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpruned_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcuda_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_regularization_strength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml1_regularization_strength\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml2_regularization_strength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml2_regularization_strength\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconv2d_prune_amount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinear_prune_amount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# такое число итераций\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs_per_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m70\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# и эпох из-за ограничений по времени \u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_filename_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_filename_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrouped_pruning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[18], line 79\u001b[0m, in \u001b[0;36miterative_pruning_finetuning\u001b[0;34m(model, train_loader, test_loader, device, learning_rate, l1_regularization_strength, l2_regularization_strength, weight_decay, learning_rate_decay, conv2d_prune_amount, linear_prune_amount, num_iterations, num_epochs_per_iteration, model_filename_prefix, model_dir, grouped_pruning)\u001b[0m\n\u001b[1;32m     75\u001b[0m     cur_num_epochs_per_iter \u001b[38;5;241m=\u001b[39m num_epochs_per_iteration\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFine-tuning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_iter\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_filename_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m            \u001b[49m\u001b[43ml1_regularization_strength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml1_regularization_strength\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m            \u001b[49m\u001b[43ml2_regularization_strength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml2_regularization_strength\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate_decay\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_num_epochs_per_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m _, eval_accuracy \u001b[38;5;241m=\u001b[39m evaluate_model(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     93\u001b[0m                                   test_loader\u001b[38;5;241m=\u001b[39mtest_loader,\n\u001b[1;32m     94\u001b[0m                                   device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     95\u001b[0m                                   criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     97\u001b[0m classification_report \u001b[38;5;241m=\u001b[39m create_classification_report(\n\u001b[1;32m     98\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel, test_loader\u001b[38;5;241m=\u001b[39mtest_loader, device\u001b[38;5;241m=\u001b[39mdevice)\n","Cell \u001b[0;32mIn[10], line 92\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, device, model_dir, model_filename, l1_regularization_strength, l2_regularization_strength, weight_decay, learning_rate, num_epochs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n\u001b[1;32m     91\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 92\u001b[0m eval_loss, eval_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m40\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     97\u001b[0m     save_model(model\u001b[38;5;241m=\u001b[39mmodel, model_dir\u001b[38;5;241m=\u001b[39mmodel_dir, model_filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_epoch\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model_filename, epoch))\n","Cell \u001b[0;32mIn[13], line 9\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, test_loader, device, criterion)\u001b[0m\n\u001b[1;32m      6\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      7\u001b[0m running_corrects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m     11\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["print(\"Pruning...\")\n","iterative_pruning_finetuning(\n","        model=pruned_model,\n","        train_loader=train_loader,\n","        test_loader=test_loader,\n","        device=cuda_device,\n","        learning_rate=learning_rate,\n","        learning_rate_decay=learning_rate_decay,\n","        l1_regularization_strength=l1_regularization_strength,\n","        l2_regularization_strength=l2_regularization_strength,\n","        weight_decay=weight_decay,\n","        conv2d_prune_amount=0.95,\n","        linear_prune_amount=0,\n","        num_iterations=1,            \n","        num_epochs_per_iteration=70, \n","        model_filename_prefix=model_filename_prefix,\n","        model_dir=model_dir,\n","        grouped_pruning=True)"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T16:01:06.251688Z","iopub.status.busy":"2024-03-30T16:01:06.251050Z","iopub.status.idle":"2024-03-30T16:01:07.270160Z","shell.execute_reply":"2024-03-30T16:01:07.269181Z","shell.execute_reply.started":"2024-03-30T16:01:06.251655Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Sat Mar 30 16:01:07 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P0              34W / 250W |   6838MiB / 16384MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi\n"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T16:01:02.116917Z","iopub.status.busy":"2024-03-30T16:01:02.116507Z","iopub.status.idle":"2024-03-30T16:01:02.171796Z","shell.execute_reply":"2024-03-30T16:01:02.170718Z","shell.execute_reply.started":"2024-03-30T16:01:02.116884Z"},"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:24:20.179404Z","iopub.status.idle":"2024-03-29T12:24:20.179790Z","shell.execute_reply":"2024-03-29T12:24:20.179622Z","shell.execute_reply.started":"2024-03-29T12:24:20.179606Z"},"trusted":true},"outputs":[],"source":["pruned_model"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T16:07:11.949199Z","iopub.status.busy":"2024-03-30T16:07:11.948585Z","iopub.status.idle":"2024-03-30T16:07:12.177197Z","shell.execute_reply":"2024-03-30T16:07:12.176197Z","shell.execute_reply.started":"2024-03-30T16:07:11.949168Z"},"trusted":true},"outputs":[],"source":["save_model(model=pruned_model, model_dir=\"saved_models\", model_filename=\"trained_prune_rate0.95_accuracy0.961_with_masks\")"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T16:05:16.240836Z","iopub.status.busy":"2024-03-30T16:05:16.239806Z","iopub.status.idle":"2024-03-30T16:05:37.652816Z","shell.execute_reply":"2024-03-30T16:05:37.651852Z","shell.execute_reply.started":"2024-03-30T16:05:16.240797Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.97      0.97      0.97      1000\n","           1       0.97      0.98      0.98      1000\n","           2       0.96      0.95      0.95      1000\n","           3       0.93      0.90      0.92      1000\n","           4       0.96      0.97      0.97      1000\n","           5       0.92      0.94      0.93      1000\n","           6       0.96      0.99      0.97      1000\n","           7       0.98      0.98      0.98      1000\n","           8       0.98      0.98      0.98      1000\n","           9       0.98      0.97      0.97      1000\n","\n","    accuracy                           0.96     10000\n","   macro avg       0.96      0.96      0.96     10000\n","weighted avg       0.96      0.96      0.96     10000\n","\n"]}],"source":["classification_report = create_classification_report(\n","        model=pruned_model, test_loader=test_loader, device=cuda_device)\n","print(classification_report)"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T16:05:45.621511Z","iopub.status.busy":"2024-03-30T16:05:45.620774Z","iopub.status.idle":"2024-03-30T16:05:45.634446Z","shell.execute_reply":"2024-03-30T16:05:45.633570Z","shell.execute_reply.started":"2024-03-30T16:05:45.621468Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.97      0.97      1000\n","           1       0.97      0.98      0.98      1000\n","           2       0.96      0.95      0.95      1000\n","           3       0.93      0.90      0.92      1000\n","           4       0.96      0.97      0.97      1000\n","           5       0.92      0.94      0.93      1000\n","           6       0.96      0.99      0.97      1000\n","           7       0.98      0.98      0.98      1000\n","           8       0.98      0.98      0.98      1000\n","           9       0.98      0.97      0.97      1000\n","\n","    accuracy                           0.96     10000\n","   macro avg       0.96      0.96      0.96     10000\n","weighted avg       0.96      0.96      0.96     10000\n","\n","Global Sparsity:\n","0.9498\n"]}],"source":["num_zeros, num_elements, sparsity = measure_global_sparsity(pruned_model, conv2d_use_mask=True)\n","\n","#print(\"Test Accuracy: {:.3f}\".format(eval_accuracy))\n","print(\"Classification Report:\")\n","print(classification_report)\n","print(\"Global Sparsity:\")\n","print(\"{:.4f}\".format(sparsity))"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T16:15:23.010274Z","iopub.status.busy":"2024-03-30T16:15:23.009821Z","iopub.status.idle":"2024-03-30T16:15:23.027202Z","shell.execute_reply":"2024-03-30T16:15:23.026214Z","shell.execute_reply.started":"2024-03-30T16:15:23.010231Z"},"trusted":true},"outputs":[],"source":["\n","def train_model_another_mils(model,\n","                train_loader,\n","                test_loader,\n","                device,\n","                model_dir,\n","                model_filename,\n","                l1_regularization_strength=0,\n","                l2_regularization_strength=0,\n","                weight_decay=5e-4,\n","                learning_rate=1e-4,\n","                num_epochs=200\n","                ):\n","\n","   \n","\n","    criterion = nn.CrossEntropyLoss()\n","\n","    model.to(device)\n","\n","    \n","    #optimizer = optim.SGD(model.parameters(),\n","    #                      lr=learning_rate,\n","    #                      momentum=0.9,\n","    #                      weight_decay=l2_regularization_strength)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=500)\n","    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n","                                                     milestones=[num_epochs/6, num_epochs*2/3],\n","                                                     gamma=0.1,\n","                                                     last_epoch=-1)\n","    # optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n","\n","    # Evaluation\n","    model.eval()\n","    eval_loss, eval_accuracy = evaluate_model(model=model,\n","                                              test_loader=test_loader,\n","                                              device=device,\n","                                              criterion=criterion)\n","    print(\"Epoch: {:03d} Eval Loss: {:.3f} Eval Acc: {:.3f}\".format(\n","        0, eval_loss, eval_accuracy))\n","\n","    for epoch in range(num_epochs):\n","\n","        # Training\n","        model.train()\n","\n","        running_loss = 0\n","        running_corrects = 0\n","\n","        for inputs, labels in train_loader:\n","\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward + backward + optimize\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","            loss = criterion(outputs, labels)\n","\n","            l1_reg = torch.tensor(0.).to(device)\n","            for module in model.modules():\n","                mask = None\n","                weight = None\n","                for name, buffer in module.named_buffers():\n","                    if name == \"weight_mask\":\n","                        mask = buffer\n","                for name, param in module.named_parameters():\n","                    if name == \"weight_orig\":\n","                        weight = param\n","                if mask is not None and weight is not None:\n","                    l1_reg += torch.norm(mask * weight, 1)\n","\n","            loss += l1_regularization_strength * l1_reg \n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            # statistics\n","            running_loss += loss.item() * inputs.size(0)\n","            running_corrects += torch.sum(preds == labels.data)\n","\n","        train_loss = running_loss / len(train_loader.dataset)\n","        train_accuracy = running_corrects / len(train_loader.dataset)\n","\n","        # Evaluation\n","        model.eval()\n","        eval_loss, eval_accuracy = evaluate_model(model=model,\n","                                                  test_loader=test_loader,\n","                                                  device=device,\n","                                                  criterion=criterion)\n","        if epoch % 40 == 0:\n","            save_model(model=model, model_dir=model_dir, model_filename=\"{}_epoch{}\".format(model_filename, epoch))\n","\n","        scheduler.step()\n","\n","        print(\n","            \"Epoch: {:03d} Train Loss: {:.3f} Train Acc: {:.3f} Eval Loss: {:.3f} Eval Acc: {:.3f}\"\n","            .format(epoch + 1, train_loss, train_accuracy, eval_loss,\n","                    eval_accuracy))\n","        #torch.cuda.empty_cache()\n","\n","    return model"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T16:24:48.204176Z","iopub.status.busy":"2024-03-30T16:24:48.203488Z","iopub.status.idle":"2024-03-30T18:40:21.116654Z","shell.execute_reply":"2024-03-30T18:40:21.115688Z","shell.execute_reply.started":"2024-03-30T16:24:48.204140Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 000 Eval Loss: 0.124 Eval Acc: 0.962\n","Epoch: 001 Train Loss: 0.051 Train Acc: 0.983 Eval Loss: 0.124 Eval Acc: 0.961\n","Epoch: 002 Train Loss: 0.050 Train Acc: 0.983 Eval Loss: 0.124 Eval Acc: 0.961\n","Epoch: 003 Train Loss: 0.052 Train Acc: 0.983 Eval Loss: 0.126 Eval Acc: 0.961\n","Epoch: 004 Train Loss: 0.051 Train Acc: 0.983 Eval Loss: 0.127 Eval Acc: 0.961\n","Epoch: 005 Train Loss: 0.052 Train Acc: 0.983 Eval Loss: 0.122 Eval Acc: 0.962\n","Epoch: 006 Train Loss: 0.052 Train Acc: 0.983 Eval Loss: 0.129 Eval Acc: 0.959\n","Epoch: 007 Train Loss: 0.050 Train Acc: 0.984 Eval Loss: 0.123 Eval Acc: 0.961\n","Epoch: 008 Train Loss: 0.050 Train Acc: 0.984 Eval Loss: 0.128 Eval Acc: 0.960\n","Epoch: 009 Train Loss: 0.051 Train Acc: 0.983 Eval Loss: 0.123 Eval Acc: 0.961\n","Epoch: 010 Train Loss: 0.050 Train Acc: 0.984 Eval Loss: 0.122 Eval Acc: 0.961\n","Epoch: 011 Train Loss: 0.050 Train Acc: 0.984 Eval Loss: 0.123 Eval Acc: 0.962\n","Epoch: 012 Train Loss: 0.047 Train Acc: 0.985 Eval Loss: 0.121 Eval Acc: 0.961\n","Epoch: 013 Train Loss: 0.049 Train Acc: 0.984 Eval Loss: 0.121 Eval Acc: 0.962\n","Epoch: 014 Train Loss: 0.049 Train Acc: 0.984 Eval Loss: 0.124 Eval Acc: 0.962\n","Epoch: 015 Train Loss: 0.050 Train Acc: 0.983 Eval Loss: 0.123 Eval Acc: 0.961\n","Epoch: 016 Train Loss: 0.048 Train Acc: 0.984 Eval Loss: 0.122 Eval Acc: 0.961\n","Epoch: 017 Train Loss: 0.049 Train Acc: 0.984 Eval Loss: 0.121 Eval Acc: 0.962\n","Epoch: 018 Train Loss: 0.049 Train Acc: 0.984 Eval Loss: 0.118 Eval Acc: 0.963\n","Epoch: 019 Train Loss: 0.048 Train Acc: 0.984 Eval Loss: 0.123 Eval Acc: 0.962\n","Epoch: 020 Train Loss: 0.050 Train Acc: 0.984 Eval Loss: 0.126 Eval Acc: 0.961\n","Epoch: 021 Train Loss: 0.048 Train Acc: 0.985 Eval Loss: 0.125 Eval Acc: 0.962\n","Epoch: 022 Train Loss: 0.046 Train Acc: 0.986 Eval Loss: 0.121 Eval Acc: 0.962\n","Epoch: 023 Train Loss: 0.045 Train Acc: 0.986 Eval Loss: 0.121 Eval Acc: 0.962\n","Epoch: 024 Train Loss: 0.046 Train Acc: 0.985 Eval Loss: 0.124 Eval Acc: 0.962\n","Epoch: 025 Train Loss: 0.047 Train Acc: 0.985 Eval Loss: 0.125 Eval Acc: 0.962\n","Epoch: 026 Train Loss: 0.047 Train Acc: 0.984 Eval Loss: 0.122 Eval Acc: 0.964\n","Epoch: 027 Train Loss: 0.045 Train Acc: 0.985 Eval Loss: 0.125 Eval Acc: 0.962\n","Epoch: 028 Train Loss: 0.046 Train Acc: 0.986 Eval Loss: 0.120 Eval Acc: 0.962\n","Epoch: 029 Train Loss: 0.045 Train Acc: 0.985 Eval Loss: 0.122 Eval Acc: 0.963\n","Epoch: 030 Train Loss: 0.048 Train Acc: 0.985 Eval Loss: 0.123 Eval Acc: 0.961\n"]},{"data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (3): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (3): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (4): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (5): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["train_model(model=pruned_model,\n","            train_loader=train_loader,\n","            test_loader=test_loader,\n","            device=cuda_device,\n","            model_dir=\"saved_models\",\n","            model_filename=\"sparsity0.95_from46ep.pt\",\n","                l1_regularization_strength=0,\n","                l2_regularization_strength=0,\n","                weight_decay=weight_decay,\n","                learning_rate=learning_rate*0.1,\n","                num_epochs=30)"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T18:42:04.534406Z","iopub.status.busy":"2024-03-30T18:42:04.534045Z","iopub.status.idle":"2024-03-30T18:42:26.334451Z","shell.execute_reply":"2024-03-30T18:42:26.333420Z","shell.execute_reply.started":"2024-03-30T18:42:04.534378Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.97      0.97      0.97      1000\n","           1       0.97      0.98      0.98      1000\n","           2       0.96      0.95      0.95      1000\n","           3       0.93      0.90      0.91      1000\n","           4       0.95      0.98      0.97      1000\n","           5       0.93      0.94      0.93      1000\n","           6       0.96      0.98      0.97      1000\n","           7       0.98      0.97      0.98      1000\n","           8       0.98      0.98      0.98      1000\n","           9       0.97      0.97      0.97      1000\n","\n","    accuracy                           0.96     10000\n","   macro avg       0.96      0.96      0.96     10000\n","weighted avg       0.96      0.96      0.96     10000\n","\n"]}],"source":["classification_report = create_classification_report(\n","        model=pruned_model, test_loader=test_loader, device=cuda_device)\n","print(classification_report)"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T18:42:35.385520Z","iopub.status.busy":"2024-03-30T18:42:35.385165Z","iopub.status.idle":"2024-03-30T18:42:35.397807Z","shell.execute_reply":"2024-03-30T18:42:35.396741Z","shell.execute_reply.started":"2024-03-30T18:42:35.385491Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.97      0.97      1000\n","           1       0.97      0.98      0.98      1000\n","           2       0.96      0.95      0.95      1000\n","           3       0.93      0.90      0.91      1000\n","           4       0.95      0.98      0.97      1000\n","           5       0.93      0.94      0.93      1000\n","           6       0.96      0.98      0.97      1000\n","           7       0.98      0.97      0.98      1000\n","           8       0.98      0.98      0.98      1000\n","           9       0.97      0.97      0.97      1000\n","\n","    accuracy                           0.96     10000\n","   macro avg       0.96      0.96      0.96     10000\n","weighted avg       0.96      0.96      0.96     10000\n","\n","Global Sparsity:\n","0.9498\n"]}],"source":["num_zeros, num_elements, sparsity = measure_global_sparsity(pruned_model, conv2d_use_mask=True)\n","\n","#print(\"Test Accuracy: {:.3f}\".format(eval_accuracy))\n","print(\"Classification Report:\")\n","print(classification_report)\n","print(\"Global Sparsity:\")\n","print(\"{:.4f}\".format(sparsity))"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T18:48:56.984164Z","iopub.status.busy":"2024-03-30T18:48:56.983478Z","iopub.status.idle":"2024-03-30T18:48:57.224254Z","shell.execute_reply":"2024-03-30T18:48:57.223254Z","shell.execute_reply.started":"2024-03-30T18:48:56.984109Z"},"trusted":true},"outputs":[],"source":["save_model(pruned_model, \"saved_models\", \"sparsity0.95_final_acc0.96.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:24:20.185676Z","iopub.status.idle":"2024-03-29T12:24:20.186049Z","shell.execute_reply":"2024-03-29T12:24:20.185841Z","shell.execute_reply.started":"2024-03-29T12:24:20.185828Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","iterative_pruning_finetuning(\n","        model=pruned_model,\n","        train_loader=train_loader,\n","        test_loader=test_loader,\n","        device=cuda_device,\n","        learning_rate=learning_rate,\n","        learning_rate_decay=learning_rate_decay,\n","        l1_regularization_strength=l1_regularization_strength,\n","        l2_regularization_strength=l2_regularization_strength,\n","        conv2d_prune_amount=0.725, # 0.725^5 = 0.2\n","        linear_prune_amount=0,\n","        num_iterations=5,\n","        num_epochs_per_iteration=100,\n","        model_filename_prefix=model_filename_prefix,\n","        model_dir=model_dir,\n","        grouped_pruning=True)\n","\"\"\""]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"isSourceIdPinned":true,"modelInstanceId":16433,"sourceId":19809,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
