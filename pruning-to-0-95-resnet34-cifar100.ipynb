{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:05:24.866067Z","iopub.status.busy":"2024-05-06T14:05:24.865274Z","iopub.status.idle":"2024-05-06T14:05:31.437300Z","shell.execute_reply":"2024-05-06T14:05:31.436493Z","shell.execute_reply.started":"2024-05-06T14:05:24.866036Z"},"trusted":true},"outputs":[],"source":["import os\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import datasets, transforms\n","\n","import time\n","import copy\n","\n","import numpy as np\n","\n","import sklearn.metrics\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:05:34.228335Z","iopub.status.busy":"2024-05-06T14:05:34.227842Z","iopub.status.idle":"2024-05-06T14:05:34.233841Z","shell.execute_reply":"2024-05-06T14:05:34.232795Z","shell.execute_reply.started":"2024-05-06T14:05:34.228306Z"},"trusted":true},"outputs":[],"source":["def set_random_seeds(random_seed=0):\n","\n","    torch.manual_seed(random_seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(random_seed)\n","    random.seed(random_seed)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:05:38.167976Z","iopub.status.busy":"2024-05-06T14:05:38.167641Z","iopub.status.idle":"2024-05-06T14:05:39.174708Z","shell.execute_reply":"2024-05-06T14:05:39.173512Z","shell.execute_reply.started":"2024-05-06T14:05:38.167952Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon May  6 14:05:39 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0              26W / 250W |      0MiB / 16384MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:24:45.685210Z","iopub.status.busy":"2024-03-30T12:24:45.684857Z","iopub.status.idle":"2024-03-30T12:24:45.689622Z","shell.execute_reply":"2024-03-30T12:24:45.688575Z","shell.execute_reply.started":"2024-03-30T12:24:45.685180Z"},"trusted":true},"outputs":[],"source":["#torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:24:46.134619Z","iopub.status.busy":"2024-03-30T12:24:46.133697Z","iopub.status.idle":"2024-03-30T12:24:46.138546Z","shell.execute_reply":"2024-03-30T12:24:46.137515Z","shell.execute_reply.started":"2024-03-30T12:24:46.134573Z"},"trusted":true},"outputs":[],"source":["#!nvidia-smi"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:05:42.362890Z","iopub.status.busy":"2024-05-06T14:05:42.362508Z","iopub.status.idle":"2024-05-06T14:05:42.878180Z","shell.execute_reply":"2024-05-06T14:05:42.877186Z","shell.execute_reply.started":"2024-05-06T14:05:42.362860Z"},"trusted":true},"outputs":[],"source":["#import os\n","#import time\n","import math\n","#import random\n","#import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","import glob\n","\n","import matplotlib.pyplot as plt\n","from PIL import Image, ImageEnhance, ImageOps\n","\n","from tqdm import tqdm, tqdm_notebook\n","\n","import torch\n","from torch import nn, cuda\n","from torch.autograd import Variable \n","import torch.nn.functional as F\n","import torchvision as vision\n","import torchvision.models as models\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import Adam, SGD, Optimizer\n","from torch.optim.lr_scheduler import _LRScheduler, CosineAnnealingLR, ReduceLROnPlateau\n","\n","from sklearn.metrics import f1_score\n","\n","class CIFAR10Policy(object):\n","    \"\"\" Randomly choose one of the best 25 Sub-policies on CIFAR10.\n","        Example:\n","        >>> policy = CIFAR10Policy()\n","        >>> transformed = policy(image)\n","        Example as a PyTorch Transform:\n","        >>> transform=transforms.Compose([\n","        >>>     transforms.Resize(256),\n","        >>>     CIFAR10Policy(),\n","        >>>     transforms.ToTensor()])\n","    \"\"\"\n","    def __init__(self, fillcolor=(128, 128, 128)):\n","        self.policies = [\n","            SubPolicy(0.1, \"invert\", 7, 0.2, \"contrast\", 6, fillcolor),\n","            SubPolicy(0.7, \"rotate\", 2, 0.3, \"translateX\", 9, fillcolor),\n","            SubPolicy(0.8, \"sharpness\", 1, 0.9, \"sharpness\", 3, fillcolor),\n","            SubPolicy(0.5, \"shearY\", 8, 0.7, \"translateY\", 9, fillcolor),\n","            SubPolicy(0.5, \"autocontrast\", 8, 0.9, \"equalize\", 2, fillcolor),\n","\n","            SubPolicy(0.2, \"shearY\", 7, 0.3, \"posterize\", 7, fillcolor),\n","            SubPolicy(0.4, \"color\", 3, 0.6, \"brightness\", 7, fillcolor),\n","            SubPolicy(0.3, \"sharpness\", 9, 0.7, \"brightness\", 9, fillcolor),\n","            SubPolicy(0.6, \"equalize\", 5, 0.5, \"equalize\", 1, fillcolor),\n","            SubPolicy(0.6, \"contrast\", 7, 0.6, \"sharpness\", 5, fillcolor),\n","\n","            SubPolicy(0.7, \"color\", 7, 0.5, \"translateX\", 8, fillcolor),\n","            SubPolicy(0.3, \"equalize\", 7, 0.4, \"autocontrast\", 8, fillcolor),\n","            SubPolicy(0.4, \"translateY\", 3, 0.2, \"sharpness\", 6, fillcolor),\n","            SubPolicy(0.9, \"brightness\", 6, 0.2, \"color\", 8, fillcolor),\n","            SubPolicy(0.5, \"solarize\", 2, 0.0, \"invert\", 3, fillcolor),\n","\n","            SubPolicy(0.2, \"equalize\", 0, 0.6, \"autocontrast\", 0, fillcolor),\n","            SubPolicy(0.2, \"equalize\", 8, 0.8, \"equalize\", 4, fillcolor),\n","            SubPolicy(0.9, \"color\", 9, 0.6, \"equalize\", 6, fillcolor),\n","            SubPolicy(0.8, \"autocontrast\", 4, 0.2, \"solarize\", 8, fillcolor),\n","            SubPolicy(0.1, \"brightness\", 3, 0.7, \"color\", 0, fillcolor),\n","\n","            SubPolicy(0.4, \"solarize\", 5, 0.9, \"autocontrast\", 3, fillcolor),\n","            SubPolicy(0.9, \"translateY\", 9, 0.7, \"translateY\", 9, fillcolor),\n","            SubPolicy(0.9, \"autocontrast\", 2, 0.8, \"solarize\", 3, fillcolor),\n","            SubPolicy(0.8, \"equalize\", 8, 0.1, \"invert\", 3, fillcolor),\n","            SubPolicy(0.7, \"translateY\", 9, 0.9, \"autocontrast\", 1, fillcolor)\n","        ]\n","\n","\n","    def __call__(self, img):\n","        policy_idx = random.randint(0, len(self.policies) - 1)\n","        return self.policies[policy_idx](img)\n","\n","    def __repr__(self):\n","        return \"AutoAugment CIFAR10 Policy\"\n","\n","\n","class SubPolicy(object):\n","    def __init__(self, p1, operation1, magnitude_idx1, p2, operation2, magnitude_idx2, fillcolor=(128, 128, 128)):\n","        ranges = {\n","            \"shearX\": np.linspace(0, 0.3, 10),\n","            \"shearY\": np.linspace(0, 0.3, 10),\n","            \"translateX\": np.linspace(0, 150 / 331, 10),\n","            \"translateY\": np.linspace(0, 150 / 331, 10),\n","            \"rotate\": np.linspace(0, 30, 10),\n","            \"color\": np.linspace(0.0, 0.9, 10),\n","            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(int),\n","            \"solarize\": np.linspace(256, 0, 10),\n","            \"contrast\": np.linspace(0.0, 0.9, 10),\n","            \"sharpness\": np.linspace(0.0, 0.9, 10),\n","            \"brightness\": np.linspace(0.0, 0.9, 10),\n","            \"autocontrast\": [0] * 10,\n","            \"equalize\": [0] * 10,\n","            \"invert\": [0] * 10\n","        }\n","\n","        # from https://stackoverflow.com/questions/5252170/specify-image-filling-color-when-rotating-in-python-with-pil-and-setting-expand\n","        def rotate_with_fill(img, magnitude):\n","            rot = img.convert(\"RGBA\").rotate(magnitude)\n","            return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(img.mode)\n","\n","        func = {\n","            \"shearX\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, magnitude * random.choice([-1, 1]), 0, 0, 1, 0),\n","                Image.BICUBIC, fillcolor=fillcolor),\n","            \"shearY\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, 0, 0, magnitude * random.choice([-1, 1]), 1, 0),\n","                Image.BICUBIC, fillcolor=fillcolor),\n","            \"translateX\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, 0, magnitude * img.size[0] * random.choice([-1, 1]), 0, 1, 0),\n","                fillcolor=fillcolor),\n","            \"translateY\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * img.size[1] * random.choice([-1, 1])),\n","                fillcolor=fillcolor),\n","            \"rotate\": lambda img, magnitude: rotate_with_fill(img, magnitude),\n","            # \"rotate\": lambda img, magnitude: img.rotate(magnitude * random.choice([-1, 1])),\n","            \"color\": lambda img, magnitude: ImageEnhance.Color(img).enhance(1 + magnitude * random.choice([-1, 1])),\n","            \"posterize\": lambda img, magnitude: ImageOps.posterize(img, magnitude),\n","            \"solarize\": lambda img, magnitude: ImageOps.solarize(img, magnitude),\n","            \"contrast\": lambda img, magnitude: ImageEnhance.Contrast(img).enhance(\n","                1 + magnitude * random.choice([-1, 1])),\n","            \"sharpness\": lambda img, magnitude: ImageEnhance.Sharpness(img).enhance(\n","                1 + magnitude * random.choice([-1, 1])),\n","            \"brightness\": lambda img, magnitude: ImageEnhance.Brightness(img).enhance(\n","                1 + magnitude * random.choice([-1, 1])),\n","            \"autocontrast\": lambda img, magnitude: ImageOps.autocontrast(img),\n","            \"equalize\": lambda img, magnitude: ImageOps.equalize(img),\n","            \"invert\": lambda img, magnitude: ImageOps.invert(img)\n","        }\n","\n","        # self.name = \"{}_{:.2f}_and_{}_{:.2f}\".format(\n","        #     operation1, ranges[operation1][magnitude_idx1],\n","        #     operation2, ranges[operation2][magnitude_idx2])\n","        self.p1 = p1\n","        self.operation1 = func[operation1]\n","        self.magnitude1 = ranges[operation1][magnitude_idx1]\n","        self.p2 = p2\n","        self.operation2 = func[operation2]\n","        self.magnitude2 = ranges[operation2][magnitude_idx2]\n","\n","\n","    def __call__(self, img):\n","        if random.random() < self.p1: img = self.operation1(img, self.magnitude1)\n","        if random.random() < self.p2: img = self.operation2(img, self.magnitude2)\n","        return img\n","  \n","\n","class TestDataset(Dataset):\n","    def __init__(self, df, mode='test', transforms=None):\n","        self.df = df\n","        self.mode = mode\n","        self.transform = transforms[self.mode]\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, idx):\n","        \n","        image = Image.open(TEST_IMAGE_PATH / self.df[idx]).convert(\"RGB\")\n","        \n","        if self.transform:\n","            image = self.transform(image)\n","            \n","        return image"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:05:49.736777Z","iopub.status.busy":"2024-05-06T14:05:49.735686Z","iopub.status.idle":"2024-05-06T14:05:49.747520Z","shell.execute_reply":"2024-05-06T14:05:49.746394Z","shell.execute_reply.started":"2024-05-06T14:05:49.736738Z"},"trusted":true},"outputs":[],"source":["def prepare_dataloader(num_workers=0,\n","                       train_batch_size=128,\n","                       eval_batch_size=256,\n","                       mean=(0.4914, 0.4822, 0.4466),\n","                       stdev=(0.2412, 0.2377, 0.2563)):\n","\n","    train_transform = transforms.Compose([\n","        torchvision.transforms.Resize((224,224)),\n","        CIFAR10Policy(),\n","        torchvision.transforms.ToTensor(),\n","        torchvision.transforms.Normalize(mean=mean, std=stdev)\n","    ])\n","\n","    test_transform = transforms.Compose([\n","        torchvision.transforms.Resize((224,224)),\n","        torchvision.transforms.ToTensor(),\n","        torchvision.transforms.Normalize(mean=torch.tensor(mean), std=stdev)\n","    ])\n","\n","    train_set = torchvision.datasets.CIFAR100(root=\"data\",\n","                                             train=True,\n","                                             download=True,\n","                                             transform=train_transform)\n","\n","    test_set = torchvision.datasets.CIFAR100(root=\"data\",\n","                                            train=False,\n","                                            download=True,\n","                                            transform=test_transform)\n","\n","    train_sampler = torch.utils.data.RandomSampler(train_set)\n","    test_sampler = torch.utils.data.SequentialSampler(test_set)\n","\n","    train_loader = torch.utils.data.DataLoader(dataset=train_set,\n","                                               batch_size=train_batch_size,\n","                                               #shuffle=True,\n","                                               sampler=train_sampler,\n","                                               num_workers=num_workers,\n","                                               pin_memory=True\n","                                              )\n","\n","    test_loader = torch.utils.data.DataLoader(dataset=test_set,\n","                                              batch_size=eval_batch_size,\n","                                              #shuffle=False,\n","                                              sampler=test_sampler,\n","                                              num_workers=num_workers,\n","                                              pin_memory=True\n","                                             )\n","\n","    classes = train_set.classes\n","\n","    return train_loader, test_loader, classes"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:54:02.377160Z","iopub.status.busy":"2024-05-06T14:54:02.376782Z","iopub.status.idle":"2024-05-06T14:54:02.394199Z","shell.execute_reply":"2024-05-06T14:54:02.393213Z","shell.execute_reply.started":"2024-05-06T14:54:02.377134Z"},"trusted":true},"outputs":[],"source":["def train_model(model,\n","                train_loader,\n","                test_loader,\n","                device,\n","                model_dir,\n","                model_filename,\n","                l1_regularization_strength=0,\n","                l2_regularization_strength=0,\n","                weight_decay=5e-4,\n","                learning_rate=1e-4,\n","                num_epochs=200,\n","                checkpoint_epochs=10\n","                ):\n","\n","    # The training configurations were not carefully selected.\n","    start = time.time()\n","    criterion = nn.CrossEntropyLoss()\n","\n","    model.to(device)\n","\n","    # It seems that SGD optimizer is better than Adam optimizer for ResNet training on CIFAR10.\n","    #optimizer = optim.SGD(model.parameters(),\n","    #                      lr=learning_rate,\n","    #                      momentum=0.9,\n","    #                      weight_decay=l2_regularization_strength)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=500)\n","    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n","                                                     milestones=[19, 28, 36],\n","                                                     gamma=0.1,\n","                                                     last_epoch=-1)\n","    # optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n","\n","    # Evaluation\n","    model.eval()\n","    eval_loss, eval_accuracy = evaluate_model(model=model,\n","                                              test_loader=test_loader,\n","                                              device=device,\n","                                              criterion=criterion)\n","    print(\"Epoch: {:03d} Eval Loss: {:.3f} Eval Acc: {:.3f}\".format(\n","        0, eval_loss, eval_accuracy))\n","\n","    for epoch in range(1, num_epochs+1):\n","        epoch_start = time.time()\n","        # Training\n","        model.train()\n","\n","        running_loss = 0\n","        running_corrects = 0\n","\n","        for inputs, labels in train_loader:\n","\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward + backward + optimize\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","            loss = criterion(outputs, labels)\n","\n","            l1_reg = torch.tensor(0.).to(device)\n","            for module in model.modules():\n","                mask = None\n","                weight = None\n","                for name, buffer in module.named_buffers():\n","                    if name == \"weight_mask\":\n","                        mask = buffer\n","                for name, param in module.named_parameters():\n","                    if name == \"weight_orig\":\n","                        weight = param\n","                # We usually only want to introduce sparsity to weights and prune weights.\n","                # Do the same for bias if necessary.\n","                if mask is not None and weight is not None:\n","                    l1_reg += torch.norm(mask * weight, 1)\n","\n","            loss += l1_regularization_strength * l1_reg \n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            # statistics\n","            running_loss += loss.item() * inputs.size(0)\n","            running_corrects += torch.sum(preds == labels.data)\n","\n","        train_loss = running_loss / len(train_loader.dataset)\n","        train_accuracy = running_corrects / len(train_loader.dataset)\n","\n","        # Evaluation\n","        model.eval()\n","        eval_loss, eval_accuracy = evaluate_model(model=model,\n","                                                  test_loader=test_loader,\n","                                                  device=device,\n","                                                  criterion=criterion)\n","        if epoch % checkpoint_epochs == 0:\n","            torch.save({\n","                'epoch': epoch,\n","                'state_dict': model.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","            }, f'./checkpoint_epoch{epoch}.pth.tar')\n","\n","        # Set learning rate scheduler\n","        scheduler.step()\n","        elapsed = time.time()\n","        print(\n","            \"Epoch: {:03d} Train Loss: {:.3f} Train Acc: {:.3f} Eval Loss: {:.3f} Eval Acc: {:.3f}\"\n","            .format(epoch, train_loss, train_accuracy, eval_loss,\n","                    eval_accuracy))\n","        print(f'Epoch time: {elapsed-epoch_start:.1f} Total training time: {elapsed-start:.1f}')\n","        print()\n","        #torch.cuda.empty_cache()\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train(net, train_dataloader, valid_dataloader, criterion, optimizer, scheduler=None, epochs=10, device='cpu', checkpoint_epochs=10):\n","    start = time.time()\n","    print(f'Training for {epochs} epochs on {device}')\n","    \n","    for epoch in range(1,epochs+1):\n","        epoch_start = time.time()\n","        print(f\"Epoch {epoch}/{epochs}\")\n","        \n","        net.train()  # put network in train mode for Dropout and Batch Normalization\n","        train_loss = torch.tensor(0., device=device)  # loss and accuracy tensors are on the GPU to avoid data transfers\n","        train_accuracy = torch.tensor(0., device=device)\n","        for X, y in train_dataloader:\n","            X = X.to(device)\n","            y = y.to(device)\n","            preds = net(X)\n","            loss = criterion(preds, y)\n","            \n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            \n","            with torch.no_grad():\n","                train_loss += loss * train_dataloader.batch_size\n","                train_accuracy += (torch.argmax(preds, dim=1) == y).sum()\n","        \n","        if valid_dataloader is not None:\n","            net.eval()  # put network in train mode for Dropout and Batch Normalization\n","            valid_loss = torch.tensor(0., device=device)\n","            valid_accuracy = torch.tensor(0., device=device)\n","            with torch.no_grad():\n","                for X, y in valid_dataloader:\n","                    X = X.to(device)\n","                    y = y.to(device)\n","                    preds = net(X)\n","                    loss = criterion(preds, y)\n","\n","                    valid_loss += loss * valid_dataloader.batch_size\n","                    valid_accuracy += (torch.argmax(preds, dim=1) == y).sum()\n","        \n","        if scheduler is not None: \n","            scheduler.step()\n","            \n","        print(f'Training loss: {train_loss/len(train_dataloader.dataset):.2f}')\n","        print(f'Training accuracy: {100*train_accuracy/len(train_dataloader.dataset):.2f}')\n","        \n","        if valid_dataloader is not None:\n","            print(f'Valid loss: {valid_loss/len(valid_dataloader.dataset):.2f}')\n","            print(f'Valid accuracy: {100*valid_accuracy/len(valid_dataloader.dataset):.2f}')\n","        \n","        if epoch % checkpoint_epochs == 0:\n","            torch.save({\n","                'epoch': epoch,\n","                'state_dict': net.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","            }, f'./checkpoint_epoch{epoch}.pth.tar')\n","        elapsed = time.time()\n","        print(f'Epoch time: {elapsed-epoch_start:.1f} Total training time: {elapsed-start:.1f}')\n","        print()\n","    \n","    end = time.time()\n","    print(f'Total training time: {end-start:.1f} seconds')\n","    return net"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:06:06.342519Z","iopub.status.busy":"2024-05-06T14:06:06.342152Z","iopub.status.idle":"2024-05-06T14:06:06.351112Z","shell.execute_reply":"2024-05-06T14:06:06.350166Z","shell.execute_reply.started":"2024-05-06T14:06:06.342492Z"},"trusted":true},"outputs":[],"source":["def measure_module_sparsity(module, weight=True, bias=False, use_mask=False):\n","\n","    num_zeros = 0\n","    num_elements = 0\n","\n","    if use_mask == True:\n","        for buffer_name, buffer in module.named_buffers():\n","            if \"weight_mask\" in buffer_name and weight == True:\n","                num_zeros += torch.sum(buffer == 0).item()\n","                num_elements += buffer.nelement()\n","            if \"bias_mask\" in buffer_name and bias == True:\n","                num_zeros += torch.sum(buffer == 0).item()\n","                num_elements += buffer.nelement()\n","    else:\n","        for param_name, param in module.named_parameters():\n","            if \"weight\" in param_name and weight == True:\n","                num_zeros += torch.sum(param == 0).item()\n","                num_elements += param.nelement()\n","            if \"bias\" in param_name and bias == True:\n","                num_zeros += torch.sum(param == 0).item()\n","                num_elements += param.nelement()\n","\n","    sparsity = num_zeros / num_elements\n","\n","    return num_zeros, num_elements, sparsity"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:06:12.435662Z","iopub.status.busy":"2024-05-06T14:06:12.434680Z","iopub.status.idle":"2024-05-06T14:06:12.442707Z","shell.execute_reply":"2024-05-06T14:06:12.441671Z","shell.execute_reply.started":"2024-05-06T14:06:12.435628Z"},"trusted":true},"outputs":[],"source":["def measure_global_sparsity(model,\n","                            weight=True,\n","                            bias=False,\n","                            conv2d_use_mask=False,\n","                            linear_use_mask=False):\n","\n","    num_zeros = 0\n","    num_elements = 0\n","\n","    for module_name, module in model.named_modules():\n","\n","        if isinstance(module, torch.nn.Conv2d):\n","\n","            module_num_zeros, module_num_elements, _ = measure_module_sparsity(\n","                module, weight=weight, bias=bias, use_mask=conv2d_use_mask)\n","            num_zeros += module_num_zeros\n","            num_elements += module_num_elements\n","\n","        elif isinstance(module, torch.nn.Linear):\n","\n","            module_num_zeros, module_num_elements, _ = measure_module_sparsity(\n","                module, weight=weight, bias=bias, use_mask=linear_use_mask)\n","            num_zeros += module_num_zeros\n","            num_elements += module_num_elements\n","\n","    sparsity = num_zeros / num_elements\n","\n","    return num_zeros, num_elements, sparsity"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:06:15.011281Z","iopub.status.busy":"2024-05-06T14:06:15.010638Z","iopub.status.idle":"2024-05-06T14:06:15.018663Z","shell.execute_reply":"2024-05-06T14:06:15.017623Z","shell.execute_reply.started":"2024-05-06T14:06:15.011249Z"},"trusted":true},"outputs":[],"source":["def evaluate_model(model, test_loader, device, criterion=None):\n","\n","    model.eval()\n","    model.to(device)\n","\n","    running_loss = 0\n","    running_corrects = 0\n","\n","    for inputs, labels in test_loader:\n","\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(inputs)\n","        _, preds = torch.max(outputs, 1)\n","\n","        if criterion is not None:\n","            loss = criterion(outputs, labels).item()\n","        else:\n","            loss = 0\n","\n","        # statistics\n","        running_loss += loss * inputs.size(0)\n","        running_corrects += torch.sum(preds == labels.data)\n","        \n","        #torch.cuda.empty_cache()\n","\n","    eval_loss = running_loss / len(test_loader.dataset)\n","    eval_accuracy = running_corrects / len(test_loader.dataset)\n","    \n","\n","    return eval_loss, eval_accuracy"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:06:16.787745Z","iopub.status.busy":"2024-05-06T14:06:16.787198Z","iopub.status.idle":"2024-05-06T14:06:16.794771Z","shell.execute_reply":"2024-05-06T14:06:16.793736Z","shell.execute_reply.started":"2024-05-06T14:06:16.787711Z"},"trusted":true},"outputs":[],"source":["def create_classification_report(model, device, test_loader):\n","\n","    model.eval()\n","    model.to(device)\n","\n","    y_pred = []\n","    y_true = []\n","\n","    with torch.no_grad():\n","        for data in test_loader:\n","            y_true += data[1].numpy().tolist()\n","            images, _ = data[0].to(device), data[1].to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            y_pred += predicted.cpu().numpy().tolist()\n","\n","    classification_report = sklearn.metrics.classification_report(\n","        y_true=y_true, y_pred=y_pred)\n","\n","    return classification_report"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:07:54.139706Z","iopub.status.busy":"2024-05-06T14:07:54.139319Z","iopub.status.idle":"2024-05-06T14:07:54.145040Z","shell.execute_reply":"2024-05-06T14:07:54.144108Z","shell.execute_reply.started":"2024-05-06T14:07:54.139676Z"},"trusted":true},"outputs":[],"source":["def save_model(model, model_dir, model_filename):\n","\n","    if not os.path.exists(model_dir):\n","        os.makedirs(model_dir)\n","    model_filepath = os.path.join(model_dir, model_filename)\n","    torch.save(model.state_dict(), model_filepath)\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:07:57.180385Z","iopub.status.busy":"2024-05-06T14:07:57.180020Z","iopub.status.idle":"2024-05-06T14:07:57.185324Z","shell.execute_reply":"2024-05-06T14:07:57.184293Z","shell.execute_reply.started":"2024-05-06T14:07:57.180356Z"},"trusted":true},"outputs":[],"source":["def load_model(model, model_filepath, device):\n","\n","    model.load_state_dict(torch.load(model_filepath, map_location=device)['state_dict'])\n","\n","    return model"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:08:04.397633Z","iopub.status.busy":"2024-05-06T14:08:04.397255Z","iopub.status.idle":"2024-05-06T14:08:04.403281Z","shell.execute_reply":"2024-05-06T14:08:04.402046Z","shell.execute_reply.started":"2024-05-06T14:08:04.397604Z"},"trusted":true},"outputs":[],"source":["def create_model(num_classes=10, model_func=torchvision.models.resnet34):\n","\n","    \n","    model = model_func(num_classes=num_classes, pretrained=False)\n","\n","    return model"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T16:14:03.950482Z","iopub.status.busy":"2024-05-06T16:14:03.950058Z","iopub.status.idle":"2024-05-06T16:14:03.970228Z","shell.execute_reply":"2024-05-06T16:14:03.969235Z","shell.execute_reply.started":"2024-05-06T16:14:03.950437Z"},"trusted":true},"outputs":[],"source":["def iterative_pruning_finetuning(model,\n","                                 train_loader,\n","                                 test_loader,\n","                                 device,\n","                                 learning_rate,\n","                                 l1_regularization_strength=0,\n","                                 l2_regularization_strength=0,\n","                                 weight_decay=5e-4,\n","                                 learning_rate_decay=0.6,\n","                                 conv2d_prune_amount=0.4,\n","                                 linear_prune_amount=0.2,\n","                                 num_iterations=10,\n","                                 num_epochs_per_iteration=10,\n","                                 model_filename_prefix=\"pruned_model\",\n","                                 model_dir=\"saved_models\",\n","                                 grouped_pruning=False):\n","\n","    conv2d_one_iter_prune_amount = 1 - (1 - conv2d_prune_amount)**(1/num_iterations)\n","    linear_one_iter_prune_amount = 1 - (1 - linear_prune_amount)**(1/num_iterations)\n","    for i in range(num_iterations):\n","\n","        print(\"Pruning and Finetuning {}/{}\".format(i + 1, num_iterations))\n","\n","        print(\"Pruning...\")\n","\n","        if grouped_pruning == True:\n","            \n","            parameters_to_prune = []\n","            for module_name, module in model.named_modules():\n","                if isinstance(module, torch.nn.Conv2d):\n","                    parameters_to_prune.append((module, \"weight\"))\n","            prune.global_unstructured(\n","                parameters_to_prune,\n","                pruning_method=prune.L1Unstructured,\n","                amount=conv2d_one_iter_prune_amount,\n","            )\n","        else:\n","            for module_name, module in model.named_modules():\n","                if isinstance(module, torch.nn.Conv2d):\n","                    prune.l1_unstructured(module,\n","                                          name=\"weight\",\n","                                          amount=conv2d_one_iter_prune_amount)\n","                elif isinstance(module, torch.nn.Linear):\n","                    prune.l1_unstructured(module,\n","                                          name=\"weight\",\n","                                          amount=linear_one_iter_prune_amount)\n","\n","        _, eval_accuracy = evaluate_model(model=model,\n","                                          test_loader=test_loader,\n","                                          device=device,\n","                                          criterion=None)\n","\n","        classification_report = create_classification_report(\n","            model=model, test_loader=test_loader, device=device)\n","\n","        num_zeros, num_elements, sparsity = measure_global_sparsity(\n","            model,\n","            weight=True,\n","            bias=False,\n","            conv2d_use_mask=True,\n","            linear_use_mask=False)\n","\n","        print(\"Test Accuracy: {:.3f}\".format(eval_accuracy))\n","        print(\"Classification Report:\")\n","        print(classification_report)\n","        print(\"Global Sparsity:\")\n","        print(\"{:.2f}\".format(sparsity))\n","\n","        # print(model.conv1._forward_pre_hooks)\n","        \n","        if (i >= (num_iterations * 2/3)) and (num_iterations >= 3):\n","            cur_num_epochs_per_iter = num_epochs_per_iteration * 3/2\n","        else:\n","            cur_num_epochs_per_iter = num_epochs_per_iteration\n","\n","        print(\"Fine-tuning...\")\n","\n","        train_model(model=model,\n","                    train_loader=train_loader,\n","                    test_loader=test_loader,\n","                    device=device,\n","                    model_dir=model_dir,\n","                    model_filename=\"{}_iter{}\".format(model_filename_prefix, i + 1),\n","                    l1_regularization_strength=l1_regularization_strength,\n","                    l2_regularization_strength=l2_regularization_strength,\n","                    weight_decay=weight_decay,\n","                    learning_rate=learning_rate * (learning_rate_decay**i),\n","                    num_epochs=cur_num_epochs_per_iter)\n","        \n","\n","        _, eval_accuracy = evaluate_model(model=model,\n","                                          test_loader=test_loader,\n","                                          device=device,\n","                                          criterion=None)\n","\n","        classification_report = create_classification_report(\n","            model=model, test_loader=test_loader, device=device)\n","\n","        num_zeros, num_elements, sparsity = measure_global_sparsity(\n","            model,\n","            weight=True,\n","            bias=False,\n","            conv2d_use_mask=True,\n","            linear_use_mask=False)\n","\n","        print(\"Test Accuracy: {:.3f}\".format(eval_accuracy))\n","        print(\"Classification Report:\")\n","        print(classification_report)\n","        print(\"Global Sparsity:\")\n","        print(\"{:.2f}\".format(sparsity))\n","\n","        model_filename = \"{}_{}.pt\".format(model_filename_prefix, i + 1)\n","        model_filepath = os.path.join(model_dir, model_filename)\n","        save_model(model=model,\n","                   model_dir=model_dir,\n","                   model_filename=model_filename)\n","        \n","        #model = load_model(model=model,\n","        #                   model_filepath=model_filepath,\n","        #                   device=device)\n","        torch.cuda.empty_cache()\n","        \n","\n","    return model\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:09:43.766054Z","iopub.status.busy":"2024-05-06T14:09:43.765686Z","iopub.status.idle":"2024-05-06T14:09:43.772712Z","shell.execute_reply":"2024-05-06T14:09:43.771789Z","shell.execute_reply.started":"2024-05-06T14:09:43.766026Z"},"trusted":true},"outputs":[],"source":["def remove_parameters(model):\n","\n","    for module_name, module in model.named_modules():\n","        if isinstance(module, torch.nn.Conv2d):\n","            try:\n","                prune.remove(module, \"weight\")\n","            except:\n","                pass\n","            try:\n","                prune.remove(module, \"bias\")\n","            except:\n","                pass\n","        elif isinstance(module, torch.nn.Linear):\n","            try:\n","                prune.remove(module, \"weight\")\n","            except:\n","                pass\n","            try:\n","                prune.remove(module, \"bias\")\n","            except:\n","                pass\n","\n","    return model"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:09:44.626894Z","iopub.status.busy":"2024-05-06T14:09:44.626536Z","iopub.status.idle":"2024-05-06T14:09:44.632775Z","shell.execute_reply":"2024-05-06T14:09:44.631985Z","shell.execute_reply.started":"2024-05-06T14:09:44.626868Z"},"trusted":true},"outputs":[],"source":["import torch.nn.utils.prune as prune"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:09:55.417153Z","iopub.status.busy":"2024-05-06T14:09:55.416794Z","iopub.status.idle":"2024-05-06T14:09:55.421814Z","shell.execute_reply":"2024-05-06T14:09:55.420734Z","shell.execute_reply.started":"2024-05-06T14:09:55.417125Z"},"trusted":true},"outputs":[],"source":["model_dir = \"saved_models\"\n","model_filename_prefix = \"resnet34_cifar100\"\n","pruned_model_filename = \"resnet34_cifar100_sp0.95.pt\"\n","pruned_model_filepath = os.path.join(model_dir, pruned_model_filename)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:11:02.405749Z","iopub.status.busy":"2024-05-06T14:11:02.405381Z","iopub.status.idle":"2024-05-06T14:11:02.410526Z","shell.execute_reply":"2024-05-06T14:11:02.409202Z","shell.execute_reply.started":"2024-05-06T14:11:02.405723Z"},"trusted":true},"outputs":[],"source":["model_filepath = \"/kaggle/input/resnet34-for-cifar100/pytorch/accuracy-83.8/1/checkpoint_epoch50.pth.tar\""]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:10:14.818192Z","iopub.status.busy":"2024-05-06T14:10:14.817682Z","iopub.status.idle":"2024-05-06T14:10:14.823194Z","shell.execute_reply":"2024-05-06T14:10:14.822252Z","shell.execute_reply.started":"2024-05-06T14:10:14.818158Z"},"trusted":true},"outputs":[],"source":["num_classes = 100\n","random_seed = 1\n","l1_regularization_strength = 0\n","l2_regularization_strength = 0\n","weight_decay = 5e-4\n","learning_rate = 3e-4\n","learning_rate_decay = 1"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:10:16.070625Z","iopub.status.busy":"2024-05-06T14:10:16.070236Z","iopub.status.idle":"2024-05-06T14:10:16.086168Z","shell.execute_reply":"2024-05-06T14:10:16.085282Z","shell.execute_reply.started":"2024-05-06T14:10:16.070595Z"},"trusted":true},"outputs":[],"source":["mean = torch.tensor([0.5070, 0.4865, 0.4408]) # CIFAR100 train mean\n","std = torch.tensor([0.2621, 0.2512, 0.2713]) # CIFAR100 train std"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:10:26.933242Z","iopub.status.busy":"2024-05-06T14:10:26.932872Z","iopub.status.idle":"2024-05-06T14:10:26.970255Z","shell.execute_reply":"2024-05-06T14:10:26.969213Z","shell.execute_reply.started":"2024-05-06T14:10:26.933212Z"},"trusted":true},"outputs":[{"data":{"text/plain":["True"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:10:29.038238Z","iopub.status.busy":"2024-05-06T14:10:29.037856Z","iopub.status.idle":"2024-05-06T14:10:29.042833Z","shell.execute_reply":"2024-05-06T14:10:29.041873Z","shell.execute_reply.started":"2024-05-06T14:10:29.038207Z"},"trusted":true},"outputs":[],"source":["cuda_device = torch.device(\"cuda:0\")\n","cpu_device = torch.device(\"cpu:0\")"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:10:34.353377Z","iopub.status.busy":"2024-05-06T14:10:34.353034Z","iopub.status.idle":"2024-05-06T14:10:34.359832Z","shell.execute_reply":"2024-05-06T14:10:34.358950Z","shell.execute_reply.started":"2024-05-06T14:10:34.353352Z"},"trusted":true},"outputs":[],"source":["set_random_seeds(random_seed=random_seed)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:11:06.698837Z","iopub.status.busy":"2024-05-06T14:11:06.698475Z","iopub.status.idle":"2024-05-06T14:11:10.672519Z","shell.execute_reply":"2024-05-06T14:11:10.671637Z","shell.execute_reply.started":"2024-05-06T14:11:06.698808Z"},"trusted":true},"outputs":[],"source":["model = create_model(num_classes=num_classes)\n","\n","    # Load a pretrained model.\n","model = load_model(model=model,\n","                    model_filepath=model_filepath,\n","                    device=cuda_device) # cuda_device!!!"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:25:55.647386Z","iopub.status.busy":"2024-03-30T12:25:55.646944Z","iopub.status.idle":"2024-03-30T12:25:55.651778Z","shell.execute_reply":"2024-03-30T12:25:55.650720Z","shell.execute_reply.started":"2024-03-30T12:25:55.647356Z"},"trusted":true},"outputs":[],"source":["#torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:25:56.072481Z","iopub.status.busy":"2024-03-30T12:25:56.071667Z","iopub.status.idle":"2024-03-30T12:25:56.076194Z","shell.execute_reply":"2024-03-30T12:25:56.075172Z","shell.execute_reply.started":"2024-03-30T12:25:56.072446Z"},"trusted":true},"outputs":[],"source":["#!nvidia-smi"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:11:22.446830Z","iopub.status.busy":"2024-05-06T14:11:22.445942Z","iopub.status.idle":"2024-05-06T14:11:29.792480Z","shell.execute_reply":"2024-05-06T14:11:29.791599Z","shell.execute_reply.started":"2024-05-06T14:11:22.446798Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34/2226863683.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torchvision.transforms.Normalize(mean=torch.tensor(mean), std=stdev)\n"]},{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 169001437/169001437 [00:03<00:00, 48436279.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data/cifar-100-python.tar.gz to data\n","Files already downloaded and verified\n"]}],"source":["train_loader, test_loader, classes = prepare_dataloader(\n","        num_workers=2, train_batch_size=128, eval_batch_size=128, mean=mean, stdev=std)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:11:31.579716Z","iopub.status.busy":"2024-05-06T14:11:31.578959Z","iopub.status.idle":"2024-05-06T14:11:32.580620Z","shell.execute_reply":"2024-05-06T14:11:32.579619Z","shell.execute_reply.started":"2024-05-06T14:11:31.579685Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon May  6 14:11:32 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0              32W / 250W |    536MiB / 16384MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:26:22.586523Z","iopub.status.busy":"2024-03-30T12:26:22.586143Z","iopub.status.idle":"2024-03-30T12:26:22.591383Z","shell.execute_reply":"2024-03-30T12:26:22.590329Z","shell.execute_reply.started":"2024-03-30T12:26:22.586488Z"},"trusted":true},"outputs":[],"source":["#torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:26:22.968310Z","iopub.status.busy":"2024-03-30T12:26:22.967896Z","iopub.status.idle":"2024-03-30T12:26:22.972752Z","shell.execute_reply":"2024-03-30T12:26:22.971558Z","shell.execute_reply.started":"2024-03-30T12:26:22.968280Z"},"trusted":true},"outputs":[],"source":["#!nvidia-smi"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:11:47.477246Z","iopub.status.busy":"2024-05-06T14:11:47.476846Z","iopub.status.idle":"2024-05-06T14:11:59.209336Z","shell.execute_reply":"2024-05-06T14:11:59.207929Z","shell.execute_reply.started":"2024-05-06T14:11:47.477212Z"},"trusted":true},"outputs":[],"source":["\n","_, eval_accuracy = evaluate_model(model=model,\n","                                    test_loader=test_loader,\n","                                    device=cuda_device,\n","                                    criterion=None)\n"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:12:00.915376Z","iopub.status.busy":"2024-05-06T14:12:00.914980Z","iopub.status.idle":"2024-05-06T14:12:12.505851Z","shell.execute_reply":"2024-05-06T14:12:12.504811Z","shell.execute_reply.started":"2024-05-06T14:12:00.915338Z"},"trusted":true},"outputs":[],"source":["\n","classification_report = create_classification_report(\n","        model=model, test_loader=test_loader, device=cuda_device)\n"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:12:14.732044Z","iopub.status.busy":"2024-05-06T14:12:14.731347Z","iopub.status.idle":"2024-05-06T14:12:14.744020Z","shell.execute_reply":"2024-05-06T14:12:14.743090Z","shell.execute_reply.started":"2024-05-06T14:12:14.732008Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.838\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.93      0.93      0.93       100\n","           1       0.91      0.92      0.92       100\n","           2       0.73      0.77      0.75       100\n","           3       0.77      0.83      0.80       100\n","           4       0.67      0.75      0.71       100\n","           5       0.85      0.83      0.84       100\n","           6       0.87      0.90      0.89       100\n","           7       0.86      0.88      0.87       100\n","           8       0.93      0.94      0.94       100\n","           9       0.94      0.95      0.95       100\n","          10       0.75      0.63      0.68       100\n","          11       0.60      0.63      0.61       100\n","          12       0.87      0.90      0.89       100\n","          13       0.88      0.82      0.85       100\n","          14       0.89      0.90      0.90       100\n","          15       0.87      0.90      0.89       100\n","          16       0.90      0.88      0.89       100\n","          17       0.94      0.93      0.93       100\n","          18       0.88      0.84      0.86       100\n","          19       0.79      0.86      0.82       100\n","          20       0.91      0.89      0.90       100\n","          21       0.92      0.94      0.93       100\n","          22       0.90      0.91      0.91       100\n","          23       0.91      0.87      0.89       100\n","          24       0.92      0.88      0.90       100\n","          25       0.80      0.78      0.79       100\n","          26       0.77      0.81      0.79       100\n","          27       0.80      0.86      0.83       100\n","          28       0.91      0.89      0.90       100\n","          29       0.84      0.85      0.85       100\n","          30       0.74      0.78      0.76       100\n","          31       0.87      0.83      0.85       100\n","          32       0.80      0.82      0.81       100\n","          33       0.88      0.75      0.81       100\n","          34       0.90      0.90      0.90       100\n","          35       0.64      0.61      0.62       100\n","          36       0.85      0.89      0.87       100\n","          37       0.88      0.84      0.86       100\n","          38       0.87      0.83      0.85       100\n","          39       0.98      0.92      0.95       100\n","          40       0.89      0.88      0.88       100\n","          41       0.91      0.95      0.93       100\n","          42       0.83      0.80      0.82       100\n","          43       0.89      0.93      0.91       100\n","          44       0.79      0.81      0.80       100\n","          45       0.75      0.75      0.75       100\n","          46       0.70      0.67      0.68       100\n","          47       0.69      0.62      0.65       100\n","          48       0.97      0.96      0.96       100\n","          49       0.86      0.89      0.87       100\n","          50       0.70      0.62      0.66       100\n","          51       0.90      0.92      0.91       100\n","          52       0.63      0.74      0.68       100\n","          53       0.88      0.97      0.92       100\n","          54       0.83      0.85      0.84       100\n","          55       0.69      0.67      0.68       100\n","          56       0.92      0.92      0.92       100\n","          57       0.82      0.84      0.83       100\n","          58       0.93      0.98      0.96       100\n","          59       0.72      0.68      0.70       100\n","          60       0.90      0.87      0.88       100\n","          61       0.86      0.87      0.87       100\n","          62       0.80      0.78      0.79       100\n","          63       0.83      0.81      0.82       100\n","          64       0.74      0.73      0.73       100\n","          65       0.77      0.80      0.78       100\n","          66       0.95      0.87      0.91       100\n","          67       0.80      0.78      0.79       100\n","          68       0.91      0.97      0.94       100\n","          69       0.88      0.92      0.90       100\n","          70       0.79      0.79      0.79       100\n","          71       0.86      0.85      0.85       100\n","          72       0.64      0.65      0.64       100\n","          73       0.76      0.74      0.75       100\n","          74       0.68      0.67      0.68       100\n","          75       0.95      0.92      0.93       100\n","          76       0.92      0.94      0.93       100\n","          77       0.92      0.90      0.91       100\n","          78       0.75      0.78      0.76       100\n","          79       0.84      0.90      0.87       100\n","          80       0.80      0.82      0.81       100\n","          81       0.81      0.81      0.81       100\n","          82       0.93      0.96      0.95       100\n","          83       0.87      0.77      0.81       100\n","          84       0.86      0.89      0.87       100\n","          85       0.93      0.91      0.92       100\n","          86       0.95      0.91      0.93       100\n","          87       0.92      0.93      0.93       100\n","          88       0.88      0.86      0.87       100\n","          89       0.90      0.96      0.93       100\n","          90       0.88      0.91      0.90       100\n","          91       0.92      0.89      0.90       100\n","          92       0.69      0.76      0.72       100\n","          93       0.93      0.78      0.85       100\n","          94       0.94      0.97      0.96       100\n","          95       0.84      0.79      0.81       100\n","          96       0.71      0.67      0.69       100\n","          97       0.92      0.90      0.91       100\n","          98       0.68      0.69      0.68       100\n","          99       0.84      0.81      0.83       100\n","\n","    accuracy                           0.84     10000\n","   macro avg       0.84      0.84      0.84     10000\n","weighted avg       0.84      0.84      0.84     10000\n","\n","Global Sparsity:\n","0.00\n"]}],"source":["\n","num_zeros, num_elements, sparsity = measure_global_sparsity(model)\n","\n","print(\"Test Accuracy: {:.3f}\".format(eval_accuracy))\n","print(\"Classification Report:\")\n","print(classification_report)\n","print(\"Global Sparsity:\")\n","print(\"{:.2f}\".format(sparsity))\n"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:52:37.466949Z","iopub.status.busy":"2024-05-06T14:52:37.466587Z","iopub.status.idle":"2024-05-06T14:52:37.503061Z","shell.execute_reply":"2024-05-06T14:52:37.502190Z","shell.execute_reply.started":"2024-05-06T14:52:37.466921Z"},"trusted":true},"outputs":[],"source":["pruned_model = copy.deepcopy(model)"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:52:39.027259Z","iopub.status.busy":"2024-05-06T14:52:39.026903Z","iopub.status.idle":"2024-05-06T14:52:39.037064Z","shell.execute_reply":"2024-05-06T14:52:39.036266Z","shell.execute_reply.started":"2024-05-06T14:52:39.027231Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.0\n"]}],"source":["num_zeros, num_elements, sparsity = measure_global_sparsity(pruned_model)\n","print(sparsity)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:12:38.587659Z","iopub.status.busy":"2024-05-06T14:12:38.587006Z","iopub.status.idle":"2024-05-06T14:12:39.592786Z","shell.execute_reply":"2024-05-06T14:12:39.591755Z","shell.execute_reply.started":"2024-05-06T14:12:38.587627Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon May  6 14:12:39 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P0              33W / 250W |   8914MiB / 16384MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:54:32.816232Z","iopub.status.busy":"2024-05-06T14:54:32.815859Z","iopub.status.idle":"2024-05-06T14:54:32.977527Z","shell.execute_reply":"2024-05-06T14:54:32.976405Z","shell.execute_reply.started":"2024-05-06T14:54:32.816203Z"},"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:54:34.234182Z","iopub.status.busy":"2024-05-06T14:54:34.233317Z","iopub.status.idle":"2024-05-06T14:54:35.241644Z","shell.execute_reply":"2024-05-06T14:54:35.240268Z","shell.execute_reply.started":"2024-05-06T14:54:34.234151Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon May  6 14:54:35 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0              37W / 250W |   2052MiB / 16384MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:13:07.893338Z","iopub.status.busy":"2024-05-06T14:13:07.892924Z","iopub.status.idle":"2024-05-06T14:13:07.900626Z","shell.execute_reply":"2024-05-06T14:13:07.899679Z","shell.execute_reply.started":"2024-05-06T14:13:07.893304Z"},"trusted":true},"outputs":[{"data":{"text/plain":["True"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["next(pruned_model.parameters()).is_cuda"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:26:40.975551Z","iopub.status.busy":"2024-03-30T12:26:40.974619Z","iopub.status.idle":"2024-03-30T12:26:41.010481Z","shell.execute_reply":"2024-03-30T12:26:41.009583Z","shell.execute_reply.started":"2024-03-30T12:26:40.975515Z"},"trusted":true},"outputs":[],"source":["pruned_model.to(cuda_device);"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:26:44.232244Z","iopub.status.busy":"2024-03-30T12:26:44.231877Z","iopub.status.idle":"2024-03-30T12:26:44.238557Z","shell.execute_reply":"2024-03-30T12:26:44.237620Z","shell.execute_reply.started":"2024-03-30T12:26:44.232214Z"},"trusted":true},"outputs":[{"data":{"text/plain":["True"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["next(pruned_model.parameters()).is_cuda"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:54:25.590296Z","iopub.status.busy":"2024-05-06T14:54:25.589862Z","iopub.status.idle":"2024-05-06T14:54:26.612356Z","shell.execute_reply":"2024-05-06T14:54:26.611200Z","shell.execute_reply.started":"2024-05-06T14:54:25.590250Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon May  6 14:54:26 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0              32W / 250W |  10652MiB / 16384MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:24:20.174310Z","iopub.status.idle":"2024-03-29T12:24:20.174707Z","shell.execute_reply":"2024-03-29T12:24:20.174542Z","shell.execute_reply.started":"2024-03-29T12:24:20.174526Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:54:40.384072Z","iopub.status.busy":"2024-05-06T14:54:40.383137Z","iopub.status.idle":"2024-05-06T16:07:16.801677Z","shell.execute_reply":"2024-05-06T16:07:16.800184Z","shell.execute_reply.started":"2024-05-06T14:54:40.384031Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Pruning...\n","Pruning and Finetuning 1/1\n","Pruning...\n","Test Accuracy: 0.010\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       100\n","           1       0.00      0.00      0.00       100\n","           2       0.00      0.00      0.00       100\n","           3       0.00      0.00      0.00       100\n","           4       0.00      0.00      0.00       100\n","           5       0.00      0.00      0.00       100\n","           6       0.00      0.00      0.00       100\n","           7       0.00      0.00      0.00       100\n","           8       0.00      0.00      0.00       100\n","           9       0.00      0.00      0.00       100\n","          10       0.00      0.00      0.00       100\n","          11       0.00      0.00      0.00       100\n","          12       0.00      0.00      0.00       100\n","          13       0.00      0.00      0.00       100\n","          14       0.00      0.00      0.00       100\n","          15       0.00      0.00      0.00       100\n","          16       0.00      0.00      0.00       100\n","          17       0.00      0.00      0.00       100\n","          18       0.00      0.00      0.00       100\n","          19       0.00      0.00      0.00       100\n","          20       0.00      0.00      0.00       100\n","          21       0.00      0.00      0.00       100\n","          22       0.00      0.00      0.00       100\n","          23       0.00      0.00      0.00       100\n","          24       0.00      0.00      0.00       100\n","          25       0.00      0.00      0.00       100\n","          26       0.00      0.00      0.00       100\n","          27       0.00      0.00      0.00       100\n","          28       0.00      0.00      0.00       100\n","          29       0.00      0.00      0.00       100\n","          30       0.00      0.00      0.00       100\n","          31       0.00      0.00      0.00       100\n","          32       0.00      0.00      0.00       100\n","          33       0.00      0.00      0.00       100\n","          34       0.00      0.00      0.00       100\n","          35       0.00      0.00      0.00       100\n","          36       0.00      0.00      0.00       100\n","          37       0.00      0.00      0.00       100\n","          38       0.00      0.00      0.00       100\n","          39       0.00      0.00      0.00       100\n","          40       0.00      0.00      0.00       100\n","          41       0.00      0.00      0.00       100\n","          42       0.00      0.00      0.00       100\n","          43       0.00      0.00      0.00       100\n","          44       0.00      0.00      0.00       100\n","          45       0.00      0.00      0.00       100\n","          46       0.00      0.00      0.00       100\n","          47       0.00      0.00      0.00       100\n","          48       0.00      0.00      0.00       100\n","          49       0.00      0.00      0.00       100\n","          50       0.00      0.00      0.00       100\n","          51       0.00      0.00      0.00       100\n","          52       0.00      0.00      0.00       100\n","          53       0.00      0.00      0.00       100\n","          54       0.00      0.00      0.00       100\n","          55       0.00      0.00      0.00       100\n","          56       0.00      0.00      0.00       100\n","          57       0.00      0.00      0.00       100\n","          58       0.00      0.00      0.00       100\n","          59       0.00      0.00      0.00       100\n","          60       0.00      0.00      0.00       100\n","          61       0.00      0.00      0.00       100\n","          62       0.00      0.00      0.00       100\n","          63       0.00      0.00      0.00       100\n","          64       0.00      0.00      0.00       100\n","          65       0.00      0.00      0.00       100\n","          66       0.00      0.00      0.00       100\n","          67       0.00      0.00      0.00       100\n","          68       0.00      0.00      0.00       100\n","          69       0.00      0.00      0.00       100\n","          70       0.00      0.00      0.00       100\n","          71       0.00      0.00      0.00       100\n","          72       0.00      0.00      0.00       100\n","          73       0.00      0.00      0.00       100\n","          74       0.00      0.00      0.00       100\n","          75       0.00      0.00      0.00       100\n","          76       0.00      0.00      0.00       100\n","          77       0.00      0.00      0.00       100\n","          78       0.00      0.00      0.00       100\n","          79       0.00      0.00      0.00       100\n","          80       0.00      0.00      0.00       100\n","          81       0.00      0.00      0.00       100\n","          82       0.00      0.00      0.00       100\n","          83       0.00      0.00      0.00       100\n","          84       0.01      1.00      0.02       100\n","          85       0.00      0.00      0.00       100\n","          86       0.00      0.00      0.00       100\n","          87       0.00      0.00      0.00       100\n","          88       0.00      0.00      0.00       100\n","          89       0.00      0.00      0.00       100\n","          90       0.00      0.00      0.00       100\n","          91       0.00      0.00      0.00       100\n","          92       0.00      0.00      0.00       100\n","          93       0.00      0.00      0.00       100\n","          94       0.00      0.00      0.00       100\n","          95       0.00      0.00      0.00       100\n","          96       0.00      0.00      0.00       100\n","          97       0.00      0.00      0.00       100\n","          98       0.00      0.00      0.00       100\n","          99       0.00      0.00      0.00       100\n","\n","    accuracy                           0.01     10000\n","   macro avg       0.00      0.01      0.00     10000\n","weighted avg       0.00      0.01      0.00     10000\n","\n","Global Sparsity:\n","0.95\n","Fine-tuning...\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 000 Eval Loss: 54.789 Eval Acc: 0.010\n","Epoch: 001 Train Loss: 1.896 Train Acc: 0.510 Eval Loss: 1.050 Eval Acc: 0.695\n","Epoch time: 142.8 Total training time: 154.1\n","\n","Epoch: 002 Train Loss: 1.147 Train Acc: 0.677 Eval Loss: 0.900 Eval Acc: 0.732\n","Epoch time: 143.4 Total training time: 297.5\n","\n","Epoch: 003 Train Loss: 0.946 Train Acc: 0.729 Eval Loss: 0.818 Eval Acc: 0.757\n","Epoch time: 143.2 Total training time: 440.7\n","\n","Epoch: 004 Train Loss: 0.814 Train Acc: 0.770 Eval Loss: 0.818 Eval Acc: 0.753\n","Epoch time: 143.2 Total training time: 583.9\n","\n","Epoch: 005 Train Loss: 0.714 Train Acc: 0.795 Eval Loss: 0.818 Eval Acc: 0.757\n","Epoch time: 143.2 Total training time: 727.1\n","\n","Epoch: 006 Train Loss: 0.654 Train Acc: 0.814 Eval Loss: 0.772 Eval Acc: 0.770\n","Epoch time: 143.5 Total training time: 870.6\n","\n","Epoch: 007 Train Loss: 0.592 Train Acc: 0.833 Eval Loss: 0.800 Eval Acc: 0.765\n","Epoch time: 143.4 Total training time: 1014.0\n","\n","Epoch: 008 Train Loss: 0.555 Train Acc: 0.846 Eval Loss: 0.809 Eval Acc: 0.763\n","Epoch time: 143.6 Total training time: 1157.5\n","\n","Epoch: 009 Train Loss: 0.521 Train Acc: 0.855 Eval Loss: 0.806 Eval Acc: 0.769\n","Epoch time: 142.9 Total training time: 1300.4\n","\n","Epoch: 010 Train Loss: 0.492 Train Acc: 0.864 Eval Loss: 0.805 Eval Acc: 0.768\n","Epoch time: 143.8 Total training time: 1444.2\n","\n","Epoch: 011 Train Loss: 0.463 Train Acc: 0.872 Eval Loss: 0.783 Eval Acc: 0.773\n","Epoch time: 143.3 Total training time: 1587.5\n","\n","Epoch: 012 Train Loss: 0.449 Train Acc: 0.877 Eval Loss: 0.813 Eval Acc: 0.767\n","Epoch time: 143.3 Total training time: 1730.7\n","\n","Epoch: 013 Train Loss: 0.432 Train Acc: 0.883 Eval Loss: 0.796 Eval Acc: 0.771\n","Epoch time: 143.2 Total training time: 1874.0\n","\n","Epoch: 014 Train Loss: 0.420 Train Acc: 0.887 Eval Loss: 0.795 Eval Acc: 0.772\n","Epoch time: 143.1 Total training time: 2017.0\n","\n","Epoch: 015 Train Loss: 0.400 Train Acc: 0.892 Eval Loss: 0.802 Eval Acc: 0.772\n","Epoch time: 143.1 Total training time: 2160.2\n","\n","Epoch: 016 Train Loss: 0.395 Train Acc: 0.893 Eval Loss: 0.823 Eval Acc: 0.766\n","Epoch time: 142.9 Total training time: 2303.1\n","\n","Epoch: 017 Train Loss: 0.388 Train Acc: 0.895 Eval Loss: 0.817 Eval Acc: 0.772\n","Epoch time: 143.1 Total training time: 2446.2\n","\n","Epoch: 018 Train Loss: 0.378 Train Acc: 0.899 Eval Loss: 0.794 Eval Acc: 0.774\n","Epoch time: 143.2 Total training time: 2589.5\n","\n","Epoch: 019 Train Loss: 0.365 Train Acc: 0.904 Eval Loss: 0.808 Eval Acc: 0.771\n","Epoch time: 143.4 Total training time: 2732.9\n","\n","Epoch: 020 Train Loss: 0.291 Train Acc: 0.927 Eval Loss: 0.716 Eval Acc: 0.795\n","Epoch time: 143.7 Total training time: 2876.5\n","\n","Epoch: 021 Train Loss: 0.262 Train Acc: 0.935 Eval Loss: 0.703 Eval Acc: 0.797\n","Epoch time: 143.4 Total training time: 3019.9\n","\n","Epoch: 022 Train Loss: 0.250 Train Acc: 0.939 Eval Loss: 0.703 Eval Acc: 0.798\n","Epoch time: 143.7 Total training time: 3163.6\n","\n","Epoch: 023 Train Loss: 0.245 Train Acc: 0.940 Eval Loss: 0.704 Eval Acc: 0.797\n","Epoch time: 143.6 Total training time: 3307.2\n","\n","Epoch: 024 Train Loss: 0.232 Train Acc: 0.944 Eval Loss: 0.702 Eval Acc: 0.797\n","Epoch time: 143.5 Total training time: 3450.7\n","\n","Epoch: 025 Train Loss: 0.233 Train Acc: 0.944 Eval Loss: 0.700 Eval Acc: 0.800\n","Epoch time: 143.6 Total training time: 3594.3\n","\n","Epoch: 026 Train Loss: 0.227 Train Acc: 0.945 Eval Loss: 0.696 Eval Acc: 0.799\n","Epoch time: 143.2 Total training time: 3737.5\n","\n","Epoch: 027 Train Loss: 0.226 Train Acc: 0.945 Eval Loss: 0.702 Eval Acc: 0.801\n","Epoch time: 143.7 Total training time: 3881.2\n","\n","Epoch: 028 Train Loss: 0.218 Train Acc: 0.946 Eval Loss: 0.697 Eval Acc: 0.800\n","Epoch time: 143.3 Total training time: 4024.5\n","\n","Epoch: 029 Train Loss: 0.217 Train Acc: 0.947 Eval Loss: 0.693 Eval Acc: 0.800\n","Epoch time: 143.3 Total training time: 4167.9\n","\n","Epoch: 030 Train Loss: 0.212 Train Acc: 0.950 Eval Loss: 0.692 Eval Acc: 0.803\n","Epoch time: 144.0 Total training time: 4311.9\n","\n","Test Accuracy: 0.803\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.91      0.94      0.93       100\n","           1       0.90      0.88      0.89       100\n","           2       0.67      0.68      0.68       100\n","           3       0.74      0.65      0.69       100\n","           4       0.71      0.73      0.72       100\n","           5       0.81      0.84      0.82       100\n","           6       0.81      0.81      0.81       100\n","           7       0.83      0.82      0.82       100\n","           8       0.94      0.92      0.93       100\n","           9       0.93      0.90      0.91       100\n","          10       0.73      0.59      0.65       100\n","          11       0.53      0.58      0.55       100\n","          12       0.83      0.83      0.83       100\n","          13       0.77      0.79      0.78       100\n","          14       0.91      0.87      0.89       100\n","          15       0.79      0.89      0.84       100\n","          16       0.86      0.83      0.84       100\n","          17       0.87      0.89      0.88       100\n","          18       0.78      0.80      0.79       100\n","          19       0.82      0.76      0.79       100\n","          20       0.92      0.87      0.89       100\n","          21       0.88      0.91      0.89       100\n","          22       0.83      0.82      0.82       100\n","          23       0.88      0.84      0.86       100\n","          24       0.93      0.87      0.90       100\n","          25       0.76      0.78      0.77       100\n","          26       0.74      0.75      0.74       100\n","          27       0.69      0.72      0.71       100\n","          28       0.89      0.85      0.87       100\n","          29       0.81      0.86      0.83       100\n","          30       0.75      0.86      0.80       100\n","          31       0.82      0.84      0.83       100\n","          32       0.80      0.73      0.76       100\n","          33       0.79      0.67      0.72       100\n","          34       0.77      0.86      0.82       100\n","          35       0.64      0.58      0.61       100\n","          36       0.84      0.85      0.85       100\n","          37       0.84      0.81      0.82       100\n","          38       0.74      0.76      0.75       100\n","          39       0.95      0.94      0.94       100\n","          40       0.78      0.79      0.79       100\n","          41       0.96      0.91      0.93       100\n","          42       0.79      0.82      0.80       100\n","          43       0.90      0.89      0.89       100\n","          44       0.70      0.68      0.69       100\n","          45       0.70      0.71      0.70       100\n","          46       0.61      0.65      0.63       100\n","          47       0.62      0.66      0.64       100\n","          48       0.90      0.98      0.94       100\n","          49       0.80      0.92      0.86       100\n","          50       0.68      0.64      0.66       100\n","          51       0.85      0.83      0.84       100\n","          52       0.64      0.67      0.66       100\n","          53       0.88      0.96      0.92       100\n","          54       0.83      0.87      0.85       100\n","          55       0.53      0.57      0.55       100\n","          56       0.85      0.90      0.87       100\n","          57       0.85      0.88      0.86       100\n","          58       0.91      0.96      0.94       100\n","          59       0.70      0.63      0.66       100\n","          60       0.87      0.86      0.86       100\n","          61       0.78      0.83      0.81       100\n","          62       0.75      0.80      0.77       100\n","          63       0.75      0.75      0.75       100\n","          64       0.78      0.69      0.73       100\n","          65       0.71      0.75      0.73       100\n","          66       0.94      0.90      0.92       100\n","          67       0.75      0.68      0.71       100\n","          68       0.91      0.96      0.93       100\n","          69       0.87      0.88      0.88       100\n","          70       0.82      0.79      0.81       100\n","          71       0.80      0.81      0.81       100\n","          72       0.64      0.57      0.60       100\n","          73       0.74      0.73      0.73       100\n","          74       0.67      0.62      0.64       100\n","          75       0.94      0.91      0.92       100\n","          76       0.88      0.92      0.90       100\n","          77       0.81      0.82      0.82       100\n","          78       0.75      0.76      0.76       100\n","          79       0.84      0.87      0.85       100\n","          80       0.71      0.76      0.73       100\n","          81       0.78      0.77      0.77       100\n","          82       0.94      0.95      0.95       100\n","          83       0.86      0.78      0.82       100\n","          84       0.87      0.80      0.83       100\n","          85       0.90      0.88      0.89       100\n","          86       0.90      0.80      0.85       100\n","          87       0.90      0.92      0.91       100\n","          88       0.89      0.86      0.87       100\n","          89       0.86      0.91      0.88       100\n","          90       0.83      0.84      0.84       100\n","          91       0.89      0.86      0.87       100\n","          92       0.74      0.72      0.73       100\n","          93       0.84      0.73      0.78       100\n","          94       0.86      0.95      0.90       100\n","          95       0.83      0.78      0.80       100\n","          96       0.63      0.69      0.66       100\n","          97       0.85      0.88      0.87       100\n","          98       0.63      0.63      0.63       100\n","          99       0.83      0.80      0.82       100\n","\n","    accuracy                           0.80     10000\n","   macro avg       0.80      0.80      0.80     10000\n","weighted avg       0.80      0.80      0.80     10000\n","\n","Global Sparsity:\n","0.95\n"]},{"ename":"KeyError","evalue":"'state_dict'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[50], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPruning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43miterative_pruning_finetuning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpruned_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcuda_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_regularization_strength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml1_regularization_strength\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml2_regularization_strength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml2_regularization_strength\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconv2d_prune_amount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinear_prune_amount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs_per_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_filename_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_filename_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrouped_pruning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[15], line 119\u001b[0m, in \u001b[0;36miterative_pruning_finetuning\u001b[0;34m(model, train_loader, test_loader, device, learning_rate, l1_regularization_strength, l2_regularization_strength, weight_decay, learning_rate_decay, conv2d_prune_amount, linear_prune_amount, num_iterations, num_epochs_per_iteration, model_filename_prefix, model_dir, grouped_pruning)\u001b[0m\n\u001b[1;32m    114\u001b[0m     model_filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, model_filename)\n\u001b[1;32m    115\u001b[0m     save_model(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    116\u001b[0m                model_dir\u001b[38;5;241m=\u001b[39mmodel_dir,\n\u001b[1;32m    117\u001b[0m                model_filename\u001b[38;5;241m=\u001b[39mmodel_filename)\n\u001b[0;32m--> 119\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mmodel_filepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_filepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n","Cell \u001b[0;32mIn[13], line 3\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model, model_filepath, device)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(model, model_filepath, device):\n\u001b[0;32m----> 3\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_filepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n","\u001b[0;31mKeyError\u001b[0m: 'state_dict'"]}],"source":["print(\"Pruning...\")\n","iterative_pruning_finetuning(\n","        model=pruned_model,\n","        train_loader=train_loader,\n","        test_loader=test_loader,\n","        device=cuda_device,\n","        learning_rate=learning_rate,\n","        learning_rate_decay=learning_rate_decay,\n","        l1_regularization_strength=l1_regularization_strength,\n","        l2_regularization_strength=l2_regularization_strength,\n","        weight_decay=weight_decay,\n","        conv2d_prune_amount=0.95,\n","        linear_prune_amount=0,\n","        num_iterations=1,           \n","        num_epochs_per_iteration=30,  \n","        model_filename_prefix=model_filename_prefix,\n","        model_dir=model_dir,\n","        grouped_pruning=True)"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T16:01:02.116917Z","iopub.status.busy":"2024-03-30T16:01:02.116507Z","iopub.status.idle":"2024-03-30T16:01:02.171796Z","shell.execute_reply":"2024-03-30T16:01:02.170718Z","shell.execute_reply.started":"2024-03-30T16:01:02.116884Z"},"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":51,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-05-06T16:07:56.868196Z","iopub.status.busy":"2024-05-06T16:07:56.867402Z","iopub.status.idle":"2024-05-06T16:07:56.877746Z","shell.execute_reply":"2024-05-06T16:07:56.876718Z","shell.execute_reply.started":"2024-05-06T16:07:56.868160Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (3): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (3): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (4): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (5): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=100, bias=True)\n",")"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["pruned_model"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T16:07:11.949199Z","iopub.status.busy":"2024-03-30T16:07:11.948585Z","iopub.status.idle":"2024-03-30T16:07:12.177197Z","shell.execute_reply":"2024-03-30T16:07:12.176197Z","shell.execute_reply.started":"2024-03-30T16:07:11.949168Z"},"trusted":true},"outputs":[],"source":["save_model(model=pruned_model, model_dir=\"saved_models\", model_filename=\"trained_prune_rate0.95_accuracy0.961_with_masks\")"]},{"cell_type":"code","execution_count":52,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-05-06T16:08:09.034396Z","iopub.status.busy":"2024-05-06T16:08:09.033692Z","iopub.status.idle":"2024-05-06T16:08:20.227075Z","shell.execute_reply":"2024-05-06T16:08:20.225948Z","shell.execute_reply.started":"2024-05-06T16:08:09.034369Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.91      0.94      0.93       100\n","           1       0.90      0.88      0.89       100\n","           2       0.67      0.68      0.68       100\n","           3       0.74      0.65      0.69       100\n","           4       0.71      0.73      0.72       100\n","           5       0.81      0.84      0.82       100\n","           6       0.81      0.81      0.81       100\n","           7       0.83      0.82      0.82       100\n","           8       0.94      0.92      0.93       100\n","           9       0.93      0.90      0.91       100\n","          10       0.73      0.59      0.65       100\n","          11       0.53      0.58      0.55       100\n","          12       0.83      0.83      0.83       100\n","          13       0.77      0.79      0.78       100\n","          14       0.91      0.87      0.89       100\n","          15       0.79      0.89      0.84       100\n","          16       0.86      0.83      0.84       100\n","          17       0.87      0.89      0.88       100\n","          18       0.78      0.80      0.79       100\n","          19       0.82      0.76      0.79       100\n","          20       0.92      0.87      0.89       100\n","          21       0.88      0.91      0.89       100\n","          22       0.83      0.82      0.82       100\n","          23       0.88      0.84      0.86       100\n","          24       0.93      0.87      0.90       100\n","          25       0.76      0.78      0.77       100\n","          26       0.74      0.75      0.74       100\n","          27       0.69      0.72      0.71       100\n","          28       0.89      0.85      0.87       100\n","          29       0.81      0.86      0.83       100\n","          30       0.75      0.86      0.80       100\n","          31       0.82      0.84      0.83       100\n","          32       0.80      0.73      0.76       100\n","          33       0.79      0.67      0.72       100\n","          34       0.77      0.86      0.82       100\n","          35       0.64      0.58      0.61       100\n","          36       0.84      0.85      0.85       100\n","          37       0.84      0.81      0.82       100\n","          38       0.74      0.76      0.75       100\n","          39       0.95      0.94      0.94       100\n","          40       0.78      0.79      0.79       100\n","          41       0.96      0.91      0.93       100\n","          42       0.79      0.82      0.80       100\n","          43       0.90      0.89      0.89       100\n","          44       0.70      0.68      0.69       100\n","          45       0.70      0.71      0.70       100\n","          46       0.61      0.65      0.63       100\n","          47       0.62      0.66      0.64       100\n","          48       0.90      0.98      0.94       100\n","          49       0.80      0.92      0.86       100\n","          50       0.68      0.64      0.66       100\n","          51       0.85      0.83      0.84       100\n","          52       0.64      0.67      0.66       100\n","          53       0.88      0.96      0.92       100\n","          54       0.83      0.87      0.85       100\n","          55       0.53      0.57      0.55       100\n","          56       0.85      0.90      0.87       100\n","          57       0.85      0.88      0.86       100\n","          58       0.91      0.96      0.94       100\n","          59       0.70      0.63      0.66       100\n","          60       0.87      0.86      0.86       100\n","          61       0.78      0.83      0.81       100\n","          62       0.75      0.80      0.77       100\n","          63       0.75      0.75      0.75       100\n","          64       0.78      0.69      0.73       100\n","          65       0.71      0.75      0.73       100\n","          66       0.94      0.90      0.92       100\n","          67       0.75      0.68      0.71       100\n","          68       0.91      0.96      0.93       100\n","          69       0.87      0.88      0.88       100\n","          70       0.82      0.79      0.81       100\n","          71       0.80      0.81      0.81       100\n","          72       0.64      0.57      0.60       100\n","          73       0.74      0.73      0.73       100\n","          74       0.67      0.62      0.64       100\n","          75       0.94      0.91      0.92       100\n","          76       0.88      0.92      0.90       100\n","          77       0.81      0.82      0.82       100\n","          78       0.75      0.76      0.76       100\n","          79       0.84      0.87      0.85       100\n","          80       0.71      0.76      0.73       100\n","          81       0.78      0.77      0.77       100\n","          82       0.94      0.95      0.95       100\n","          83       0.86      0.78      0.82       100\n","          84       0.87      0.80      0.83       100\n","          85       0.90      0.88      0.89       100\n","          86       0.90      0.80      0.85       100\n","          87       0.90      0.92      0.91       100\n","          88       0.89      0.86      0.87       100\n","          89       0.86      0.91      0.88       100\n","          90       0.83      0.84      0.84       100\n","          91       0.89      0.86      0.87       100\n","          92       0.74      0.72      0.73       100\n","          93       0.84      0.73      0.78       100\n","          94       0.86      0.95      0.90       100\n","          95       0.83      0.78      0.80       100\n","          96       0.63      0.69      0.66       100\n","          97       0.85      0.88      0.87       100\n","          98       0.63      0.63      0.63       100\n","          99       0.83      0.80      0.82       100\n","\n","    accuracy                           0.80     10000\n","   macro avg       0.80      0.80      0.80     10000\n","weighted avg       0.80      0.80      0.80     10000\n","\n"]}],"source":["classification_report = create_classification_report(\n","        model=pruned_model, test_loader=test_loader, device=cuda_device)\n","print(classification_report)"]},{"cell_type":"code","execution_count":54,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-05-06T16:08:47.110628Z","iopub.status.busy":"2024-05-06T16:08:47.110239Z","iopub.status.idle":"2024-05-06T16:08:47.123081Z","shell.execute_reply":"2024-05-06T16:08:47.121961Z","shell.execute_reply.started":"2024-05-06T16:08:47.110598Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.91      0.94      0.93       100\n","           1       0.90      0.88      0.89       100\n","           2       0.67      0.68      0.68       100\n","           3       0.74      0.65      0.69       100\n","           4       0.71      0.73      0.72       100\n","           5       0.81      0.84      0.82       100\n","           6       0.81      0.81      0.81       100\n","           7       0.83      0.82      0.82       100\n","           8       0.94      0.92      0.93       100\n","           9       0.93      0.90      0.91       100\n","          10       0.73      0.59      0.65       100\n","          11       0.53      0.58      0.55       100\n","          12       0.83      0.83      0.83       100\n","          13       0.77      0.79      0.78       100\n","          14       0.91      0.87      0.89       100\n","          15       0.79      0.89      0.84       100\n","          16       0.86      0.83      0.84       100\n","          17       0.87      0.89      0.88       100\n","          18       0.78      0.80      0.79       100\n","          19       0.82      0.76      0.79       100\n","          20       0.92      0.87      0.89       100\n","          21       0.88      0.91      0.89       100\n","          22       0.83      0.82      0.82       100\n","          23       0.88      0.84      0.86       100\n","          24       0.93      0.87      0.90       100\n","          25       0.76      0.78      0.77       100\n","          26       0.74      0.75      0.74       100\n","          27       0.69      0.72      0.71       100\n","          28       0.89      0.85      0.87       100\n","          29       0.81      0.86      0.83       100\n","          30       0.75      0.86      0.80       100\n","          31       0.82      0.84      0.83       100\n","          32       0.80      0.73      0.76       100\n","          33       0.79      0.67      0.72       100\n","          34       0.77      0.86      0.82       100\n","          35       0.64      0.58      0.61       100\n","          36       0.84      0.85      0.85       100\n","          37       0.84      0.81      0.82       100\n","          38       0.74      0.76      0.75       100\n","          39       0.95      0.94      0.94       100\n","          40       0.78      0.79      0.79       100\n","          41       0.96      0.91      0.93       100\n","          42       0.79      0.82      0.80       100\n","          43       0.90      0.89      0.89       100\n","          44       0.70      0.68      0.69       100\n","          45       0.70      0.71      0.70       100\n","          46       0.61      0.65      0.63       100\n","          47       0.62      0.66      0.64       100\n","          48       0.90      0.98      0.94       100\n","          49       0.80      0.92      0.86       100\n","          50       0.68      0.64      0.66       100\n","          51       0.85      0.83      0.84       100\n","          52       0.64      0.67      0.66       100\n","          53       0.88      0.96      0.92       100\n","          54       0.83      0.87      0.85       100\n","          55       0.53      0.57      0.55       100\n","          56       0.85      0.90      0.87       100\n","          57       0.85      0.88      0.86       100\n","          58       0.91      0.96      0.94       100\n","          59       0.70      0.63      0.66       100\n","          60       0.87      0.86      0.86       100\n","          61       0.78      0.83      0.81       100\n","          62       0.75      0.80      0.77       100\n","          63       0.75      0.75      0.75       100\n","          64       0.78      0.69      0.73       100\n","          65       0.71      0.75      0.73       100\n","          66       0.94      0.90      0.92       100\n","          67       0.75      0.68      0.71       100\n","          68       0.91      0.96      0.93       100\n","          69       0.87      0.88      0.88       100\n","          70       0.82      0.79      0.81       100\n","          71       0.80      0.81      0.81       100\n","          72       0.64      0.57      0.60       100\n","          73       0.74      0.73      0.73       100\n","          74       0.67      0.62      0.64       100\n","          75       0.94      0.91      0.92       100\n","          76       0.88      0.92      0.90       100\n","          77       0.81      0.82      0.82       100\n","          78       0.75      0.76      0.76       100\n","          79       0.84      0.87      0.85       100\n","          80       0.71      0.76      0.73       100\n","          81       0.78      0.77      0.77       100\n","          82       0.94      0.95      0.95       100\n","          83       0.86      0.78      0.82       100\n","          84       0.87      0.80      0.83       100\n","          85       0.90      0.88      0.89       100\n","          86       0.90      0.80      0.85       100\n","          87       0.90      0.92      0.91       100\n","          88       0.89      0.86      0.87       100\n","          89       0.86      0.91      0.88       100\n","          90       0.83      0.84      0.84       100\n","          91       0.89      0.86      0.87       100\n","          92       0.74      0.72      0.73       100\n","          93       0.84      0.73      0.78       100\n","          94       0.86      0.95      0.90       100\n","          95       0.83      0.78      0.80       100\n","          96       0.63      0.69      0.66       100\n","          97       0.85      0.88      0.87       100\n","          98       0.63      0.63      0.63       100\n","          99       0.83      0.80      0.82       100\n","\n","    accuracy                           0.80     10000\n","   macro avg       0.80      0.80      0.80     10000\n","weighted avg       0.80      0.80      0.80     10000\n","\n","Global Sparsity:\n","0.95\n"]}],"source":["num_zeros, num_elements, sparsity = measure_global_sparsity(pruned_model, conv2d_use_mask=True)\n","\n","#print(\"Test Accuracy: {:.3f}\".format(eval_accuracy))\n","print(\"Classification Report:\")\n","print(classification_report)\n","print(\"Global Sparsity:\")\n","print(\"{:.2f}\".format(sparsity))"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T16:11:17.620690Z","iopub.status.busy":"2024-05-06T16:11:17.619941Z","iopub.status.idle":"2024-05-06T16:11:17.949634Z","shell.execute_reply":"2024-05-06T16:11:17.948818Z","shell.execute_reply.started":"2024-05-06T16:11:17.620661Z"},"trusted":true},"outputs":[],"source":["checkpoint = torch.load(\"/kaggle/working/checkpoint_epoch30.pth.tar\")"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T16:35:01.338792Z","iopub.status.busy":"2024-05-06T16:35:01.338410Z","iopub.status.idle":"2024-05-06T16:35:03.507760Z","shell.execute_reply":"2024-05-06T16:35:03.506791Z","shell.execute_reply.started":"2024-05-06T16:35:01.338766Z"},"trusted":true},"outputs":[],"source":["a = create_model(num_classes=num_classes)\n","parameters_to_prune = []\n","    # Substitute the FC output layer\n","a.fc = torch.nn.Linear(a.fc.in_features, 100)\n","for module_name, module in a.named_modules():\n","    if isinstance(module, torch.nn.Conv2d):\n","        parameters_to_prune.append((module, \"weight\"))\n","prune.global_unstructured(\n","                        parameters_to_prune,\n","                        pruning_method=prune.L1Unstructured,\n","                        amount=0,\n","                        )\n","\n","    # Load a pretrained model.\n","a = load_model(model=a,\n","                    model_filepath=\"/kaggle/working/checkpoint_epoch30.pth.tar\",\n","                    device=cuda_device)"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T16:35:17.711379Z","iopub.status.busy":"2024-05-06T16:35:17.710979Z","iopub.status.idle":"2024-05-06T16:35:29.491346Z","shell.execute_reply":"2024-05-06T16:35:29.490096Z","shell.execute_reply.started":"2024-05-06T16:35:17.711348Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.91      0.94      0.93       100\n","           1       0.90      0.88      0.89       100\n","           2       0.67      0.68      0.68       100\n","           3       0.74      0.65      0.69       100\n","           4       0.71      0.73      0.72       100\n","           5       0.81      0.84      0.82       100\n","           6       0.81      0.81      0.81       100\n","           7       0.83      0.82      0.82       100\n","           8       0.94      0.92      0.93       100\n","           9       0.93      0.90      0.91       100\n","          10       0.73      0.59      0.65       100\n","          11       0.53      0.58      0.55       100\n","          12       0.83      0.83      0.83       100\n","          13       0.77      0.79      0.78       100\n","          14       0.91      0.87      0.89       100\n","          15       0.79      0.89      0.84       100\n","          16       0.86      0.83      0.84       100\n","          17       0.87      0.89      0.88       100\n","          18       0.78      0.80      0.79       100\n","          19       0.82      0.76      0.79       100\n","          20       0.92      0.87      0.89       100\n","          21       0.88      0.91      0.89       100\n","          22       0.83      0.82      0.82       100\n","          23       0.88      0.84      0.86       100\n","          24       0.93      0.87      0.90       100\n","          25       0.76      0.78      0.77       100\n","          26       0.74      0.75      0.74       100\n","          27       0.69      0.72      0.71       100\n","          28       0.89      0.85      0.87       100\n","          29       0.81      0.86      0.83       100\n","          30       0.75      0.86      0.80       100\n","          31       0.82      0.84      0.83       100\n","          32       0.80      0.73      0.76       100\n","          33       0.79      0.67      0.72       100\n","          34       0.77      0.86      0.82       100\n","          35       0.64      0.58      0.61       100\n","          36       0.84      0.85      0.85       100\n","          37       0.84      0.81      0.82       100\n","          38       0.74      0.76      0.75       100\n","          39       0.95      0.94      0.94       100\n","          40       0.78      0.79      0.79       100\n","          41       0.96      0.91      0.93       100\n","          42       0.79      0.82      0.80       100\n","          43       0.90      0.89      0.89       100\n","          44       0.70      0.68      0.69       100\n","          45       0.70      0.71      0.70       100\n","          46       0.61      0.65      0.63       100\n","          47       0.62      0.66      0.64       100\n","          48       0.90      0.98      0.94       100\n","          49       0.80      0.92      0.86       100\n","          50       0.68      0.64      0.66       100\n","          51       0.85      0.83      0.84       100\n","          52       0.64      0.67      0.66       100\n","          53       0.88      0.96      0.92       100\n","          54       0.83      0.87      0.85       100\n","          55       0.53      0.57      0.55       100\n","          56       0.85      0.90      0.87       100\n","          57       0.85      0.88      0.86       100\n","          58       0.91      0.96      0.94       100\n","          59       0.70      0.63      0.66       100\n","          60       0.87      0.86      0.86       100\n","          61       0.78      0.83      0.81       100\n","          62       0.75      0.80      0.77       100\n","          63       0.75      0.75      0.75       100\n","          64       0.78      0.69      0.73       100\n","          65       0.71      0.75      0.73       100\n","          66       0.94      0.90      0.92       100\n","          67       0.75      0.68      0.71       100\n","          68       0.91      0.96      0.93       100\n","          69       0.87      0.88      0.88       100\n","          70       0.82      0.79      0.81       100\n","          71       0.80      0.81      0.81       100\n","          72       0.64      0.57      0.60       100\n","          73       0.74      0.73      0.73       100\n","          74       0.67      0.62      0.64       100\n","          75       0.94      0.91      0.92       100\n","          76       0.88      0.92      0.90       100\n","          77       0.81      0.82      0.82       100\n","          78       0.75      0.76      0.76       100\n","          79       0.84      0.87      0.85       100\n","          80       0.71      0.76      0.73       100\n","          81       0.78      0.77      0.77       100\n","          82       0.94      0.95      0.95       100\n","          83       0.86      0.78      0.82       100\n","          84       0.87      0.80      0.83       100\n","          85       0.90      0.88      0.89       100\n","          86       0.90      0.80      0.85       100\n","          87       0.90      0.92      0.91       100\n","          88       0.89      0.86      0.87       100\n","          89       0.86      0.91      0.88       100\n","          90       0.83      0.84      0.84       100\n","          91       0.89      0.86      0.87       100\n","          92       0.74      0.72      0.73       100\n","          93       0.84      0.73      0.78       100\n","          94       0.86      0.95      0.90       100\n","          95       0.83      0.78      0.80       100\n","          96       0.63      0.69      0.66       100\n","          97       0.85      0.88      0.87       100\n","          98       0.63      0.63      0.63       100\n","          99       0.83      0.80      0.82       100\n","\n","    accuracy                           0.80     10000\n","   macro avg       0.80      0.80      0.80     10000\n","weighted avg       0.80      0.80      0.80     10000\n","\n"]}],"source":["classification_report = create_classification_report(\n","        model=a, test_loader=test_loader, device=cuda_device)\n","print(classification_report)"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T16:35:49.224635Z","iopub.status.busy":"2024-05-06T16:35:49.223574Z","iopub.status.idle":"2024-05-06T16:35:49.235240Z","shell.execute_reply":"2024-05-06T16:35:49.234219Z","shell.execute_reply.started":"2024-05-06T16:35:49.224593Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9477184695908522\n"]}],"source":["num_zeros, num_elements, sparsity = measure_global_sparsity(a, conv2d_use_mask=True)\n","print(sparsity)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"isSourceIdPinned":true,"modelInstanceId":16433,"sourceId":19809,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":true,"modelInstanceId":37215,"sourceId":44307,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
