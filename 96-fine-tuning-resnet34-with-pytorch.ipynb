{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from random import random\n","import os\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-08-06T07:30:31.01273Z","iopub.status.busy":"2021-08-06T07:30:31.008273Z","iopub.status.idle":"2021-08-06T07:32:14.161735Z","shell.execute_reply":"2021-08-06T07:32:14.160369Z","shell.execute_reply.started":"2021-08-06T07:30:31.012664Z"},"trusted":true},"outputs":[],"source":["!pip install -q --upgrade torchvision"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-08-06T07:32:14.164382Z","iopub.status.busy":"2021-08-06T07:32:14.163787Z","iopub.status.idle":"2021-08-06T07:34:10.442974Z","shell.execute_reply":"2021-08-06T07:34:10.441334Z","shell.execute_reply.started":"2021-08-06T07:32:14.164334Z"},"trusted":true},"outputs":[],"source":["import torchvision\n","import torch\n","\n","#train_dataset = torchvision.datasets.ImageFolder(\n","#    root/'train', \n","#    transform=torchvision.transforms.Compose([\n","#        # Resize step is required as we will use a ResNet model, which accepts at leats 224x224 images\n","#        torchvision.transforms.Resize((224,224)),  \n","#        torchvision.transforms.ToTensor(),\n","#    ])\n","#)\n","\n","train_dataset = torchvision.datasets.CIFAR10(root=\"data\",\n","                                             train=True,\n","                                             download=True,\n","                                             transform=torchvision.transforms.Compose([\n","        # Resize step is required as we will use a ResNet model, which accepts at leats 224x224 images\n","        torchvision.transforms.Resize((224,224)),  \n","        torchvision.transforms.ToTensor(),\n","    ]))\n","\n","train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=512, shuffle=False, num_workers=2, pin_memory=True)\n","\n","means = []\n","stdevs = []\n","for X, _ in train_dataloader:\n","    # Dimensions 0,2,3 are respectively the batch, height and width dimensions\n","    means.append(X.mean(dim=(0,2,3)))\n","    stdevs.append(X.std(dim=(0,2,3)))\n","\n","mean = torch.stack(means, dim=0).mean(dim=0)\n","stdev = torch.stack(stdevs, dim=0).mean(dim=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-08-06T07:34:10.445657Z","iopub.status.busy":"2021-08-06T07:34:10.445189Z","iopub.status.idle":"2021-08-06T07:34:12.886638Z","shell.execute_reply":"2021-08-06T07:34:12.885463Z","shell.execute_reply.started":"2021-08-06T07:34:10.445591Z"},"trusted":true},"outputs":[],"source":["train_transforms = torchvision.transforms.Compose([\n","        torchvision.transforms.Resize((224,224)),\n","        torchvision.transforms.AutoAugment(policy=torchvision.transforms.AutoAugmentPolicy.CIFAR10),\n","        torchvision.transforms.ToTensor(),\n","        torchvision.transforms.Normalize(mean, stdev)\n","    ])\n","\n","#train_dataset, train_valid_dataset = [torchvision.datasets.ImageFolder(folder, transform=train_transforms) for folder in [root/'train', root/'train_valid']]\n","train_dataset = torchvision.datasets.CIFAR10(root=\"data\",\n","                                             train=True,\n","                                             download=True,\n","                                             transform=train_transforms)\n","\n","valid_transforms = torchvision.transforms.Compose([\n","        torchvision.transforms.Resize((224,224)),\n","        torchvision.transforms.ToTensor(),\n","        torchvision.transforms.Normalize(mean, stdev)\n","    ])\n","\n","#valid_dataset, test_dataset = [torchvision.datasets.ImageFolder(folder, transform=valid_transforms) for folder in [root/'valid', root/'test']]\n","\n","valid_dataset = torchvision.datasets.CIFAR10(root=\"data\",\n","                                            train=False,\n","                                            download=True,\n","                                            transform=valid_transforms)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-08-06T07:34:12.888999Z","iopub.status.busy":"2021-08-06T07:34:12.888525Z","iopub.status.idle":"2021-08-06T07:34:12.902217Z","shell.execute_reply":"2021-08-06T07:34:12.900316Z","shell.execute_reply.started":"2021-08-06T07:34:12.888946Z"},"trusted":true},"outputs":[],"source":["num_gpus = torch.cuda.device_count()\n","\n","train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2*num_gpus, pin_memory=True)\n","train_valid_dataloader = torch.utils.data.DataLoader(train_valid_dataset, batch_size=128, shuffle=True, num_workers=2*num_gpus, pin_memory=True)\n","\n","valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=256, shuffle=False, num_workers=2*num_gpus, pin_memory=True)\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2*num_gpus, pin_memory=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-08-06T07:34:12.907206Z","iopub.status.busy":"2021-08-06T07:34:12.906359Z","iopub.status.idle":"2021-08-06T07:34:12.91449Z","shell.execute_reply":"2021-08-06T07:34:12.913141Z","shell.execute_reply.started":"2021-08-06T07:34:12.907155Z"},"trusted":true},"outputs":[],"source":["def get_net():\n","    resnet = torchvision.models.resnet34(pretrained=True)\n","    \n","    # Substitute the FC output layer\n","    resnet.fc = torch.nn.Linear(resnet.fc.in_features, 10)\n","    torch.nn.init.xavier_uniform_(resnet.fc.weight)\n","    return resnet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-08-06T07:34:12.917457Z","iopub.status.busy":"2021-08-06T07:34:12.916969Z","iopub.status.idle":"2021-08-06T07:34:12.938347Z","shell.execute_reply":"2021-08-06T07:34:12.936783Z","shell.execute_reply.started":"2021-08-06T07:34:12.917411Z"},"trusted":true},"outputs":[],"source":["import time\n","\n","def train(net, train_dataloader, valid_dataloader, criterion, optimizer, scheduler=None, epochs=10, device='cpu', checkpoint_epochs=10):\n","    start = time.time()\n","    print(f'Training for {epochs} epochs on {device}')\n","    \n","    for epoch in range(1,epochs+1):\n","        print(f\"Epoch {epoch}/{epochs}\")\n","        \n","        net.train()  # put network in train mode for Dropout and Batch Normalization\n","        train_loss = torch.tensor(0., device=device)  # loss and accuracy tensors are on the GPU to avoid data transfers\n","        train_accuracy = torch.tensor(0., device=device)\n","        for X, y in train_dataloader:\n","            X = X.to(device)\n","            y = y.to(device)\n","            preds = net(X)\n","            loss = criterion(preds, y)\n","            \n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            \n","            with torch.no_grad():\n","                train_loss += loss * train_dataloader.batch_size\n","                train_accuracy += (torch.argmax(preds, dim=1) == y).sum()\n","        \n","        if valid_dataloader is not None:\n","            net.eval()  # put network in train mode for Dropout and Batch Normalization\n","            valid_loss = torch.tensor(0., device=device)\n","            valid_accuracy = torch.tensor(0., device=device)\n","            with torch.no_grad():\n","                for X, y in valid_dataloader:\n","                    X = X.to(device)\n","                    y = y.to(device)\n","                    preds = net(X)\n","                    loss = criterion(preds, y)\n","\n","                    valid_loss += loss * valid_dataloader.batch_size\n","                    valid_accuracy += (torch.argmax(preds, dim=1) == y).sum()\n","        \n","        if scheduler is not None: \n","            scheduler.step()\n","            \n","        print(f'Training loss: {train_loss/len(train_dataloader.dataset):.2f}')\n","        print(f'Training accuracy: {100*train_accuracy/len(train_dataloader.dataset):.2f}')\n","        \n","        if valid_dataloader is not None:\n","            print(f'Valid loss: {valid_loss/len(valid_dataloader.dataset):.2f}')\n","            print(f'Valid accuracy: {100*valid_accuracy/len(valid_dataloader.dataset):.2f}')\n","        \n","        if epoch%checkpoint_epochs==0:\n","            torch.save({\n","                'epoch': epoch,\n","                'state_dict': net.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","            }, './checkpoint.pth.tar')\n","        \n","        print()\n","    \n","    end = time.time()\n","    print(f'Total training time: {end-start:.1f} seconds')\n","    return net"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-08-06T07:34:12.940722Z","iopub.status.busy":"2021-08-06T07:34:12.9401Z","iopub.status.idle":"2021-08-06T08:27:42.722397Z","shell.execute_reply":"2021-08-06T08:27:42.720883Z","shell.execute_reply.started":"2021-08-06T07:34:12.940655Z"},"trusted":true},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","lr, weight_decay, epochs = 1e-5, 5e-4, 20\n","\n","net = get_net().to(device)\n","\n","# Standard CrossEntropy Loss for multi-class classification problems\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","# params_1x are the parameters of the network body, i.e., of all layers except the FC layers\n","params_1x = [param for name, param in net.named_parameters() if 'fc' not in str(name)]\n","optimizer = torch.optim.Adam([{'params':params_1x}, {'params': net.fc.parameters(), 'lr': lr*10}], lr=lr, weight_decay=weight_decay)\n","\n","net = train(net, train_dataloader, valid_dataloader, criterion, optimizer, None, epochs, device)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
