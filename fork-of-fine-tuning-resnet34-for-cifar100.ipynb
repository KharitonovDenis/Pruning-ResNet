{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Fine-Tuning with PyTorch\n","\n","Throughout this notebook, we use the CIFAR-100 dataset, a popular computer-vision dataset of 60,000 32x32 color images to be classified in one of 100 classes, with 600 images per class."]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:46:28.632641Z","iopub.status.busy":"2024-05-08T14:46:28.632232Z","iopub.status.idle":"2024-05-08T14:46:28.637701Z","shell.execute_reply":"2024-05-08T14:46:28.636256Z","shell.execute_reply.started":"2024-05-08T14:46:28.632601Z"},"trusted":true},"outputs":[],"source":["#from random import random\n","import os\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{},"source":["## Datasets and DataLoaders <a name='data'></a>\n","\n","As mentioned above, we rely on the `ImageDataset` class of PyTorch to create the required datasets for training, validation, training+validation and testing. Out of each dataset, we then create a DataLoader to be used in the training/evaluation loops to efficiently fetch images in batches from disk."]},{"cell_type":"markdown","metadata":{},"source":["We perform an initial step to load in the train data and compute the mean and standard deviation of the dataset for each channel (R, G, B), across all images and all pixels. We compute a mean and stdev value batch-by-batch to avoid loading the entire dataset in memory, and then compute the mean of the means and of the stdevs.  \n","**NOTE**: if you have enough RAM (or memory on the GPU), you can use a batch_size equal to the entire train_dataset length, it will provide a more accurate estimation of the means and stdevs by channel."]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:46:31.304222Z","iopub.status.busy":"2024-05-08T14:46:31.303358Z","iopub.status.idle":"2024-05-08T14:46:31.308366Z","shell.execute_reply":"2024-05-08T14:46:31.307142Z","shell.execute_reply.started":"2024-05-08T14:46:31.304188Z"},"trusted":true},"outputs":[],"source":["#!pip install -q --upgrade torchvision"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:46:31.682504Z","iopub.status.busy":"2024-05-08T14:46:31.682079Z","iopub.status.idle":"2024-05-08T14:46:31.687478Z","shell.execute_reply":"2024-05-08T14:46:31.686325Z","shell.execute_reply.started":"2024-05-08T14:46:31.682464Z"},"trusted":true},"outputs":[],"source":["import torchvision\n","import torch"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:46:32.655826Z","iopub.status.busy":"2024-05-08T14:46:32.655055Z","iopub.status.idle":"2024-05-08T14:46:32.660644Z","shell.execute_reply":"2024-05-08T14:46:32.659334Z","shell.execute_reply.started":"2024-05-08T14:46:32.655787Z"},"trusted":true},"outputs":[],"source":["import sklearn\n","import copy"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:46:33.533656Z","iopub.status.busy":"2024-05-08T14:46:33.533245Z","iopub.status.idle":"2024-05-08T14:46:33.577784Z","shell.execute_reply":"2024-05-08T14:46:33.576383Z","shell.execute_reply.started":"2024-05-08T14:46:33.533624Z"},"trusted":true},"outputs":[],"source":["#import os\n","import time\n","import math\n","import random\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","import glob\n","\n","import matplotlib.pyplot as plt\n","from PIL import Image, ImageEnhance, ImageOps\n","\n","from tqdm import tqdm, tqdm_notebook\n","\n","import torch\n","from torch import nn, cuda\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","import torchvision as vision\n","import torchvision.models as models\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import Adam, SGD, Optimizer\n","from torch.optim.lr_scheduler import _LRScheduler, CosineAnnealingLR, ReduceLROnPlateau\n","\n","from sklearn.metrics import f1_score\n","\n","class CIFAR10Policy(object):\n","    \"\"\" Randomly choose one of the best 25 Sub-policies on CIFAR10.\n","        Example:\n","        >>> policy = CIFAR10Policy()\n","        >>> transformed = policy(image)\n","        Example as a PyTorch Transform:\n","        >>> transform=transforms.Compose([\n","        >>>     transforms.Resize(256),\n","        >>>     CIFAR10Policy(),\n","        >>>     transforms.ToTensor()])\n","    \"\"\"\n","    def __init__(self, fillcolor=(128, 128, 128)):\n","        self.policies = [\n","            SubPolicy(0.1, \"invert\", 7, 0.2, \"contrast\", 6, fillcolor),\n","            SubPolicy(0.7, \"rotate\", 2, 0.3, \"translateX\", 9, fillcolor),\n","            SubPolicy(0.8, \"sharpness\", 1, 0.9, \"sharpness\", 3, fillcolor),\n","            SubPolicy(0.5, \"shearY\", 8, 0.7, \"translateY\", 9, fillcolor),\n","            SubPolicy(0.5, \"autocontrast\", 8, 0.9, \"equalize\", 2, fillcolor),\n","\n","            SubPolicy(0.2, \"shearY\", 7, 0.3, \"posterize\", 7, fillcolor),\n","            SubPolicy(0.4, \"color\", 3, 0.6, \"brightness\", 7, fillcolor),\n","            SubPolicy(0.3, \"sharpness\", 9, 0.7, \"brightness\", 9, fillcolor),\n","            SubPolicy(0.6, \"equalize\", 5, 0.5, \"equalize\", 1, fillcolor),\n","            SubPolicy(0.6, \"contrast\", 7, 0.6, \"sharpness\", 5, fillcolor),\n","\n","            SubPolicy(0.7, \"color\", 7, 0.5, \"translateX\", 8, fillcolor),\n","            SubPolicy(0.3, \"equalize\", 7, 0.4, \"autocontrast\", 8, fillcolor),\n","            SubPolicy(0.4, \"translateY\", 3, 0.2, \"sharpness\", 6, fillcolor),\n","            SubPolicy(0.9, \"brightness\", 6, 0.2, \"color\", 8, fillcolor),\n","            SubPolicy(0.5, \"solarize\", 2, 0.0, \"invert\", 3, fillcolor),\n","\n","            SubPolicy(0.2, \"equalize\", 0, 0.6, \"autocontrast\", 0, fillcolor),\n","            SubPolicy(0.2, \"equalize\", 8, 0.8, \"equalize\", 4, fillcolor),\n","            SubPolicy(0.9, \"color\", 9, 0.6, \"equalize\", 6, fillcolor),\n","            SubPolicy(0.8, \"autocontrast\", 4, 0.2, \"solarize\", 8, fillcolor),\n","            SubPolicy(0.1, \"brightness\", 3, 0.7, \"color\", 0, fillcolor),\n","\n","            SubPolicy(0.4, \"solarize\", 5, 0.9, \"autocontrast\", 3, fillcolor),\n","            SubPolicy(0.9, \"translateY\", 9, 0.7, \"translateY\", 9, fillcolor),\n","            SubPolicy(0.9, \"autocontrast\", 2, 0.8, \"solarize\", 3, fillcolor),\n","            SubPolicy(0.8, \"equalize\", 8, 0.1, \"invert\", 3, fillcolor),\n","            SubPolicy(0.7, \"translateY\", 9, 0.9, \"autocontrast\", 1, fillcolor)\n","        ]\n","\n","\n","    def __call__(self, img):\n","        policy_idx = random.randint(0, len(self.policies) - 1)\n","        return self.policies[policy_idx](img)\n","\n","    def __repr__(self):\n","        return \"AutoAugment CIFAR10 Policy\"\n","\n","\n","class SubPolicy(object):\n","    def __init__(self, p1, operation1, magnitude_idx1, p2, operation2, magnitude_idx2, fillcolor=(128, 128, 128)):\n","        ranges = {\n","            \"shearX\": np.linspace(0, 0.3, 10),\n","            \"shearY\": np.linspace(0, 0.3, 10),\n","            \"translateX\": np.linspace(0, 150 / 331, 10),\n","            \"translateY\": np.linspace(0, 150 / 331, 10),\n","            \"rotate\": np.linspace(0, 30, 10),\n","            \"color\": np.linspace(0.0, 0.9, 10),\n","            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(int),\n","            \"solarize\": np.linspace(256, 0, 10),\n","            \"contrast\": np.linspace(0.0, 0.9, 10),\n","            \"sharpness\": np.linspace(0.0, 0.9, 10),\n","            \"brightness\": np.linspace(0.0, 0.9, 10),\n","            \"autocontrast\": [0] * 10,\n","            \"equalize\": [0] * 10,\n","            \"invert\": [0] * 10\n","        }\n","\n","        # from https://stackoverflow.com/questions/5252170/specify-image-filling-color-when-rotating-in-python-with-pil-and-setting-expand\n","        def rotate_with_fill(img, magnitude):\n","            rot = img.convert(\"RGBA\").rotate(magnitude)\n","            return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(img.mode)\n","\n","        func = {\n","            \"shearX\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, magnitude * random.choice([-1, 1]), 0, 0, 1, 0),\n","                Image.BICUBIC, fillcolor=fillcolor),\n","            \"shearY\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, 0, 0, magnitude * random.choice([-1, 1]), 1, 0),\n","                Image.BICUBIC, fillcolor=fillcolor),\n","            \"translateX\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, 0, magnitude * img.size[0] * random.choice([-1, 1]), 0, 1, 0),\n","                fillcolor=fillcolor),\n","            \"translateY\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * img.size[1] * random.choice([-1, 1])),\n","                fillcolor=fillcolor),\n","            \"rotate\": lambda img, magnitude: rotate_with_fill(img, magnitude),\n","            # \"rotate\": lambda img, magnitude: img.rotate(magnitude * random.choice([-1, 1])),\n","            \"color\": lambda img, magnitude: ImageEnhance.Color(img).enhance(1 + magnitude * random.choice([-1, 1])),\n","            \"posterize\": lambda img, magnitude: ImageOps.posterize(img, magnitude),\n","            \"solarize\": lambda img, magnitude: ImageOps.solarize(img, magnitude),\n","            \"contrast\": lambda img, magnitude: ImageEnhance.Contrast(img).enhance(\n","                1 + magnitude * random.choice([-1, 1])),\n","            \"sharpness\": lambda img, magnitude: ImageEnhance.Sharpness(img).enhance(\n","                1 + magnitude * random.choice([-1, 1])),\n","            \"brightness\": lambda img, magnitude: ImageEnhance.Brightness(img).enhance(\n","                1 + magnitude * random.choice([-1, 1])),\n","            \"autocontrast\": lambda img, magnitude: ImageOps.autocontrast(img),\n","            \"equalize\": lambda img, magnitude: ImageOps.equalize(img),\n","            \"invert\": lambda img, magnitude: ImageOps.invert(img)\n","        }\n","\n","        # self.name = \"{}_{:.2f}_and_{}_{:.2f}\".format(\n","        #     operation1, ranges[operation1][magnitude_idx1],\n","        #     operation2, ranges[operation2][magnitude_idx2])\n","        self.p1 = p1\n","        self.operation1 = func[operation1]\n","        self.magnitude1 = ranges[operation1][magnitude_idx1]\n","        self.p2 = p2\n","        self.operation2 = func[operation2]\n","        self.magnitude2 = ranges[operation2][magnitude_idx2]\n","\n","\n","    def __call__(self, img):\n","        if random.random() < self.p1: img = self.operation1(img, self.magnitude1)\n","        if random.random() < self.p2: img = self.operation2(img, self.magnitude2)\n","        return img\n","\n","\n","class TestDataset(Dataset):\n","    def __init__(self, df, mode='test', transforms=None):\n","        self.df = df\n","        self.mode = mode\n","        self.transform = transforms[self.mode]\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","\n","        image = Image.open(TEST_IMAGE_PATH / self.df[idx]).convert(\"RGB\")\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:46:34.096820Z","iopub.status.busy":"2024-05-08T14:46:34.095890Z","iopub.status.idle":"2024-05-08T14:46:34.101677Z","shell.execute_reply":"2024-05-08T14:46:34.100663Z","shell.execute_reply.started":"2024-05-08T14:46:34.096786Z"},"trusted":true},"outputs":[],"source":["mean = torch.tensor([0.5070, 0.4865, 0.4408])\n","stdev = torch.tensor([0.2621, 0.2512, 0.2713])"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:46:34.601783Z","iopub.status.busy":"2024-05-08T14:46:34.601119Z","iopub.status.idle":"2024-05-08T14:46:36.604958Z","shell.execute_reply":"2024-05-08T14:46:36.604043Z","shell.execute_reply.started":"2024-05-08T14:46:34.601749Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["train_transforms = torchvision.transforms.Compose([\n","        torchvision.transforms.Resize((224,224)),\n","        CIFAR10Policy(),\n","        torchvision.transforms.ToTensor(),\n","        torchvision.transforms.Normalize(mean, stdev)\n","    ])\n","\n","#train_dataset, train_valid_dataset = [torchvision.datasets.ImageFolder(folder, transform=train_transforms) for folder in [root/'train', root/'train_valid']]\n","train_dataset = torchvision.datasets.CIFAR100(root=\"data\",\n","                                             train=True,\n","                                             download=True,\n","                                             transform=train_transforms)\n","\n","valid_transforms = torchvision.transforms.Compose([\n","        torchvision.transforms.Resize((224,224)),\n","        torchvision.transforms.ToTensor(),\n","        torchvision.transforms.Normalize(mean, stdev)\n","    ])\n","\n","#valid_dataset, test_dataset = [torchvision.datasets.ImageFolder(folder, transform=valid_transforms) for folder in [root/'valid', root/'test']]\n","\n","valid_dataset = torchvision.datasets.CIFAR100(root=\"data\",\n","                                            train=False,\n","                                            download=True,\n","                                            transform=valid_transforms)"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:46:36.606854Z","iopub.status.busy":"2024-05-08T14:46:36.606511Z","iopub.status.idle":"2024-05-08T14:46:36.614483Z","shell.execute_reply":"2024-05-08T14:46:36.613135Z","shell.execute_reply.started":"2024-05-08T14:46:36.606826Z"},"trusted":true},"outputs":[],"source":["num_gpus = torch.cuda.device_count()\n","\n","train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2*num_gpus, pin_memory=True)\n","#train_valid_dataloader = torch.utils.data.DataLoader(train_valid_dataset, batch_size=128, shuffle=True, num_workers=2*num_gpus, pin_memory=True)\n","\n","valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=128, shuffle=False, num_workers=2*num_gpus, pin_memory=True)\n","#test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2*num_gpus, pin_memory=True)"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:46:39.279831Z","iopub.status.busy":"2024-05-08T14:46:39.279310Z","iopub.status.idle":"2024-05-08T14:46:39.285593Z","shell.execute_reply":"2024-05-08T14:46:39.284453Z","shell.execute_reply.started":"2024-05-08T14:46:39.279785Z"},"trusted":true},"outputs":[],"source":["def get_net():\n","    resnet = torchvision.models.resnet34(pretrained=True)\n","    \n","    # Substitute the FC output layer\n","    resnet.fc = torch.nn.Linear(resnet.fc.in_features, 100)\n","    torch.nn.init.xavier_uniform_(resnet.fc.weight)\n","    return resnet"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:46:40.627844Z","iopub.status.busy":"2024-05-08T14:46:40.627060Z","iopub.status.idle":"2024-05-08T14:46:40.644163Z","shell.execute_reply":"2024-05-08T14:46:40.643033Z","shell.execute_reply.started":"2024-05-08T14:46:40.627810Z"},"trusted":true},"outputs":[],"source":["import time\n","\n","def train(net, train_dataloader, valid_dataloader, criterion, optimizer, scheduler=None, epochs=10, device='cpu', checkpoint_epochs=10):\n","    start = time.time()\n","    print(f'Training for {epochs} epochs on {device}')\n","    \n","    for epoch in range(1,epochs+1):\n","        epoch_start = time.time()\n","        print(f\"Epoch {epoch}/{epochs}\")\n","        \n","        net.train()  \n","        train_loss = torch.tensor(0., device=device)  \n","        train_accuracy = torch.tensor(0., device=device)\n","        for X, y in train_dataloader:\n","            X = X.to(device)\n","            y = y.to(device)\n","            preds = net(X)\n","            loss = criterion(preds, y)\n","            \n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            \n","            with torch.no_grad():\n","                train_loss += loss * train_dataloader.batch_size\n","                train_accuracy += (torch.argmax(preds, dim=1) == y).sum()\n","        \n","        if valid_dataloader is not None:\n","            net.eval()  \n","            valid_loss = torch.tensor(0., device=device)\n","            valid_accuracy = torch.tensor(0., device=device)\n","            with torch.no_grad():\n","                for X, y in valid_dataloader:\n","                    X = X.to(device)\n","                    y = y.to(device)\n","                    preds = net(X)\n","                    loss = criterion(preds, y)\n","\n","                    valid_loss += loss * valid_dataloader.batch_size\n","                    valid_accuracy += (torch.argmax(preds, dim=1) == y).sum()\n","        \n","        if scheduler is not None: \n","            scheduler.step()\n","            \n","        print(f'Training loss: {train_loss/len(train_dataloader.dataset):.2f}')\n","        print(f'Training accuracy: {100*train_accuracy/len(train_dataloader.dataset):.2f}')\n","        \n","        if valid_dataloader is not None:\n","            print(f'Valid loss: {valid_loss/len(valid_dataloader.dataset):.2f}')\n","            print(f'Valid accuracy: {100*valid_accuracy/len(valid_dataloader.dataset):.2f}')\n","        \n","        if epoch % checkpoint_epochs == 0:\n","            torch.save({\n","                'epoch': epoch,\n","                'state_dict': net.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","            }, f'./checkpoint_epoch{epoch}.pth.tar')\n","        elapsed = time.time()\n","        print(f'Epoch time: {elapsed-epoch_start:.1f} Total training time: {elapsed-start:.1f}')\n","        print()\n","    \n","    end = time.time()\n","    print(f'Total training time: {end-start:.1f} seconds')\n","    return net"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:52:50.853765Z","iopub.status.busy":"2024-05-08T14:52:50.853341Z","iopub.status.idle":"2024-05-08T14:52:50.865014Z","shell.execute_reply":"2024-05-08T14:52:50.863836Z","shell.execute_reply.started":"2024-05-08T14:52:50.853732Z"},"trusted":true},"outputs":[],"source":["def measure_module_sparsity(module, weight=True, bias=False, use_mask=False):\n","\n","    num_zeros = 0\n","    num_elements = 0\n","\n","    if use_mask == True:\n","        for buffer_name, buffer in module.named_buffers():\n","            if \"weight_mask\" in buffer_name and weight == True:\n","                num_zeros += torch.sum(buffer == 0).item()\n","                num_elements += buffer.nelement()\n","            if \"bias_mask\" in buffer_name and bias == True:\n","                num_zeros += torch.sum(buffer == 0).item()\n","                num_elements += buffer.nelement()\n","    else:\n","        for param_name, param in module.named_parameters():\n","            if \"weight\" in param_name and weight == True:\n","                num_zeros += torch.sum(param == 0).item()\n","                num_elements += param.nelement()\n","            if \"bias\" in param_name and bias == True:\n","                num_zeros += torch.sum(param == 0).item()\n","                num_elements += param.nelement()\n","\n","    sparsity = num_zeros / num_elements\n","\n","    return num_zeros, num_elements, sparsity"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:53:01.873636Z","iopub.status.busy":"2024-05-08T14:53:01.872957Z","iopub.status.idle":"2024-05-08T14:53:01.881857Z","shell.execute_reply":"2024-05-08T14:53:01.880760Z","shell.execute_reply.started":"2024-05-08T14:53:01.873603Z"},"trusted":true},"outputs":[],"source":["def measure_global_sparsity(model,\n","                            weight=True,\n","                            bias=False,\n","                            conv2d_use_mask=False,\n","                            linear_use_mask=False):\n","\n","    num_zeros = 0\n","    num_elements = 0\n","\n","    for module_name, module in model.named_modules():\n","\n","        if isinstance(module, torch.nn.Conv2d):\n","\n","            module_num_zeros, module_num_elements, _ = measure_module_sparsity(\n","                module, weight=weight, bias=bias, use_mask=conv2d_use_mask)\n","            num_zeros += module_num_zeros\n","            num_elements += module_num_elements\n","\n","        elif isinstance(module, torch.nn.Linear):\n","\n","            module_num_zeros, module_num_elements, _ = measure_module_sparsity(\n","                module, weight=weight, bias=bias, use_mask=linear_use_mask)\n","            num_zeros += module_num_zeros\n","            num_elements += module_num_elements\n","\n","    sparsity = num_zeros / num_elements\n","\n","    return num_zeros, num_elements, sparsity"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:46:42.281075Z","iopub.status.busy":"2024-05-08T14:46:42.280595Z","iopub.status.idle":"2024-05-08T14:46:42.285817Z","shell.execute_reply":"2024-05-08T14:46:42.284648Z","shell.execute_reply.started":"2024-05-08T14:46:42.281043Z"},"trusted":true},"outputs":[],"source":["import torch.nn.utils.prune as prune"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:53:11.796213Z","iopub.status.busy":"2024-05-08T14:53:11.795267Z","iopub.status.idle":"2024-05-08T14:53:12.227603Z","shell.execute_reply":"2024-05-08T14:53:12.226714Z","shell.execute_reply.started":"2024-05-08T14:53:11.796179Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]}],"source":["net = torchvision.models.resnet34(num_classes=10, pretrained=False)"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:53:13.427989Z","iopub.status.busy":"2024-05-08T14:53:13.427287Z","iopub.status.idle":"2024-05-08T14:53:13.432755Z","shell.execute_reply":"2024-05-08T14:53:13.431518Z","shell.execute_reply.started":"2024-05-08T14:53:13.427956Z"},"trusted":true},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:53:14.332970Z","iopub.status.busy":"2024-05-08T14:53:14.332590Z","iopub.status.idle":"2024-05-08T14:53:15.189115Z","shell.execute_reply":"2024-05-08T14:53:15.187949Z","shell.execute_reply.started":"2024-05-08T14:53:14.332941Z"},"trusted":true},"outputs":[],"source":["parameters_to_prune = []\n","for module_name, module in net.named_modules():\n","    if isinstance(module, torch.nn.Conv2d):\n","        parameters_to_prune.append((module, \"weight\"))\n","prune.global_unstructured(\n","                parameters_to_prune,\n","                pruning_method=prune.L1Unstructured,\n","                amount=0,\n","            )"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:53:16.420542Z","iopub.status.busy":"2024-05-08T14:53:16.420121Z","iopub.status.idle":"2024-05-08T14:53:16.629614Z","shell.execute_reply":"2024-05-08T14:53:16.628473Z","shell.execute_reply.started":"2024-05-08T14:53:16.420509Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["net.load_state_dict(torch.load(\"/kaggle/input/resnet34-for-cifar10/pytorch/sparsity0.95_accuracy0.96_with_masks/1/sparsity0.95_final_acc0.96 (1).pt\",\n","                               map_location=device))"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:53:17.749352Z","iopub.status.busy":"2024-05-08T14:53:17.748636Z","iopub.status.idle":"2024-05-08T14:53:17.755260Z","shell.execute_reply":"2024-05-08T14:53:17.754223Z","shell.execute_reply.started":"2024-05-08T14:53:17.749319Z"},"trusted":true},"outputs":[],"source":["net.fc = torch.nn.Linear(512, 100, bias=True)"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:53:18.802519Z","iopub.status.busy":"2024-05-08T14:53:18.801987Z","iopub.status.idle":"2024-05-08T14:53:18.811544Z","shell.execute_reply":"2024-05-08T14:53:18.810378Z","shell.execute_reply.started":"2024-05-08T14:53:18.802485Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Parameter containing:\n","tensor([[-0.0295, -0.0525,  0.0830,  ...,  0.0026,  0.0546,  0.0394],\n","        [ 0.0718,  0.0655, -0.0764,  ..., -0.0309,  0.0945, -0.0495],\n","        [ 0.0491,  0.0332, -0.0281,  ..., -0.0881,  0.0074,  0.0225],\n","        ...,\n","        [-0.0461, -0.0546, -0.0443,  ..., -0.0958,  0.0205,  0.0218],\n","        [-0.0324,  0.0385, -0.0196,  ..., -0.0204,  0.0054,  0.0113],\n","        [ 0.0015, -0.0329,  0.0705,  ...,  0.0321, -0.0976,  0.0513]],\n","       requires_grad=True)"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["torch.nn.init.xavier_uniform_(net.fc.weight)"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:54:11.882525Z","iopub.status.busy":"2024-05-08T14:54:11.881511Z","iopub.status.idle":"2024-05-08T14:54:11.938148Z","shell.execute_reply":"2024-05-08T14:54:11.937112Z","shell.execute_reply.started":"2024-05-08T14:54:11.882487Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(20204266, 21318848, 0.9477184695908522)"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["measure_global_sparsity(net, conv2d_use_mask=True)"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:54:22.325358Z","iopub.status.busy":"2024-05-08T14:54:22.324369Z","iopub.status.idle":"2024-05-08T14:54:22.332723Z","shell.execute_reply":"2024-05-08T14:54:22.331567Z","shell.execute_reply.started":"2024-05-08T14:54:22.325322Z"},"trusted":true},"outputs":[],"source":["#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","lr, weight_decay, epochs = 1e-3, 5e-4, 30\n","\n","#net = get_net().to(device)\n","\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","\n","#params_1x = [param for name, param in net.named_parameters() if 'fc' not in str(name)]\n","optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n","\n","scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20])"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:54:58.676843Z","iopub.status.busy":"2024-05-08T14:54:58.675874Z","iopub.status.idle":"2024-05-08T14:54:59.823846Z","shell.execute_reply":"2024-05-08T14:54:59.822479Z","shell.execute_reply.started":"2024-05-08T14:54:58.676807Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Wed May  8 14:54:59 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P0              32W / 250W |   3136MiB / 16384MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:54:42.483103Z","iopub.status.busy":"2024-05-08T14:54:42.482051Z","iopub.status.idle":"2024-05-08T14:54:42.488197Z","shell.execute_reply":"2024-05-08T14:54:42.486922Z","shell.execute_reply.started":"2024-05-08T14:54:42.483061Z"},"trusted":true},"outputs":[],"source":["import gc"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:54:55.643237Z","iopub.status.busy":"2024-05-08T14:54:55.642802Z","iopub.status.idle":"2024-05-08T14:54:56.406474Z","shell.execute_reply":"2024-05-08T14:54:56.405483Z","shell.execute_reply.started":"2024-05-08T14:54:55.643201Z"},"trusted":true},"outputs":[],"source":["gc.collect()\n","torch.cuda.empty_cache()\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T14:56:09.389540Z","iopub.status.busy":"2024-05-08T14:56:09.389107Z","iopub.status.idle":"2024-05-08T14:56:09.400483Z","shell.execute_reply":"2024-05-08T14:56:09.399492Z","shell.execute_reply.started":"2024-05-08T14:56:09.389506Z"},"trusted":true},"outputs":[],"source":["net.to(device);"]},{"cell_type":"code","execution_count":80,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-05-08T14:56:11.648703Z","iopub.status.busy":"2024-05-08T14:56:11.648288Z","iopub.status.idle":"2024-05-08T16:01:36.439901Z","shell.execute_reply":"2024-05-08T16:01:36.438645Z","shell.execute_reply.started":"2024-05-08T14:56:11.648670Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training for 30 epochs on cuda\n","Epoch 1/30\n","Training loss: 2.33\n","Training accuracy: 40.01\n","Valid loss: 1.58\n","Valid accuracy: 53.94\n","Epoch time: 130.7 Total training time: 130.7\n","\n","Epoch 2/30\n","Training loss: 1.57\n","Training accuracy: 55.90\n","Valid loss: 1.39\n","Valid accuracy: 59.76\n","Epoch time: 130.9 Total training time: 261.6\n","\n","Epoch 3/30\n","Training loss: 1.35\n","Training accuracy: 61.71\n","Valid loss: 1.30\n","Valid accuracy: 62.88\n","Epoch time: 130.8 Total training time: 392.4\n","\n","Epoch 4/30\n","Training loss: 1.23\n","Training accuracy: 65.05\n","Valid loss: 1.19\n","Valid accuracy: 65.85\n","Epoch time: 130.7 Total training time: 523.1\n","\n","Epoch 5/30\n","Training loss: 1.13\n","Training accuracy: 67.43\n","Valid loss: 1.18\n","Valid accuracy: 65.52\n","Epoch time: 130.7 Total training time: 653.9\n","\n","Epoch 6/30\n","Training loss: 1.06\n","Training accuracy: 69.38\n","Valid loss: 1.09\n","Valid accuracy: 68.23\n","Epoch time: 131.3 Total training time: 785.2\n","\n","Epoch 7/30\n","Training loss: 1.01\n","Training accuracy: 70.90\n","Valid loss: 1.10\n","Valid accuracy: 68.48\n","Epoch time: 131.2 Total training time: 916.4\n","\n","Epoch 8/30\n","Training loss: 0.97\n","Training accuracy: 71.98\n","Valid loss: 1.11\n","Valid accuracy: 68.57\n","Epoch time: 131.1 Total training time: 1047.5\n","\n","Epoch 9/30\n","Training loss: 0.93\n","Training accuracy: 73.05\n","Valid loss: 1.11\n","Valid accuracy: 68.78\n","Epoch time: 130.7 Total training time: 1178.3\n","\n","Epoch 10/30\n","Training loss: 0.90\n","Training accuracy: 73.85\n","Valid loss: 1.13\n","Valid accuracy: 68.71\n","Epoch time: 131.5 Total training time: 1309.7\n","\n","Epoch 11/30\n","Training loss: 0.87\n","Training accuracy: 74.67\n","Valid loss: 1.12\n","Valid accuracy: 68.47\n","Epoch time: 130.5 Total training time: 1440.2\n","\n","Epoch 12/30\n","Training loss: 0.84\n","Training accuracy: 75.70\n","Valid loss: 1.08\n","Valid accuracy: 68.91\n","Epoch time: 130.9 Total training time: 1571.2\n","\n","Epoch 13/30\n","Training loss: 0.83\n","Training accuracy: 75.84\n","Valid loss: 1.04\n","Valid accuracy: 70.51\n","Epoch time: 130.8 Total training time: 1701.9\n","\n","Epoch 14/30\n","Training loss: 0.80\n","Training accuracy: 76.44\n","Valid loss: 1.13\n","Valid accuracy: 68.60\n","Epoch time: 130.7 Total training time: 1832.6\n","\n","Epoch 15/30\n","Training loss: 0.79\n","Training accuracy: 77.11\n","Valid loss: 1.13\n","Valid accuracy: 68.61\n","Epoch time: 130.5 Total training time: 1963.2\n","\n","Epoch 16/30\n","Training loss: 0.76\n","Training accuracy: 77.73\n","Valid loss: 1.11\n","Valid accuracy: 69.46\n","Epoch time: 131.0 Total training time: 2094.1\n","\n","Epoch 17/30\n","Training loss: 0.76\n","Training accuracy: 77.97\n","Valid loss: 1.07\n","Valid accuracy: 69.80\n","Epoch time: 130.9 Total training time: 2225.1\n","\n","Epoch 18/30\n","Training loss: 0.74\n","Training accuracy: 78.46\n","Valid loss: 1.14\n","Valid accuracy: 68.57\n","Epoch time: 130.7 Total training time: 2355.8\n","\n","Epoch 19/30\n","Training loss: 0.73\n","Training accuracy: 78.75\n","Valid loss: 1.10\n","Valid accuracy: 69.53\n","Epoch time: 130.6 Total training time: 2486.4\n","\n","Epoch 20/30\n","Training loss: 0.72\n","Training accuracy: 78.73\n","Valid loss: 1.15\n","Valid accuracy: 69.14\n","Epoch time: 131.2 Total training time: 2617.6\n","\n","Epoch 21/30\n","Training loss: 0.49\n","Training accuracy: 86.55\n","Valid loss: 0.82\n","Valid accuracy: 76.41\n","Epoch time: 130.6 Total training time: 2748.3\n","\n","Epoch 22/30\n","Training loss: 0.41\n","Training accuracy: 89.19\n","Valid loss: 0.82\n","Valid accuracy: 76.87\n","Epoch time: 130.5 Total training time: 2878.7\n","\n","Epoch 23/30\n","Training loss: 0.37\n","Training accuracy: 90.38\n","Valid loss: 0.81\n","Valid accuracy: 77.05\n","Epoch time: 130.6 Total training time: 3009.3\n","\n","Epoch 24/30\n","Training loss: 0.34\n","Training accuracy: 91.17\n","Valid loss: 0.81\n","Valid accuracy: 77.15\n","Epoch time: 130.4 Total training time: 3139.7\n","\n","Epoch 25/30\n","Training loss: 0.34\n","Training accuracy: 91.44\n","Valid loss: 0.82\n","Valid accuracy: 77.01\n","Epoch time: 130.6 Total training time: 3270.2\n","\n","Epoch 26/30\n","Training loss: 0.32\n","Training accuracy: 91.91\n","Valid loss: 0.82\n","Valid accuracy: 76.92\n","Epoch time: 130.8 Total training time: 3401.0\n","\n","Epoch 27/30\n","Training loss: 0.30\n","Training accuracy: 92.44\n","Valid loss: 0.82\n","Valid accuracy: 76.99\n","Epoch time: 130.9 Total training time: 3531.9\n","\n","Epoch 28/30\n","Training loss: 0.29\n","Training accuracy: 92.64\n","Valid loss: 0.83\n","Valid accuracy: 76.83\n","Epoch time: 130.8 Total training time: 3662.7\n","\n","Epoch 29/30\n","Training loss: 0.28\n","Training accuracy: 92.92\n","Valid loss: 0.83\n","Valid accuracy: 76.95\n","Epoch time: 130.8 Total training time: 3793.5\n","\n","Epoch 30/30\n","Training loss: 0.29\n","Training accuracy: 92.77\n","Valid loss: 0.83\n","Valid accuracy: 76.61\n","Epoch time: 131.3 Total training time: 3924.8\n","\n","Total training time: 3924.8 seconds\n"]}],"source":["net = train(net, train_dataloader, valid_dataloader, criterion, optimizer, scheduler, epochs, device)"]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T16:03:31.896706Z","iopub.status.busy":"2024-05-08T16:03:31.896241Z","iopub.status.idle":"2024-05-08T16:03:31.903042Z","shell.execute_reply":"2024-05-08T16:03:31.901938Z","shell.execute_reply.started":"2024-05-08T16:03:31.896662Z"},"trusted":true},"outputs":[],"source":["scheduler1 = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[1, 15])"]},{"cell_type":"code","execution_count":82,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-05-08T16:03:43.210399Z","iopub.status.busy":"2024-05-08T16:03:43.209989Z","iopub.status.idle":"2024-05-08T16:58:10.238263Z","shell.execute_reply":"2024-05-08T16:58:10.236945Z","shell.execute_reply.started":"2024-05-08T16:03:43.210366Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training for 25 epochs on cuda\n","Epoch 1/25\n","Training loss: 0.28\n","Training accuracy: 93.02\n","Valid loss: 0.84\n","Valid accuracy: 76.58\n","Epoch time: 130.7 Total training time: 130.7\n","\n","Epoch 2/25\n","Training loss: 0.26\n","Training accuracy: 93.65\n","Valid loss: 0.82\n","Valid accuracy: 76.87\n","Epoch time: 130.6 Total training time: 261.3\n","\n","Epoch 3/25\n","Training loss: 0.25\n","Training accuracy: 93.71\n","Valid loss: 0.82\n","Valid accuracy: 77.01\n","Epoch time: 130.6 Total training time: 391.9\n","\n","Epoch 4/25\n","Training loss: 0.25\n","Training accuracy: 93.79\n","Valid loss: 0.82\n","Valid accuracy: 77.04\n","Epoch time: 130.6 Total training time: 522.5\n","\n","Epoch 5/25\n","Training loss: 0.24\n","Training accuracy: 94.00\n","Valid loss: 0.83\n","Valid accuracy: 77.01\n","Epoch time: 130.6 Total training time: 653.1\n","\n","Epoch 6/25\n","Training loss: 0.25\n","Training accuracy: 93.89\n","Valid loss: 0.83\n","Valid accuracy: 76.89\n","Epoch time: 130.9 Total training time: 784.0\n","\n","Epoch 7/25\n","Training loss: 0.25\n","Training accuracy: 93.93\n","Valid loss: 0.83\n","Valid accuracy: 77.05\n","Epoch time: 130.7 Total training time: 914.7\n","\n","Epoch 8/25\n","Training loss: 0.25\n","Training accuracy: 93.99\n","Valid loss: 0.82\n","Valid accuracy: 76.98\n","Epoch time: 130.6 Total training time: 1045.3\n","\n","Epoch 9/25\n","Training loss: 0.24\n","Training accuracy: 94.00\n","Valid loss: 0.83\n","Valid accuracy: 77.19\n","Epoch time: 130.7 Total training time: 1176.0\n","\n","Epoch 10/25\n","Training loss: 0.24\n","Training accuracy: 94.09\n","Valid loss: 0.82\n","Valid accuracy: 77.17\n","Epoch time: 131.5 Total training time: 1307.5\n","\n","Epoch 11/25\n","Training loss: 0.24\n","Training accuracy: 93.97\n","Valid loss: 0.83\n","Valid accuracy: 77.25\n","Epoch time: 130.7 Total training time: 1438.2\n","\n","Epoch 12/25\n","Training loss: 0.24\n","Training accuracy: 94.10\n","Valid loss: 0.82\n","Valid accuracy: 77.07\n","Epoch time: 130.6 Total training time: 1568.8\n","\n","Epoch 13/25\n","Training loss: 0.23\n","Training accuracy: 94.24\n","Valid loss: 0.82\n","Valid accuracy: 77.23\n","Epoch time: 130.6 Total training time: 1699.4\n","\n","Epoch 14/25\n","Training loss: 0.24\n","Training accuracy: 94.12\n","Valid loss: 0.82\n","Valid accuracy: 77.18\n","Epoch time: 130.3 Total training time: 1829.7\n","\n","Epoch 15/25\n","Training loss: 0.24\n","Training accuracy: 94.28\n","Valid loss: 0.82\n","Valid accuracy: 77.15\n","Epoch time: 130.4 Total training time: 1960.1\n","\n","Epoch 16/25\n","Training loss: 0.23\n","Training accuracy: 94.35\n","Valid loss: 0.82\n","Valid accuracy: 77.31\n","Epoch time: 130.5 Total training time: 2090.5\n","\n","Epoch 17/25\n","Training loss: 0.23\n","Training accuracy: 94.31\n","Valid loss: 0.83\n","Valid accuracy: 77.23\n","Epoch time: 130.6 Total training time: 2221.1\n","\n","Epoch 18/25\n","Training loss: 0.24\n","Training accuracy: 94.24\n","Valid loss: 0.82\n","Valid accuracy: 77.32\n","Epoch time: 130.5 Total training time: 2351.5\n","\n","Epoch 19/25\n","Training loss: 0.24\n","Training accuracy: 94.27\n","Valid loss: 0.82\n","Valid accuracy: 77.50\n","Epoch time: 130.5 Total training time: 2482.0\n","\n","Epoch 20/25\n","Training loss: 0.23\n","Training accuracy: 94.48\n","Valid loss: 0.82\n","Valid accuracy: 77.32\n","Epoch time: 131.1 Total training time: 2613.2\n","\n","Epoch 21/25\n","Training loss: 0.23\n","Training accuracy: 94.34\n","Valid loss: 0.83\n","Valid accuracy: 77.17\n","Epoch time: 130.6 Total training time: 2743.8\n","\n","Epoch 22/25\n","Training loss: 0.23\n","Training accuracy: 94.29\n","Valid loss: 0.82\n","Valid accuracy: 77.33\n","Epoch time: 130.3 Total training time: 2874.1\n","\n","Epoch 23/25\n","Training loss: 0.23\n","Training accuracy: 94.24\n","Valid loss: 0.83\n","Valid accuracy: 77.23\n","Epoch time: 130.8 Total training time: 3004.9\n","\n","Epoch 24/25\n","Training loss: 0.24\n","Training accuracy: 94.29\n","Valid loss: 0.82\n","Valid accuracy: 77.19\n","Epoch time: 131.3 Total training time: 3136.2\n","\n","Epoch 25/25\n","Training loss: 0.23\n","Training accuracy: 94.31\n","Valid loss: 0.83\n","Valid accuracy: 77.22\n","Epoch time: 130.8 Total training time: 3267.0\n","\n","Total training time: 3267.0 seconds\n"]}],"source":["net = train(net, train_dataloader, valid_dataloader, criterion, optimizer, scheduler1, 25, device)"]},{"cell_type":"code","execution_count":83,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T17:08:52.145363Z","iopub.status.busy":"2024-05-08T17:08:52.144259Z","iopub.status.idle":"2024-05-08T17:08:52.154109Z","shell.execute_reply":"2024-05-08T17:08:52.153005Z","shell.execute_reply.started":"2024-05-08T17:08:52.145317Z"},"trusted":true},"outputs":[],"source":["def create_classification_report(model, device, test_loader):\n","\n","    model.eval()\n","    model.to(device)\n","\n","    y_pred = []\n","    y_true = []\n","\n","    with torch.no_grad():\n","        for data in test_loader:\n","            y_true += data[1].numpy().tolist()\n","            images, _ = data[0].to(device), data[1].to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            y_pred += predicted.cpu().numpy().tolist()\n","\n","    classification_report = sklearn.metrics.classification_report(\n","        y_true=y_true, y_pred=y_pred)\n","\n","    return classification_report"]},{"cell_type":"code","execution_count":84,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-05-08T17:08:53.452644Z","iopub.status.busy":"2024-05-08T17:08:53.452215Z","iopub.status.idle":"2024-05-08T17:09:06.181024Z","shell.execute_reply":"2024-05-08T17:09:06.179697Z","shell.execute_reply.started":"2024-05-08T17:08:53.452611Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.87      0.92      0.89       100\n","           1       0.93      0.89      0.91       100\n","           2       0.57      0.64      0.60       100\n","           3       0.64      0.55      0.59       100\n","           4       0.60      0.63      0.61       100\n","           5       0.80      0.81      0.81       100\n","           6       0.78      0.75      0.77       100\n","           7       0.77      0.75      0.76       100\n","           8       0.90      0.91      0.91       100\n","           9       0.87      0.88      0.88       100\n","          10       0.76      0.70      0.73       100\n","          11       0.47      0.45      0.46       100\n","          12       0.88      0.82      0.85       100\n","          13       0.78      0.69      0.73       100\n","          14       0.80      0.73      0.76       100\n","          15       0.75      0.82      0.78       100\n","          16       0.79      0.78      0.78       100\n","          17       0.88      0.82      0.85       100\n","          18       0.74      0.71      0.72       100\n","          19       0.74      0.69      0.72       100\n","          20       0.88      0.90      0.89       100\n","          21       0.81      0.86      0.83       100\n","          22       0.82      0.80      0.81       100\n","          23       0.89      0.85      0.87       100\n","          24       0.84      0.87      0.86       100\n","          25       0.78      0.72      0.75       100\n","          26       0.81      0.75      0.78       100\n","          27       0.69      0.76      0.72       100\n","          28       0.89      0.85      0.87       100\n","          29       0.81      0.79      0.80       100\n","          30       0.72      0.70      0.71       100\n","          31       0.78      0.77      0.77       100\n","          32       0.74      0.78      0.76       100\n","          33       0.75      0.65      0.70       100\n","          34       0.74      0.78      0.76       100\n","          35       0.65      0.51      0.57       100\n","          36       0.79      0.85      0.82       100\n","          37       0.76      0.80      0.78       100\n","          38       0.80      0.70      0.75       100\n","          39       0.89      0.89      0.89       100\n","          40       0.71      0.76      0.73       100\n","          41       0.92      0.89      0.90       100\n","          42       0.84      0.76      0.80       100\n","          43       0.88      0.85      0.86       100\n","          44       0.65      0.62      0.63       100\n","          45       0.70      0.74      0.72       100\n","          46       0.57      0.60      0.58       100\n","          47       0.68      0.64      0.66       100\n","          48       0.90      0.94      0.92       100\n","          49       0.86      0.87      0.87       100\n","          50       0.66      0.63      0.65       100\n","          51       0.82      0.80      0.81       100\n","          52       0.63      0.69      0.66       100\n","          53       0.88      0.94      0.91       100\n","          54       0.81      0.84      0.82       100\n","          55       0.48      0.54      0.51       100\n","          56       0.93      0.88      0.90       100\n","          57       0.73      0.85      0.79       100\n","          58       0.91      0.93      0.92       100\n","          59       0.71      0.64      0.67       100\n","          60       0.81      0.83      0.82       100\n","          61       0.77      0.78      0.78       100\n","          62       0.75      0.78      0.76       100\n","          63       0.75      0.79      0.77       100\n","          64       0.78      0.61      0.69       100\n","          65       0.61      0.69      0.64       100\n","          66       0.93      0.86      0.90       100\n","          67       0.71      0.63      0.67       100\n","          68       0.85      0.95      0.90       100\n","          69       0.85      0.81      0.83       100\n","          70       0.87      0.77      0.81       100\n","          71       0.73      0.80      0.76       100\n","          72       0.47      0.54      0.50       100\n","          73       0.67      0.74      0.70       100\n","          74       0.57      0.66      0.61       100\n","          75       0.89      0.87      0.88       100\n","          76       0.83      0.93      0.88       100\n","          77       0.77      0.73      0.75       100\n","          78       0.76      0.74      0.75       100\n","          79       0.79      0.89      0.84       100\n","          80       0.66      0.75      0.70       100\n","          81       0.72      0.78      0.75       100\n","          82       0.95      0.92      0.93       100\n","          83       0.82      0.71      0.76       100\n","          84       0.78      0.76      0.77       100\n","          85       0.89      0.87      0.88       100\n","          86       0.89      0.79      0.84       100\n","          87       0.82      0.85      0.83       100\n","          88       0.85      0.84      0.84       100\n","          89       0.85      0.87      0.86       100\n","          90       0.75      0.83      0.79       100\n","          91       0.90      0.84      0.87       100\n","          92       0.71      0.70      0.71       100\n","          93       0.82      0.69      0.75       100\n","          94       0.90      0.94      0.92       100\n","          95       0.73      0.72      0.73       100\n","          96       0.63      0.73      0.68       100\n","          97       0.81      0.79      0.80       100\n","          98       0.61      0.69      0.64       100\n","          99       0.80      0.82      0.81       100\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.78      0.77      0.77     10000\n","weighted avg       0.78      0.77      0.77     10000\n","\n"]}],"source":["print(create_classification_report(net, device, valid_dataloader))"]},{"cell_type":"code","execution_count":87,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T17:09:52.474818Z","iopub.status.busy":"2024-05-08T17:09:52.474112Z","iopub.status.idle":"2024-05-08T17:09:52.490045Z","shell.execute_reply":"2024-05-08T17:09:52.488971Z","shell.execute_reply.started":"2024-05-08T17:09:52.474764Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(20204266, 21318848, 0.9477184695908522)"]},"execution_count":87,"metadata":{},"output_type":"execute_result"}],"source":["measure_global_sparsity(net, conv2d_use_mask=True)"]},{"cell_type":"code","execution_count":88,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T17:11:48.139882Z","iopub.status.busy":"2024-05-08T17:11:48.139119Z","iopub.status.idle":"2024-05-08T17:11:48.416936Z","shell.execute_reply":"2024-05-08T17:11:48.416044Z","shell.execute_reply.started":"2024-05-08T17:11:48.139845Z"},"trusted":true},"outputs":[],"source":["torch.save({\n","                #'epoch': epoch,\n","                'state_dict': net.state_dict(),\n","                #'optimizer': optimizer.state_dict(),\n","            }, 'sp0.95_acc0.77_finetuned_from_cifar10.pth.tar')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T11:27:34.155128Z","iopub.status.busy":"2024-05-06T11:27:34.154787Z","iopub.status.idle":"2024-05-06T11:27:34.543714Z","shell.execute_reply":"2024-05-06T11:27:34.542935Z","shell.execute_reply.started":"2024-05-06T11:27:34.155103Z"},"trusted":true},"outputs":[],"source":["model = torchvision.models.resnet34()\n","model.fc = torch.nn.Linear(model.fc.in_features, 100)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T11:27:37.44289Z","iopub.status.busy":"2024-05-06T11:27:37.442544Z","iopub.status.idle":"2024-05-06T11:27:37.716248Z","shell.execute_reply":"2024-05-06T11:27:37.715344Z","shell.execute_reply.started":"2024-05-06T11:27:37.442865Z"},"trusted":true},"outputs":[],"source":["checkpoint = torch.load('/kaggle/working/checkpoint_epoch30.pth.tar')\n","model.load_state_dict(checkpoint['state_dict'])"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-05-06T11:27:50.88839Z","iopub.status.busy":"2024-05-06T11:27:50.887625Z","iopub.status.idle":"2024-05-06T11:28:02.239324Z","shell.execute_reply":"2024-05-06T11:28:02.238195Z","shell.execute_reply.started":"2024-05-06T11:27:50.888344Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["print(create_classification_report(model, device, valid_dataloader))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"isSourceIdPinned":true,"modelInstanceId":18169,"sourceId":21938,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
